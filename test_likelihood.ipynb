{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1bae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchinfo import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aee35f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17fd99c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Om\t\t\t\\Omega_m\n",
    "# Obh2\t\t\t\\Omega_{b}h^2\n",
    "# h\t\n",
    "datafile = 'chains/LCDM_phy_HD_nested_dynesty_multi_1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc69788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataSet(torch.utils.data.Dataset):\n",
    "    '''\n",
    "    Prepare the dataset for regression\n",
    "    '''\n",
    "    def __init__(self, X, y, scale_data=False):\n",
    "        if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
    "            # Apply scaling if necessary\n",
    "            if scale_data:\n",
    "                X = StandardScaler().fit_transform(X)\n",
    "            self.X = torch.from_numpy(X)\n",
    "            self.y = torch.from_numpy(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2c80912",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    '''\n",
    "    Multilayer Perceptron for regression.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        ncols = 3\n",
    "        self.layers = nn.Sequential(\n",
    "          nn.Linear(ncols, 200),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(200, 200),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(200, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "          Forward pass\n",
    "        '''\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e24b9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1036, 3) (1036, 1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Set fixed random number seed\n",
    "    torch.manual_seed(42)\n",
    "  \n",
    "    # Load Boston dataset\n",
    "    X = np.loadtxt(datafile, usecols=(2,3,4))\n",
    "    y = np.loadtxt(datafile, usecols=1).reshape(-1, 1)\n",
    "    randomize = np.random.permutation(len(X))\n",
    "    X = X[randomize]\n",
    "    y = y[randomize]\n",
    "    print(np.shape(X), np.shape(y))\n",
    "    X_test, y_test = X[:100, :], y[:100, :]\n",
    "    X, y = X[100:, :], y[100:, :]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f173672",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = LoadDataSet(X_train, y_train)\n",
    "dataset_val = LoadDataSet(X_val, y_val)\n",
    "# dataset_test = LoadDataSet(X_test, y_test)\n",
    "X_test, y_test = torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62b89106",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(dataset_train, batch_size=2, shuffle=True, num_workers=1)\n",
    "validloader = torch.utils.data.DataLoader(dataset_val, batch_size=2, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3ea89b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MLP\n",
    "mlp = MLP()\n",
    "mlp.float()\n",
    "# Define the loss function and optimizer\n",
    "loss_function = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f533ceb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "MLP                                      --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Linear: 2-1                       800\n",
       "│    └─ReLU: 2-2                         --\n",
       "│    └─Linear: 2-3                       40,200\n",
       "│    └─ReLU: 2-4                         --\n",
       "│    └─Linear: 2-5                       201\n",
       "=================================================================\n",
       "Total params: 41,201\n",
       "Trainable params: 41,201\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(mlp, batch_size=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00af4a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Loss after mini-batch     1: 7.287\n",
      "Loss after mini-batch    11: 25.879\n",
      "Loss after mini-batch    21: 38.638\n",
      "Loss after mini-batch    31: 59.193\n",
      "Loss after mini-batch    41: 10.342\n",
      "Loss after mini-batch    51: 17.420\n",
      "Loss after mini-batch    61: 6.859\n",
      "Loss after mini-batch    71: 7.086\n",
      "Loss after mini-batch    81: 31.922\n",
      "Loss after mini-batch    91: 6.557\n",
      "Loss after mini-batch   101: 20.511\n",
      "Loss after mini-batch   111: 5.822\n",
      "Loss after mini-batch   121: 5.637\n",
      "Loss after mini-batch   131: 5.506\n",
      "Loss after mini-batch   141: 7.195\n",
      "Loss after mini-batch   151: 5.422\n",
      "Loss after mini-batch   161: 4.679\n",
      "Loss after mini-batch   171: 8.138\n",
      "Loss after mini-batch   181: 4.323\n",
      "Loss after mini-batch   191: 3.785\n",
      "Loss after mini-batch   201: 5.513\n",
      "Loss after mini-batch   211: 6.177\n",
      "Loss after mini-batch   221: 4.968\n",
      "Loss after mini-batch   231: 8.735\n",
      "Loss after mini-batch   241: 8.255\n",
      "Loss after mini-batch   251: 19.817\n",
      "Loss after mini-batch   261: 1.419\n",
      "Loss after mini-batch   271: 10.276\n",
      "Loss after mini-batch   281: 0.576\n",
      "Loss after mini-batch   291: 0.677\n",
      "Loss after mini-batch   301: 52.015\n",
      "Loss after mini-batch   311: 9.694\n",
      "Loss after mini-batch   321: 2.033\n",
      "Loss after mini-batch   331: 0.920\n",
      "Loss after mini-batch   341: 0.838\n",
      "Loss after mini-batch   351: 42.258\n",
      "Loss after mini-batch   361: 0.392\n",
      "Loss after mini-batch   371: 0.509\n",
      "Training Loss: 7.926 \t\t Validation Loss:8.550\n",
      "Starting epoch 2\n",
      "Loss after mini-batch     1: 0.605\n",
      "Loss after mini-batch    11: 27.873\n",
      "Loss after mini-batch    21: 13.712\n",
      "Loss after mini-batch    31: 2.402\n",
      "Loss after mini-batch    41: 2.966\n",
      "Loss after mini-batch    51: 6.792\n",
      "Loss after mini-batch    61: 0.498\n",
      "Loss after mini-batch    71: 6.907\n",
      "Loss after mini-batch    81: 0.752\n",
      "Loss after mini-batch    91: 2.829\n",
      "Loss after mini-batch   101: 7.360\n",
      "Loss after mini-batch   111: 0.497\n",
      "Loss after mini-batch   121: 2.706\n",
      "Loss after mini-batch   131: 10.625\n",
      "Loss after mini-batch   141: 5.235\n",
      "Loss after mini-batch   151: 0.556\n",
      "Loss after mini-batch   161: 5.856\n",
      "Loss after mini-batch   171: 0.542\n",
      "Loss after mini-batch   181: 25.880\n",
      "Loss after mini-batch   191: 1.183\n",
      "Loss after mini-batch   201: 11.254\n",
      "Loss after mini-batch   211: 0.450\n",
      "Loss after mini-batch   221: 15.533\n",
      "Loss after mini-batch   231: 5.019\n",
      "Loss after mini-batch   241: 0.153\n",
      "Loss after mini-batch   251: 0.575\n",
      "Loss after mini-batch   261: 30.014\n",
      "Loss after mini-batch   271: 28.971\n",
      "Loss after mini-batch   281: 14.220\n",
      "Loss after mini-batch   291: 0.898\n",
      "Loss after mini-batch   301: 0.279\n",
      "Loss after mini-batch   311: 0.656\n",
      "Loss after mini-batch   321: 0.842\n",
      "Loss after mini-batch   331: 0.705\n",
      "Loss after mini-batch   341: 3.652\n",
      "Loss after mini-batch   351: 0.399\n",
      "Loss after mini-batch   361: 0.586\n",
      "Loss after mini-batch   371: 1.978\n",
      "Training Loss: 0.673 \t\t Validation Loss:5.398\n",
      "Starting epoch 3\n",
      "Loss after mini-batch     1: 0.731\n",
      "Loss after mini-batch    11: 1.384\n",
      "Loss after mini-batch    21: 1.994\n",
      "Loss after mini-batch    31: 0.306\n",
      "Loss after mini-batch    41: 1.075\n",
      "Loss after mini-batch    51: 2.030\n",
      "Loss after mini-batch    61: 0.902\n",
      "Loss after mini-batch    71: 3.931\n",
      "Loss after mini-batch    81: 6.842\n",
      "Loss after mini-batch    91: 18.808\n",
      "Loss after mini-batch   101: 0.451\n",
      "Loss after mini-batch   111: 0.551\n",
      "Loss after mini-batch   121: 0.604\n",
      "Loss after mini-batch   131: 0.346\n",
      "Loss after mini-batch   141: 0.332\n",
      "Loss after mini-batch   151: 2.367\n",
      "Loss after mini-batch   161: 0.479\n",
      "Loss after mini-batch   171: 1.260\n",
      "Loss after mini-batch   181: 10.042\n",
      "Loss after mini-batch   191: 4.791\n",
      "Loss after mini-batch   201: 0.447\n",
      "Loss after mini-batch   211: 3.278\n",
      "Loss after mini-batch   221: 0.559\n",
      "Loss after mini-batch   231: 0.607\n",
      "Loss after mini-batch   241: 25.718\n",
      "Loss after mini-batch   251: 19.569\n",
      "Loss after mini-batch   261: 0.757\n",
      "Loss after mini-batch   271: 8.145\n",
      "Loss after mini-batch   281: 0.259\n",
      "Loss after mini-batch   291: 0.472\n",
      "Loss after mini-batch   301: 7.829\n",
      "Loss after mini-batch   311: 11.374\n",
      "Loss after mini-batch   321: 0.546\n",
      "Loss after mini-batch   331: 3.167\n",
      "Loss after mini-batch   341: 35.023\n",
      "Loss after mini-batch   351: 0.645\n",
      "Loss after mini-batch   361: 0.606\n",
      "Loss after mini-batch   371: 2.167\n",
      "Training Loss: 0.339 \t\t Validation Loss:2.421\n",
      "Starting epoch 4\n",
      "Loss after mini-batch     1: 2.015\n",
      "Loss after mini-batch    11: 0.516\n",
      "Loss after mini-batch    21: 2.336\n",
      "Loss after mini-batch    31: 24.421\n",
      "Loss after mini-batch    41: 4.012\n",
      "Loss after mini-batch    51: 7.692\n",
      "Loss after mini-batch    61: 0.580\n",
      "Loss after mini-batch    71: 3.069\n",
      "Loss after mini-batch    81: 0.062\n",
      "Loss after mini-batch    91: 0.499\n",
      "Loss after mini-batch   101: 0.436\n",
      "Loss after mini-batch   111: 7.617\n",
      "Loss after mini-batch   121: 0.787\n",
      "Loss after mini-batch   131: 1.770\n",
      "Loss after mini-batch   141: 3.011\n",
      "Loss after mini-batch   151: 1.702\n",
      "Loss after mini-batch   161: 0.579\n",
      "Loss after mini-batch   171: 17.763\n",
      "Loss after mini-batch   181: 4.780\n",
      "Loss after mini-batch   191: 0.451\n",
      "Loss after mini-batch   201: 0.705\n",
      "Loss after mini-batch   211: 0.299\n",
      "Loss after mini-batch   221: 3.679\n",
      "Loss after mini-batch   231: 0.536\n",
      "Loss after mini-batch   241: 1.626\n",
      "Loss after mini-batch   251: 11.515\n",
      "Loss after mini-batch   261: 8.110\n",
      "Loss after mini-batch   271: 0.538\n",
      "Loss after mini-batch   281: 13.959\n",
      "Loss after mini-batch   291: 0.973\n",
      "Loss after mini-batch   301: 0.583\n",
      "Loss after mini-batch   311: 1.223\n",
      "Loss after mini-batch   321: 3.033\n",
      "Loss after mini-batch   331: 0.503\n",
      "Loss after mini-batch   341: 1.134\n",
      "Loss after mini-batch   351: 7.420\n",
      "Loss after mini-batch   361: 53.062\n",
      "Loss after mini-batch   371: 28.867\n",
      "Training Loss: 0.631 \t\t Validation Loss:5.384\n",
      "Starting epoch 5\n",
      "Loss after mini-batch     1: 8.858\n",
      "Loss after mini-batch    11: 0.589\n",
      "Loss after mini-batch    21: 14.369\n",
      "Loss after mini-batch    31: 0.431\n",
      "Loss after mini-batch    41: 6.612\n",
      "Loss after mini-batch    51: 7.209\n",
      "Loss after mini-batch    61: 22.252\n",
      "Loss after mini-batch    71: 3.329\n",
      "Loss after mini-batch    81: 0.933\n",
      "Loss after mini-batch    91: 0.883\n",
      "Loss after mini-batch   101: 0.863\n",
      "Loss after mini-batch   111: 13.766\n",
      "Loss after mini-batch   121: 11.992\n",
      "Loss after mini-batch   131: 1.123\n",
      "Loss after mini-batch   141: 0.585\n",
      "Loss after mini-batch   151: 9.066\n",
      "Loss after mini-batch   161: 1.188\n",
      "Loss after mini-batch   171: 19.240\n",
      "Loss after mini-batch   181: 6.367\n",
      "Loss after mini-batch   191: 25.432\n",
      "Loss after mini-batch   201: 5.133\n",
      "Loss after mini-batch   211: 2.397\n",
      "Loss after mini-batch   221: 22.660\n",
      "Loss after mini-batch   231: 0.536\n",
      "Loss after mini-batch   241: 0.692\n",
      "Loss after mini-batch   251: 24.606\n",
      "Loss after mini-batch   261: 6.499\n",
      "Loss after mini-batch   271: 1.726\n",
      "Loss after mini-batch   281: 7.083\n",
      "Loss after mini-batch   291: 0.505\n",
      "Loss after mini-batch   301: 2.087\n",
      "Loss after mini-batch   311: 7.271\n",
      "Loss after mini-batch   321: 0.673\n",
      "Loss after mini-batch   331: 3.117\n",
      "Loss after mini-batch   341: 0.468\n",
      "Loss after mini-batch   351: 0.397\n",
      "Loss after mini-batch   361: 1.852\n",
      "Loss after mini-batch   371: 4.735\n",
      "Training Loss: 2.811 \t\t Validation Loss:10.959\n",
      "Starting epoch 6\n",
      "Loss after mini-batch     1: 0.292\n",
      "Loss after mini-batch    11: 0.265\n",
      "Loss after mini-batch    21: 0.538\n",
      "Loss after mini-batch    31: 0.699\n",
      "Loss after mini-batch    41: 1.621\n",
      "Loss after mini-batch    51: 0.330\n",
      "Loss after mini-batch    61: 2.866\n",
      "Loss after mini-batch    71: 0.379\n",
      "Loss after mini-batch    81: 2.148\n",
      "Loss after mini-batch    91: 3.629\n",
      "Loss after mini-batch   101: 3.136\n",
      "Loss after mini-batch   111: 2.706\n",
      "Loss after mini-batch   121: 3.412\n",
      "Loss after mini-batch   131: 11.532\n",
      "Loss after mini-batch   141: 2.247\n",
      "Loss after mini-batch   151: 0.412\n",
      "Loss after mini-batch   161: 15.077\n",
      "Loss after mini-batch   171: 32.474\n",
      "Loss after mini-batch   181: 7.259\n",
      "Loss after mini-batch   191: 5.103\n",
      "Loss after mini-batch   201: 47.074\n",
      "Loss after mini-batch   211: 2.375\n",
      "Loss after mini-batch   221: 4.877\n",
      "Loss after mini-batch   231: 6.131\n",
      "Loss after mini-batch   241: 10.251\n",
      "Loss after mini-batch   251: 0.527\n",
      "Loss after mini-batch   261: 2.615\n",
      "Loss after mini-batch   271: 6.984\n",
      "Loss after mini-batch   281: 0.740\n",
      "Loss after mini-batch   291: 0.783\n",
      "Loss after mini-batch   301: 4.612\n",
      "Loss after mini-batch   311: 11.601\n",
      "Loss after mini-batch   321: 7.913\n",
      "Loss after mini-batch   331: 2.370\n",
      "Loss after mini-batch   341: 3.037\n",
      "Loss after mini-batch   351: 0.872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   361: 0.402\n",
      "Loss after mini-batch   371: 8.020\n",
      "Training Loss: 6.675 \t\t Validation Loss:10.744\n",
      "Starting epoch 7\n",
      "Loss after mini-batch     1: 0.312\n",
      "Loss after mini-batch    11: 0.616\n",
      "Loss after mini-batch    21: 0.540\n",
      "Loss after mini-batch    31: 0.554\n",
      "Loss after mini-batch    41: 25.472\n",
      "Loss after mini-batch    51: 18.799\n",
      "Loss after mini-batch    61: 3.261\n",
      "Loss after mini-batch    71: 1.000\n",
      "Loss after mini-batch    81: 0.603\n",
      "Loss after mini-batch    91: 1.872\n",
      "Loss after mini-batch   101: 15.573\n",
      "Loss after mini-batch   111: 0.705\n",
      "Loss after mini-batch   121: 5.949\n",
      "Loss after mini-batch   131: 0.393\n",
      "Loss after mini-batch   141: 14.682\n",
      "Loss after mini-batch   151: 0.736\n",
      "Loss after mini-batch   161: 0.682\n",
      "Loss after mini-batch   171: 10.006\n",
      "Loss after mini-batch   181: 0.992\n",
      "Loss after mini-batch   191: 0.489\n",
      "Loss after mini-batch   201: 0.493\n",
      "Loss after mini-batch   211: 10.507\n",
      "Loss after mini-batch   221: 13.735\n",
      "Loss after mini-batch   231: 0.637\n",
      "Loss after mini-batch   241: 1.638\n",
      "Loss after mini-batch   251: 1.587\n",
      "Loss after mini-batch   261: 0.538\n",
      "Loss after mini-batch   271: 0.680\n",
      "Loss after mini-batch   281: 5.183\n",
      "Loss after mini-batch   291: 0.670\n",
      "Loss after mini-batch   301: 0.770\n",
      "Loss after mini-batch   311: 0.473\n",
      "Loss after mini-batch   321: 13.148\n",
      "Loss after mini-batch   331: 0.556\n",
      "Loss after mini-batch   341: 29.005\n",
      "Loss after mini-batch   351: 0.404\n",
      "Loss after mini-batch   361: 7.162\n",
      "Loss after mini-batch   371: 0.704\n",
      "Training Loss: 2.034 \t\t Validation Loss:5.724\n",
      "Starting epoch 8\n",
      "Loss after mini-batch     1: 1.159\n",
      "Loss after mini-batch    11: 0.556\n",
      "Loss after mini-batch    21: 0.531\n",
      "Loss after mini-batch    31: 3.560\n",
      "Loss after mini-batch    41: 3.854\n",
      "Loss after mini-batch    51: 0.223\n",
      "Loss after mini-batch    61: 0.965\n",
      "Loss after mini-batch    71: 7.073\n",
      "Loss after mini-batch    81: 0.413\n",
      "Loss after mini-batch    91: 6.631\n",
      "Loss after mini-batch   101: 13.727\n",
      "Loss after mini-batch   111: 0.642\n",
      "Loss after mini-batch   121: 2.948\n",
      "Loss after mini-batch   131: 1.111\n",
      "Loss after mini-batch   141: 1.326\n",
      "Loss after mini-batch   151: 4.090\n",
      "Loss after mini-batch   161: 0.527\n",
      "Loss after mini-batch   171: 0.273\n",
      "Loss after mini-batch   181: 52.906\n",
      "Loss after mini-batch   191: 3.173\n",
      "Loss after mini-batch   201: 2.992\n",
      "Loss after mini-batch   211: 14.919\n",
      "Loss after mini-batch   221: 1.665\n",
      "Loss after mini-batch   231: 1.465\n",
      "Loss after mini-batch   241: 0.403\n",
      "Loss after mini-batch   251: 8.453\n",
      "Loss after mini-batch   261: 15.747\n",
      "Loss after mini-batch   271: 6.303\n",
      "Loss after mini-batch   281: 7.465\n",
      "Loss after mini-batch   291: 0.273\n",
      "Loss after mini-batch   301: 8.164\n",
      "Loss after mini-batch   311: 23.442\n",
      "Loss after mini-batch   321: 1.533\n",
      "Loss after mini-batch   331: 0.514\n",
      "Loss after mini-batch   341: 5.121\n",
      "Loss after mini-batch   351: 0.928\n",
      "Loss after mini-batch   361: 39.393\n",
      "Loss after mini-batch   371: 7.516\n",
      "Training Loss: 2.330 \t\t Validation Loss:3.008\n",
      "Starting epoch 9\n",
      "Loss after mini-batch     1: 4.741\n",
      "Loss after mini-batch    11: 24.951\n",
      "Loss after mini-batch    21: 0.696\n",
      "Loss after mini-batch    31: 0.404\n",
      "Loss after mini-batch    41: 1.085\n",
      "Loss after mini-batch    51: 1.190\n",
      "Loss after mini-batch    61: 6.775\n",
      "Loss after mini-batch    71: 2.281\n",
      "Loss after mini-batch    81: 0.431\n",
      "Loss after mini-batch    91: 1.556\n",
      "Loss after mini-batch   101: 14.834\n",
      "Loss after mini-batch   111: 2.972\n",
      "Loss after mini-batch   121: 0.372\n",
      "Loss after mini-batch   131: 0.219\n",
      "Loss after mini-batch   141: 28.383\n",
      "Loss after mini-batch   151: 0.578\n",
      "Loss after mini-batch   161: 0.234\n",
      "Loss after mini-batch   171: 2.074\n",
      "Loss after mini-batch   181: 22.282\n",
      "Loss after mini-batch   191: 28.793\n",
      "Loss after mini-batch   201: 0.065\n",
      "Loss after mini-batch   211: 0.436\n",
      "Loss after mini-batch   221: 1.550\n",
      "Loss after mini-batch   231: 7.374\n",
      "Loss after mini-batch   241: 0.339\n",
      "Loss after mini-batch   251: 0.454\n",
      "Loss after mini-batch   261: 5.928\n",
      "Loss after mini-batch   271: 19.345\n",
      "Loss after mini-batch   281: 18.528\n",
      "Loss after mini-batch   291: 0.732\n",
      "Loss after mini-batch   301: 5.806\n",
      "Loss after mini-batch   311: 0.737\n",
      "Loss after mini-batch   321: 13.541\n",
      "Loss after mini-batch   331: 0.463\n",
      "Loss after mini-batch   341: 1.134\n",
      "Loss after mini-batch   351: 18.320\n",
      "Loss after mini-batch   361: 1.679\n",
      "Loss after mini-batch   371: 0.404\n",
      "Training Loss: 1.375 \t\t Validation Loss:3.397\n",
      "Starting epoch 10\n",
      "Loss after mini-batch     1: 0.462\n",
      "Loss after mini-batch    11: 0.281\n",
      "Loss after mini-batch    21: 0.584\n",
      "Loss after mini-batch    31: 1.211\n",
      "Loss after mini-batch    41: 0.261\n",
      "Loss after mini-batch    51: 1.566\n",
      "Loss after mini-batch    61: 6.709\n",
      "Loss after mini-batch    71: 14.806\n",
      "Loss after mini-batch    81: 1.972\n",
      "Loss after mini-batch    91: 0.559\n",
      "Loss after mini-batch   101: 13.387\n",
      "Loss after mini-batch   111: 0.770\n",
      "Loss after mini-batch   121: 0.936\n",
      "Loss after mini-batch   131: 5.033\n",
      "Loss after mini-batch   141: 1.542\n",
      "Loss after mini-batch   151: 4.758\n",
      "Loss after mini-batch   161: 7.594\n",
      "Loss after mini-batch   171: 0.853\n",
      "Loss after mini-batch   181: 0.855\n",
      "Loss after mini-batch   191: 4.973\n",
      "Loss after mini-batch   201: 0.704\n",
      "Loss after mini-batch   211: 0.734\n",
      "Loss after mini-batch   221: 3.966\n",
      "Loss after mini-batch   231: 0.355\n",
      "Loss after mini-batch   241: 3.868\n",
      "Loss after mini-batch   251: 0.687\n",
      "Loss after mini-batch   261: 0.612\n",
      "Loss after mini-batch   271: 17.996\n",
      "Loss after mini-batch   281: 0.681\n",
      "Loss after mini-batch   291: 0.717\n",
      "Loss after mini-batch   301: 0.065\n",
      "Loss after mini-batch   311: 7.802\n",
      "Loss after mini-batch   321: 0.457\n",
      "Loss after mini-batch   331: 0.557\n",
      "Loss after mini-batch   341: 4.757\n",
      "Loss after mini-batch   351: 0.701\n",
      "Loss after mini-batch   361: 2.946\n",
      "Loss after mini-batch   371: 0.194\n",
      "Training Loss: 35.342 \t\t Validation Loss:39.788\n",
      "Starting epoch 11\n",
      "Loss after mini-batch     1: 10.456\n",
      "Loss after mini-batch    11: 2.271\n",
      "Loss after mini-batch    21: 65.947\n",
      "Loss after mini-batch    31: 10.189\n",
      "Loss after mini-batch    41: 0.611\n",
      "Loss after mini-batch    51: 12.544\n",
      "Loss after mini-batch    61: 0.830\n",
      "Loss after mini-batch    71: 0.866\n",
      "Loss after mini-batch    81: 3.487\n",
      "Loss after mini-batch    91: 1.226\n",
      "Loss after mini-batch   101: 7.883\n",
      "Loss after mini-batch   111: 0.769\n",
      "Loss after mini-batch   121: 1.751\n",
      "Loss after mini-batch   131: 0.594\n",
      "Loss after mini-batch   141: 0.371\n",
      "Loss after mini-batch   151: 0.646\n",
      "Loss after mini-batch   161: 0.379\n",
      "Loss after mini-batch   171: 0.418\n",
      "Loss after mini-batch   181: 0.575\n",
      "Loss after mini-batch   191: 9.213\n",
      "Loss after mini-batch   201: 8.664\n",
      "Loss after mini-batch   211: 7.001\n",
      "Loss after mini-batch   221: 0.352\n",
      "Loss after mini-batch   231: 31.304\n",
      "Loss after mini-batch   241: 0.347\n",
      "Loss after mini-batch   251: 0.547\n",
      "Loss after mini-batch   261: 1.384\n",
      "Loss after mini-batch   271: 32.512\n",
      "Loss after mini-batch   281: 2.019\n",
      "Loss after mini-batch   291: 0.866\n",
      "Loss after mini-batch   301: 1.056\n",
      "Loss after mini-batch   311: 0.398\n",
      "Loss after mini-batch   321: 0.747\n",
      "Loss after mini-batch   331: 2.521\n",
      "Loss after mini-batch   341: 0.658\n",
      "Loss after mini-batch   351: 0.850\n",
      "Loss after mini-batch   361: 0.518\n",
      "Loss after mini-batch   371: 0.280\n",
      "Training Loss: 6.081 \t\t Validation Loss:6.584\n",
      "Starting epoch 12\n",
      "Loss after mini-batch     1: 0.730\n",
      "Loss after mini-batch    11: 10.369\n",
      "Loss after mini-batch    21: 1.523\n",
      "Loss after mini-batch    31: 0.344\n",
      "Loss after mini-batch    41: 0.321\n",
      "Loss after mini-batch    51: 4.406\n",
      "Loss after mini-batch    61: 0.652\n",
      "Loss after mini-batch    71: 8.079\n",
      "Loss after mini-batch    81: 0.449\n",
      "Loss after mini-batch    91: 0.804\n",
      "Loss after mini-batch   101: 1.642\n",
      "Loss after mini-batch   111: 13.103\n",
      "Loss after mini-batch   121: 0.578\n",
      "Loss after mini-batch   131: 0.310\n",
      "Loss after mini-batch   141: 0.452\n",
      "Loss after mini-batch   151: 0.156\n",
      "Loss after mini-batch   161: 0.406\n",
      "Loss after mini-batch   171: 1.039\n",
      "Loss after mini-batch   181: 0.471\n",
      "Loss after mini-batch   191: 0.823\n",
      "Loss after mini-batch   201: 0.506\n",
      "Loss after mini-batch   211: 3.356\n",
      "Loss after mini-batch   221: 13.919\n",
      "Loss after mini-batch   231: 0.356\n",
      "Loss after mini-batch   241: 2.309\n",
      "Loss after mini-batch   251: 0.685\n",
      "Loss after mini-batch   261: 0.609\n",
      "Loss after mini-batch   271: 7.438\n",
      "Loss after mini-batch   281: 0.267\n",
      "Loss after mini-batch   291: 0.837\n",
      "Loss after mini-batch   301: 2.060\n",
      "Loss after mini-batch   311: 0.228\n",
      "Loss after mini-batch   321: 0.431\n",
      "Loss after mini-batch   331: 30.096\n",
      "Loss after mini-batch   341: 47.273\n",
      "Loss after mini-batch   351: 1.085\n",
      "Loss after mini-batch   361: 0.251\n",
      "Loss after mini-batch   371: 0.645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.858 \t\t Validation Loss:1.423\n",
      "Starting epoch 13\n",
      "Loss after mini-batch     1: 0.835\n",
      "Loss after mini-batch    11: 1.659\n",
      "Loss after mini-batch    21: 1.230\n",
      "Loss after mini-batch    31: 1.166\n",
      "Loss after mini-batch    41: 0.508\n",
      "Loss after mini-batch    51: 0.674\n",
      "Loss after mini-batch    61: 1.273\n",
      "Loss after mini-batch    71: 0.579\n",
      "Loss after mini-batch    81: 0.511\n",
      "Loss after mini-batch    91: 9.017\n",
      "Loss after mini-batch   101: 0.651\n",
      "Loss after mini-batch   111: 25.325\n",
      "Loss after mini-batch   121: 1.933\n",
      "Loss after mini-batch   131: 3.112\n",
      "Loss after mini-batch   141: 7.063\n",
      "Loss after mini-batch   151: 8.162\n",
      "Loss after mini-batch   161: 5.256\n",
      "Loss after mini-batch   171: 0.536\n",
      "Loss after mini-batch   181: 0.593\n",
      "Loss after mini-batch   191: 0.698\n",
      "Loss after mini-batch   201: 0.483\n",
      "Loss after mini-batch   211: 0.215\n",
      "Loss after mini-batch   221: 17.962\n",
      "Loss after mini-batch   231: 1.831\n",
      "Loss after mini-batch   241: 0.552\n",
      "Loss after mini-batch   251: 2.408\n",
      "Loss after mini-batch   261: 4.796\n",
      "Loss after mini-batch   271: 0.519\n",
      "Loss after mini-batch   281: 0.245\n",
      "Loss after mini-batch   291: 3.160\n",
      "Loss after mini-batch   301: 0.914\n",
      "Loss after mini-batch   311: 2.574\n",
      "Loss after mini-batch   321: 18.862\n",
      "Loss after mini-batch   331: 0.651\n",
      "Loss after mini-batch   341: 0.403\n",
      "Loss after mini-batch   351: 28.417\n",
      "Loss after mini-batch   361: 17.093\n",
      "Loss after mini-batch   371: 0.545\n",
      "Training Loss: 0.945 \t\t Validation Loss:5.280\n",
      "Starting epoch 14\n",
      "Loss after mini-batch     1: 1.520\n",
      "Loss after mini-batch    11: 0.687\n",
      "Loss after mini-batch    21: 1.525\n",
      "Loss after mini-batch    31: 0.675\n",
      "Loss after mini-batch    41: 1.508\n",
      "Loss after mini-batch    51: 4.921\n",
      "Loss after mini-batch    61: 0.445\n",
      "Loss after mini-batch    71: 0.631\n",
      "Loss after mini-batch    81: 3.451\n",
      "Loss after mini-batch    91: 7.218\n",
      "Loss after mini-batch   101: 0.073\n",
      "Loss after mini-batch   111: 0.545\n",
      "Loss after mini-batch   121: 0.886\n",
      "Loss after mini-batch   131: 0.663\n",
      "Loss after mini-batch   141: 6.766\n",
      "Loss after mini-batch   151: 3.296\n",
      "Loss after mini-batch   161: 0.702\n",
      "Loss after mini-batch   171: 1.946\n",
      "Loss after mini-batch   181: 1.803\n",
      "Loss after mini-batch   191: 0.663\n",
      "Loss after mini-batch   201: 0.534\n",
      "Loss after mini-batch   211: 0.972\n",
      "Loss after mini-batch   221: 1.846\n",
      "Loss after mini-batch   231: 13.051\n",
      "Loss after mini-batch   241: 12.461\n",
      "Loss after mini-batch   251: 38.026\n",
      "Loss after mini-batch   261: 2.459\n",
      "Loss after mini-batch   271: 0.826\n",
      "Loss after mini-batch   281: 32.766\n",
      "Loss after mini-batch   291: 0.652\n",
      "Loss after mini-batch   301: 32.034\n",
      "Loss after mini-batch   311: 0.708\n",
      "Loss after mini-batch   321: 0.541\n",
      "Loss after mini-batch   331: 0.429\n",
      "Loss after mini-batch   341: 0.115\n",
      "Loss after mini-batch   351: 11.279\n",
      "Loss after mini-batch   361: 0.433\n",
      "Loss after mini-batch   371: 2.733\n",
      "Training Loss: 6.516 \t\t Validation Loss:11.371\n",
      "Starting epoch 15\n",
      "Loss after mini-batch     1: 0.481\n",
      "Loss after mini-batch    11: 0.238\n",
      "Loss after mini-batch    21: 8.551\n",
      "Loss after mini-batch    31: 8.795\n",
      "Loss after mini-batch    41: 0.314\n",
      "Loss after mini-batch    51: 1.792\n",
      "Loss after mini-batch    61: 0.489\n",
      "Loss after mini-batch    71: 6.948\n",
      "Loss after mini-batch    81: 0.398\n",
      "Loss after mini-batch    91: 0.650\n",
      "Loss after mini-batch   101: 0.316\n",
      "Loss after mini-batch   111: 0.474\n",
      "Loss after mini-batch   121: 0.355\n",
      "Loss after mini-batch   131: 6.844\n",
      "Loss after mini-batch   141: 6.224\n",
      "Loss after mini-batch   151: 7.453\n",
      "Loss after mini-batch   161: 3.106\n",
      "Loss after mini-batch   171: 0.711\n",
      "Loss after mini-batch   181: 0.385\n",
      "Loss after mini-batch   191: 4.847\n",
      "Loss after mini-batch   201: 0.265\n",
      "Loss after mini-batch   211: 0.579\n",
      "Loss after mini-batch   221: 10.268\n",
      "Loss after mini-batch   231: 2.233\n",
      "Loss after mini-batch   241: 24.777\n",
      "Loss after mini-batch   251: 1.098\n",
      "Loss after mini-batch   261: 1.161\n",
      "Loss after mini-batch   271: 3.791\n",
      "Loss after mini-batch   281: 9.313\n",
      "Loss after mini-batch   291: 5.742\n",
      "Loss after mini-batch   301: 0.184\n",
      "Loss after mini-batch   311: 15.658\n",
      "Loss after mini-batch   321: 0.343\n",
      "Loss after mini-batch   331: 14.391\n",
      "Loss after mini-batch   341: 0.480\n",
      "Loss after mini-batch   351: 15.386\n",
      "Loss after mini-batch   361: 31.953\n",
      "Loss after mini-batch   371: 17.807\n",
      "Training Loss: 0.373 \t\t Validation Loss:0.808\n",
      "Starting epoch 16\n",
      "Loss after mini-batch     1: 0.654\n",
      "Loss after mini-batch    11: 2.378\n",
      "Loss after mini-batch    21: 0.538\n",
      "Loss after mini-batch    31: 1.530\n",
      "Loss after mini-batch    41: 0.639\n",
      "Loss after mini-batch    51: 48.365\n",
      "Loss after mini-batch    61: 0.449\n",
      "Loss after mini-batch    71: 0.650\n",
      "Loss after mini-batch    81: 8.712\n",
      "Loss after mini-batch    91: 8.531\n",
      "Loss after mini-batch   101: 8.529\n",
      "Loss after mini-batch   111: 1.341\n",
      "Loss after mini-batch   121: 15.365\n",
      "Loss after mini-batch   131: 0.644\n",
      "Loss after mini-batch   141: 0.492\n",
      "Loss after mini-batch   151: 27.858\n",
      "Loss after mini-batch   161: 10.952\n",
      "Loss after mini-batch   171: 1.079\n",
      "Loss after mini-batch   181: 0.485\n",
      "Loss after mini-batch   191: 1.000\n",
      "Loss after mini-batch   201: 0.856\n",
      "Loss after mini-batch   211: 2.923\n",
      "Loss after mini-batch   221: 10.037\n",
      "Loss after mini-batch   231: 0.898\n",
      "Loss after mini-batch   241: 9.776\n",
      "Loss after mini-batch   251: 0.803\n",
      "Loss after mini-batch   261: 15.339\n",
      "Loss after mini-batch   271: 8.967\n",
      "Loss after mini-batch   281: 0.440\n",
      "Loss after mini-batch   291: 0.527\n",
      "Loss after mini-batch   301: 0.441\n",
      "Loss after mini-batch   311: 1.052\n",
      "Loss after mini-batch   321: 2.134\n",
      "Loss after mini-batch   331: 0.452\n",
      "Loss after mini-batch   341: 16.321\n",
      "Loss after mini-batch   351: 10.516\n",
      "Loss after mini-batch   361: 0.220\n",
      "Loss after mini-batch   371: 0.299\n",
      "Training Loss: 0.218 \t\t Validation Loss:1.301\n",
      "Starting epoch 17\n",
      "Loss after mini-batch     1: 0.387\n",
      "Loss after mini-batch    11: 2.659\n",
      "Loss after mini-batch    21: 0.514\n",
      "Loss after mini-batch    31: 14.829\n",
      "Loss after mini-batch    41: 1.110\n",
      "Loss after mini-batch    51: 0.958\n",
      "Loss after mini-batch    61: 1.573\n",
      "Loss after mini-batch    71: 4.587\n",
      "Loss after mini-batch    81: 0.412\n",
      "Loss after mini-batch    91: 13.657\n",
      "Loss after mini-batch   101: 0.686\n",
      "Loss after mini-batch   111: 0.900\n",
      "Loss after mini-batch   121: 7.222\n",
      "Loss after mini-batch   131: 0.437\n",
      "Loss after mini-batch   141: 0.595\n",
      "Loss after mini-batch   151: 0.285\n",
      "Loss after mini-batch   161: 10.483\n",
      "Loss after mini-batch   171: 2.481\n",
      "Loss after mini-batch   181: 10.464\n",
      "Loss after mini-batch   191: 2.651\n",
      "Loss after mini-batch   201: 0.742\n",
      "Loss after mini-batch   211: 4.879\n",
      "Loss after mini-batch   221: 2.682\n",
      "Loss after mini-batch   231: 0.488\n",
      "Loss after mini-batch   241: 0.451\n",
      "Loss after mini-batch   251: 0.500\n",
      "Loss after mini-batch   261: 5.631\n",
      "Loss after mini-batch   271: 18.700\n",
      "Loss after mini-batch   281: 4.701\n",
      "Loss after mini-batch   291: 0.707\n",
      "Loss after mini-batch   301: 0.099\n",
      "Loss after mini-batch   311: 1.382\n",
      "Loss after mini-batch   321: 7.831\n",
      "Loss after mini-batch   331: 1.862\n",
      "Loss after mini-batch   341: 2.438\n",
      "Loss after mini-batch   351: 4.084\n",
      "Loss after mini-batch   361: 1.012\n",
      "Loss after mini-batch   371: 0.198\n",
      "Training Loss: 6.213 \t\t Validation Loss:8.655\n",
      "Starting epoch 18\n",
      "Loss after mini-batch     1: 0.287\n",
      "Loss after mini-batch    11: 0.531\n",
      "Loss after mini-batch    21: 6.323\n",
      "Loss after mini-batch    31: 0.414\n",
      "Loss after mini-batch    41: 5.036\n",
      "Loss after mini-batch    51: 0.762\n",
      "Loss after mini-batch    61: 4.846\n",
      "Loss after mini-batch    71: 38.140\n",
      "Loss after mini-batch    81: 0.328\n",
      "Loss after mini-batch    91: 2.818\n",
      "Loss after mini-batch   101: 0.366\n",
      "Loss after mini-batch   111: 1.749\n",
      "Loss after mini-batch   121: 4.019\n",
      "Loss after mini-batch   131: 0.559\n",
      "Loss after mini-batch   141: 31.619\n",
      "Loss after mini-batch   151: 18.427\n",
      "Loss after mini-batch   161: 0.298\n",
      "Loss after mini-batch   171: 3.201\n",
      "Loss after mini-batch   181: 0.940\n",
      "Loss after mini-batch   191: 13.772\n",
      "Loss after mini-batch   201: 1.635\n",
      "Loss after mini-batch   211: 0.440\n",
      "Loss after mini-batch   221: 7.972\n",
      "Loss after mini-batch   231: 8.825\n",
      "Loss after mini-batch   241: 1.300\n",
      "Loss after mini-batch   251: 0.335\n",
      "Loss after mini-batch   261: 1.799\n",
      "Loss after mini-batch   271: 0.459\n",
      "Loss after mini-batch   281: 3.149\n",
      "Loss after mini-batch   291: 2.083\n",
      "Loss after mini-batch   301: 0.551\n",
      "Loss after mini-batch   311: 0.475\n",
      "Loss after mini-batch   321: 2.490\n",
      "Loss after mini-batch   331: 22.064\n",
      "Loss after mini-batch   341: 4.875\n",
      "Loss after mini-batch   351: 0.271\n",
      "Loss after mini-batch   361: 0.242\n",
      "Loss after mini-batch   371: 35.901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.249 \t\t Validation Loss:2.175\n",
      "Starting epoch 19\n",
      "Loss after mini-batch     1: 2.976\n",
      "Loss after mini-batch    11: 0.485\n",
      "Loss after mini-batch    21: 31.497\n",
      "Loss after mini-batch    31: 1.024\n",
      "Loss after mini-batch    41: 13.391\n",
      "Loss after mini-batch    51: 2.522\n",
      "Loss after mini-batch    61: 2.870\n",
      "Loss after mini-batch    71: 2.785\n",
      "Loss after mini-batch    81: 0.262\n",
      "Loss after mini-batch    91: 3.519\n",
      "Loss after mini-batch   101: 0.291\n",
      "Loss after mini-batch   111: 5.959\n",
      "Loss after mini-batch   121: 0.303\n",
      "Loss after mini-batch   131: 4.712\n",
      "Loss after mini-batch   141: 8.319\n",
      "Loss after mini-batch   151: 0.407\n",
      "Loss after mini-batch   161: 2.607\n",
      "Loss after mini-batch   171: 0.265\n",
      "Loss after mini-batch   181: 3.058\n",
      "Loss after mini-batch   191: 10.680\n",
      "Loss after mini-batch   201: 14.379\n",
      "Loss after mini-batch   211: 2.784\n",
      "Loss after mini-batch   221: 10.557\n",
      "Loss after mini-batch   231: 0.237\n",
      "Loss after mini-batch   241: 0.755\n",
      "Loss after mini-batch   251: 0.701\n",
      "Loss after mini-batch   261: 7.023\n",
      "Loss after mini-batch   271: 0.238\n",
      "Loss after mini-batch   281: 8.438\n",
      "Loss after mini-batch   291: 0.740\n",
      "Loss after mini-batch   301: 10.322\n",
      "Loss after mini-batch   311: 7.516\n",
      "Loss after mini-batch   321: 0.497\n",
      "Loss after mini-batch   331: 1.176\n",
      "Loss after mini-batch   341: 0.515\n",
      "Loss after mini-batch   351: 4.569\n",
      "Loss after mini-batch   361: 4.379\n",
      "Loss after mini-batch   371: 37.151\n",
      "Training Loss: 12.586 \t\t Validation Loss:13.061\n",
      "Starting epoch 20\n",
      "Loss after mini-batch     1: 3.432\n",
      "Loss after mini-batch    11: 3.100\n",
      "Loss after mini-batch    21: 2.961\n",
      "Loss after mini-batch    31: 2.773\n",
      "Loss after mini-batch    41: 8.139\n",
      "Loss after mini-batch    51: 0.328\n",
      "Loss after mini-batch    61: 14.691\n",
      "Loss after mini-batch    71: 18.085\n",
      "Loss after mini-batch    81: 0.597\n",
      "Loss after mini-batch    91: 2.123\n",
      "Loss after mini-batch   101: 0.389\n",
      "Loss after mini-batch   111: 0.412\n",
      "Loss after mini-batch   121: 5.639\n",
      "Loss after mini-batch   131: 2.699\n",
      "Loss after mini-batch   141: 8.153\n",
      "Loss after mini-batch   151: 1.601\n",
      "Loss after mini-batch   161: 0.556\n",
      "Loss after mini-batch   171: 1.033\n",
      "Loss after mini-batch   181: 0.529\n",
      "Loss after mini-batch   191: 3.276\n",
      "Loss after mini-batch   201: 0.300\n",
      "Loss after mini-batch   211: 0.451\n",
      "Loss after mini-batch   221: 0.175\n",
      "Loss after mini-batch   231: 0.183\n",
      "Loss after mini-batch   241: 0.382\n",
      "Loss after mini-batch   251: 1.868\n",
      "Loss after mini-batch   261: 0.043\n",
      "Loss after mini-batch   271: 8.598\n",
      "Loss after mini-batch   281: 22.656\n",
      "Loss after mini-batch   291: 1.545\n",
      "Loss after mini-batch   301: 0.446\n",
      "Loss after mini-batch   311: 11.716\n",
      "Loss after mini-batch   321: 0.445\n",
      "Loss after mini-batch   331: 0.894\n",
      "Loss after mini-batch   341: 35.903\n",
      "Loss after mini-batch   351: 0.442\n",
      "Loss after mini-batch   361: 3.599\n",
      "Loss after mini-batch   371: 14.616\n",
      "Training Loss: 10.359 \t\t Validation Loss:10.758\n",
      "Starting epoch 21\n",
      "Loss after mini-batch     1: 0.832\n",
      "Loss after mini-batch    11: 8.419\n",
      "Loss after mini-batch    21: 0.462\n",
      "Loss after mini-batch    31: 0.714\n",
      "Loss after mini-batch    41: 0.452\n",
      "Loss after mini-batch    51: 6.135\n",
      "Loss after mini-batch    61: 18.535\n",
      "Loss after mini-batch    71: 0.572\n",
      "Loss after mini-batch    81: 1.134\n",
      "Loss after mini-batch    91: 17.149\n",
      "Loss after mini-batch   101: 27.886\n",
      "Loss after mini-batch   111: 5.705\n",
      "Loss after mini-batch   121: 1.455\n",
      "Loss after mini-batch   131: 0.429\n",
      "Loss after mini-batch   141: 28.175\n",
      "Loss after mini-batch   151: 7.818\n",
      "Loss after mini-batch   161: 2.699\n",
      "Loss after mini-batch   171: 1.388\n",
      "Loss after mini-batch   181: 0.449\n",
      "Loss after mini-batch   191: 1.110\n",
      "Loss after mini-batch   201: 11.068\n",
      "Loss after mini-batch   211: 9.516\n",
      "Loss after mini-batch   221: 5.473\n",
      "Loss after mini-batch   231: 1.856\n",
      "Loss after mini-batch   241: 0.555\n",
      "Loss after mini-batch   251: 0.581\n",
      "Loss after mini-batch   261: 0.211\n",
      "Loss after mini-batch   271: 18.756\n",
      "Loss after mini-batch   281: 7.030\n",
      "Loss after mini-batch   291: 0.124\n",
      "Loss after mini-batch   301: 6.318\n",
      "Loss after mini-batch   311: 5.009\n",
      "Loss after mini-batch   321: 6.252\n",
      "Loss after mini-batch   331: 0.292\n",
      "Loss after mini-batch   341: 0.440\n",
      "Loss after mini-batch   351: 0.453\n",
      "Loss after mini-batch   361: 2.555\n",
      "Loss after mini-batch   371: 7.833\n",
      "Training Loss: 2.755 \t\t Validation Loss:7.315\n",
      "Starting epoch 22\n",
      "Loss after mini-batch     1: 28.827\n",
      "Loss after mini-batch    11: 31.976\n",
      "Loss after mini-batch    21: 3.061\n",
      "Loss after mini-batch    31: 0.646\n",
      "Loss after mini-batch    41: 0.628\n",
      "Loss after mini-batch    51: 0.605\n",
      "Loss after mini-batch    61: 0.423\n",
      "Loss after mini-batch    71: 0.448\n",
      "Loss after mini-batch    81: 14.843\n",
      "Loss after mini-batch    91: 4.671\n",
      "Loss after mini-batch   101: 0.351\n",
      "Loss after mini-batch   111: 6.656\n",
      "Loss after mini-batch   121: 1.501\n",
      "Loss after mini-batch   131: 43.717\n",
      "Loss after mini-batch   141: 19.134\n",
      "Loss after mini-batch   151: 1.849\n",
      "Loss after mini-batch   161: 0.917\n",
      "Loss after mini-batch   171: 0.438\n",
      "Loss after mini-batch   181: 2.148\n",
      "Loss after mini-batch   191: 6.027\n",
      "Loss after mini-batch   201: 11.382\n",
      "Loss after mini-batch   211: 0.575\n",
      "Loss after mini-batch   221: 3.095\n",
      "Loss after mini-batch   231: 12.953\n",
      "Loss after mini-batch   241: 0.263\n",
      "Loss after mini-batch   251: 0.239\n",
      "Loss after mini-batch   261: 0.229\n",
      "Loss after mini-batch   271: 12.323\n",
      "Loss after mini-batch   281: 0.303\n",
      "Loss after mini-batch   291: 8.374\n",
      "Loss after mini-batch   301: 15.834\n",
      "Loss after mini-batch   311: 0.226\n",
      "Loss after mini-batch   321: 12.914\n",
      "Loss after mini-batch   331: 0.287\n",
      "Loss after mini-batch   341: 2.787\n",
      "Loss after mini-batch   351: 1.579\n",
      "Loss after mini-batch   361: 8.597\n",
      "Loss after mini-batch   371: 0.319\n",
      "Training Loss: 0.193 \t\t Validation Loss:1.162\n",
      "Starting epoch 23\n",
      "Loss after mini-batch     1: 0.914\n",
      "Loss after mini-batch    11: 6.651\n",
      "Loss after mini-batch    21: 2.893\n",
      "Loss after mini-batch    31: 7.312\n",
      "Loss after mini-batch    41: 0.585\n",
      "Loss after mini-batch    51: 6.968\n",
      "Loss after mini-batch    61: 13.190\n",
      "Loss after mini-batch    71: 0.699\n",
      "Loss after mini-batch    81: 0.710\n",
      "Loss after mini-batch    91: 7.582\n",
      "Loss after mini-batch   101: 0.374\n",
      "Loss after mini-batch   111: 0.526\n",
      "Loss after mini-batch   121: 0.389\n",
      "Loss after mini-batch   131: 0.579\n",
      "Loss after mini-batch   141: 0.600\n",
      "Loss after mini-batch   151: 10.992\n",
      "Loss after mini-batch   161: 0.580\n",
      "Loss after mini-batch   171: 2.158\n",
      "Loss after mini-batch   181: 0.400\n",
      "Loss after mini-batch   191: 1.417\n",
      "Loss after mini-batch   201: 16.775\n",
      "Loss after mini-batch   211: 0.316\n",
      "Loss after mini-batch   221: 7.450\n",
      "Loss after mini-batch   231: 6.815\n",
      "Loss after mini-batch   241: 9.722\n",
      "Loss after mini-batch   251: 2.057\n",
      "Loss after mini-batch   261: 3.814\n",
      "Loss after mini-batch   271: 0.374\n",
      "Loss after mini-batch   281: 1.887\n",
      "Loss after mini-batch   291: 31.113\n",
      "Loss after mini-batch   301: 0.359\n",
      "Loss after mini-batch   311: 0.412\n",
      "Loss after mini-batch   321: 0.656\n",
      "Loss after mini-batch   331: 11.995\n",
      "Loss after mini-batch   341: 1.029\n",
      "Loss after mini-batch   351: 1.590\n",
      "Loss after mini-batch   361: 8.678\n",
      "Loss after mini-batch   371: 1.710\n",
      "Training Loss: 8.356 \t\t Validation Loss:8.710\n",
      "Starting epoch 24\n",
      "Loss after mini-batch     1: 46.085\n",
      "Loss after mini-batch    11: 0.446\n",
      "Loss after mini-batch    21: 0.604\n",
      "Loss after mini-batch    31: 0.945\n",
      "Loss after mini-batch    41: 0.694\n",
      "Loss after mini-batch    51: 12.315\n",
      "Loss after mini-batch    61: 0.426\n",
      "Loss after mini-batch    71: 14.599\n",
      "Loss after mini-batch    81: 0.858\n",
      "Loss after mini-batch    91: 0.531\n",
      "Loss after mini-batch   101: 24.860\n",
      "Loss after mini-batch   111: 6.889\n",
      "Loss after mini-batch   121: 0.378\n",
      "Loss after mini-batch   131: 17.612\n",
      "Loss after mini-batch   141: 1.346\n",
      "Loss after mini-batch   151: 15.881\n",
      "Loss after mini-batch   161: 0.219\n",
      "Loss after mini-batch   171: 5.255\n",
      "Loss after mini-batch   181: 10.433\n",
      "Loss after mini-batch   191: 7.151\n",
      "Loss after mini-batch   201: 25.817\n",
      "Loss after mini-batch   211: 0.169\n",
      "Loss after mini-batch   221: 10.702\n",
      "Loss after mini-batch   231: 42.599\n",
      "Loss after mini-batch   241: 0.476\n",
      "Loss after mini-batch   251: 2.828\n",
      "Loss after mini-batch   261: 3.859\n",
      "Loss after mini-batch   271: 6.273\n",
      "Loss after mini-batch   281: 2.214\n",
      "Loss after mini-batch   291: 0.358\n",
      "Loss after mini-batch   301: 8.816\n",
      "Loss after mini-batch   311: 7.537\n",
      "Loss after mini-batch   321: 13.942\n",
      "Loss after mini-batch   331: 1.803\n",
      "Loss after mini-batch   341: 0.639\n",
      "Loss after mini-batch   351: 0.296\n",
      "Loss after mini-batch   361: 0.547\n",
      "Loss after mini-batch   371: 7.479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 6.526 \t\t Validation Loss:11.345\n",
      "Starting epoch 25\n",
      "Loss after mini-batch     1: 12.817\n",
      "Loss after mini-batch    11: 3.027\n",
      "Loss after mini-batch    21: 0.253\n",
      "Loss after mini-batch    31: 1.845\n",
      "Loss after mini-batch    41: 1.363\n",
      "Loss after mini-batch    51: 2.060\n",
      "Loss after mini-batch    61: 2.746\n",
      "Loss after mini-batch    71: 1.038\n",
      "Loss after mini-batch    81: 0.966\n",
      "Loss after mini-batch    91: 1.024\n",
      "Loss after mini-batch   101: 0.232\n",
      "Loss after mini-batch   111: 0.293\n",
      "Loss after mini-batch   121: 4.179\n",
      "Loss after mini-batch   131: 1.381\n",
      "Loss after mini-batch   141: 0.350\n",
      "Loss after mini-batch   151: 0.656\n",
      "Loss after mini-batch   161: 10.008\n",
      "Loss after mini-batch   171: 13.674\n",
      "Loss after mini-batch   181: 8.203\n",
      "Loss after mini-batch   191: 2.537\n",
      "Loss after mini-batch   201: 24.403\n",
      "Loss after mini-batch   211: 8.378\n",
      "Loss after mini-batch   221: 8.801\n",
      "Loss after mini-batch   231: 3.484\n",
      "Loss after mini-batch   241: 0.221\n",
      "Loss after mini-batch   251: 2.494\n",
      "Loss after mini-batch   261: 2.789\n",
      "Loss after mini-batch   271: 1.176\n",
      "Loss after mini-batch   281: 0.443\n",
      "Loss after mini-batch   291: 24.506\n",
      "Loss after mini-batch   301: 28.616\n",
      "Loss after mini-batch   311: 0.323\n",
      "Loss after mini-batch   321: 0.309\n",
      "Loss after mini-batch   331: 0.307\n",
      "Loss after mini-batch   341: 0.413\n",
      "Loss after mini-batch   351: 1.983\n",
      "Loss after mini-batch   361: 16.493\n",
      "Loss after mini-batch   371: 6.809\n",
      "Training Loss: 13.815 \t\t Validation Loss:14.368\n",
      "Starting epoch 26\n",
      "Loss after mini-batch     1: 2.864\n",
      "Loss after mini-batch    11: 0.246\n",
      "Loss after mini-batch    21: 3.380\n",
      "Loss after mini-batch    31: 0.292\n",
      "Loss after mini-batch    41: 13.058\n",
      "Loss after mini-batch    51: 6.492\n",
      "Loss after mini-batch    61: 0.292\n",
      "Loss after mini-batch    71: 0.228\n",
      "Loss after mini-batch    81: 16.858\n",
      "Loss after mini-batch    91: 0.572\n",
      "Loss after mini-batch   101: 1.181\n",
      "Loss after mini-batch   111: 0.310\n",
      "Loss after mini-batch   121: 4.342\n",
      "Loss after mini-batch   131: 0.556\n",
      "Loss after mini-batch   141: 5.702\n",
      "Loss after mini-batch   151: 0.683\n",
      "Loss after mini-batch   161: 7.893\n",
      "Loss after mini-batch   171: 2.557\n",
      "Loss after mini-batch   181: 0.487\n",
      "Loss after mini-batch   191: 0.243\n",
      "Loss after mini-batch   201: 0.293\n",
      "Loss after mini-batch   211: 28.952\n",
      "Loss after mini-batch   221: 0.365\n",
      "Loss after mini-batch   231: 0.624\n",
      "Loss after mini-batch   241: 1.299\n",
      "Loss after mini-batch   251: 0.342\n",
      "Loss after mini-batch   261: 9.723\n",
      "Loss after mini-batch   271: 0.560\n",
      "Loss after mini-batch   281: 28.433\n",
      "Loss after mini-batch   291: 0.279\n",
      "Loss after mini-batch   301: 0.543\n",
      "Loss after mini-batch   311: 0.386\n",
      "Loss after mini-batch   321: 8.237\n",
      "Loss after mini-batch   331: 6.698\n",
      "Loss after mini-batch   341: 0.164\n",
      "Loss after mini-batch   351: 0.310\n",
      "Loss after mini-batch   361: 12.803\n",
      "Loss after mini-batch   371: 0.341\n",
      "Training Loss: 8.213 \t\t Validation Loss:8.700\n",
      "Starting epoch 27\n",
      "Loss after mini-batch     1: 8.432\n",
      "Loss after mini-batch    11: 2.366\n",
      "Loss after mini-batch    21: 0.305\n",
      "Loss after mini-batch    31: 0.013\n",
      "Loss after mini-batch    41: 0.291\n",
      "Loss after mini-batch    51: 10.818\n",
      "Loss after mini-batch    61: 1.506\n",
      "Loss after mini-batch    71: 7.602\n",
      "Loss after mini-batch    81: 0.999\n",
      "Loss after mini-batch    91: 0.305\n",
      "Loss after mini-batch   101: 9.587\n",
      "Loss after mini-batch   111: 4.522\n",
      "Loss after mini-batch   121: 0.300\n",
      "Loss after mini-batch   131: 0.436\n",
      "Loss after mini-batch   141: 6.592\n",
      "Loss after mini-batch   151: 0.635\n",
      "Loss after mini-batch   161: 10.426\n",
      "Loss after mini-batch   171: 0.484\n",
      "Loss after mini-batch   181: 7.110\n",
      "Loss after mini-batch   191: 7.773\n",
      "Loss after mini-batch   201: 0.492\n",
      "Loss after mini-batch   211: 1.198\n",
      "Loss after mini-batch   221: 6.211\n",
      "Loss after mini-batch   231: 10.279\n",
      "Loss after mini-batch   241: 6.284\n",
      "Loss after mini-batch   251: 3.490\n",
      "Loss after mini-batch   261: 15.111\n",
      "Loss after mini-batch   271: 9.819\n",
      "Loss after mini-batch   281: 15.135\n",
      "Loss after mini-batch   291: 0.664\n",
      "Loss after mini-batch   301: 0.472\n",
      "Loss after mini-batch   311: 1.058\n",
      "Loss after mini-batch   321: 0.372\n",
      "Loss after mini-batch   331: 6.831\n",
      "Loss after mini-batch   341: 1.315\n",
      "Loss after mini-batch   351: 0.530\n",
      "Loss after mini-batch   361: 0.629\n",
      "Loss after mini-batch   371: 0.241\n",
      "Training Loss: 4.633 \t\t Validation Loss:5.046\n",
      "Starting epoch 28\n",
      "Loss after mini-batch     1: 3.742\n",
      "Loss after mini-batch    11: 2.091\n",
      "Loss after mini-batch    21: 0.415\n",
      "Loss after mini-batch    31: 7.094\n",
      "Loss after mini-batch    41: 0.368\n",
      "Loss after mini-batch    51: 0.352\n",
      "Loss after mini-batch    61: 3.814\n",
      "Loss after mini-batch    71: 0.409\n",
      "Loss after mini-batch    81: 8.063\n",
      "Loss after mini-batch    91: 0.231\n",
      "Loss after mini-batch   101: 0.246\n",
      "Loss after mini-batch   111: 0.398\n",
      "Loss after mini-batch   121: 0.420\n",
      "Loss after mini-batch   131: 2.720\n",
      "Loss after mini-batch   141: 0.552\n",
      "Loss after mini-batch   151: 2.045\n",
      "Loss after mini-batch   161: 0.286\n",
      "Loss after mini-batch   171: 0.158\n",
      "Loss after mini-batch   181: 0.151\n",
      "Loss after mini-batch   191: 11.249\n",
      "Loss after mini-batch   201: 0.157\n",
      "Loss after mini-batch   211: 0.551\n",
      "Loss after mini-batch   221: 2.062\n",
      "Loss after mini-batch   231: 0.278\n",
      "Loss after mini-batch   241: 2.723\n",
      "Loss after mini-batch   251: 1.635\n",
      "Loss after mini-batch   261: 1.073\n",
      "Loss after mini-batch   271: 0.401\n",
      "Loss after mini-batch   281: 1.648\n",
      "Loss after mini-batch   291: 1.919\n",
      "Loss after mini-batch   301: 20.238\n",
      "Loss after mini-batch   311: 0.145\n",
      "Loss after mini-batch   321: 6.381\n",
      "Loss after mini-batch   331: 16.548\n",
      "Loss after mini-batch   341: 9.917\n",
      "Loss after mini-batch   351: 0.112\n",
      "Loss after mini-batch   361: 6.994\n",
      "Loss after mini-batch   371: 0.774\n",
      "Training Loss: 7.152 \t\t Validation Loss:7.463\n",
      "Starting epoch 29\n",
      "Loss after mini-batch     1: 0.914\n",
      "Loss after mini-batch    11: 0.482\n",
      "Loss after mini-batch    21: 0.447\n",
      "Loss after mini-batch    31: 3.029\n",
      "Loss after mini-batch    41: 50.776\n",
      "Loss after mini-batch    51: 2.367\n",
      "Loss after mini-batch    61: 1.266\n",
      "Loss after mini-batch    71: 0.273\n",
      "Loss after mini-batch    81: 6.623\n",
      "Loss after mini-batch    91: 2.015\n",
      "Loss after mini-batch   101: 0.595\n",
      "Loss after mini-batch   111: 0.338\n",
      "Loss after mini-batch   121: 0.342\n",
      "Loss after mini-batch   131: 27.783\n",
      "Loss after mini-batch   141: 0.387\n",
      "Loss after mini-batch   151: 2.990\n",
      "Loss after mini-batch   161: 21.839\n",
      "Loss after mini-batch   171: 7.483\n",
      "Loss after mini-batch   181: 5.787\n",
      "Loss after mini-batch   191: 0.476\n",
      "Loss after mini-batch   201: 0.254\n",
      "Loss after mini-batch   211: 2.469\n",
      "Loss after mini-batch   221: 3.397\n",
      "Loss after mini-batch   231: 1.056\n",
      "Loss after mini-batch   241: 3.995\n",
      "Loss after mini-batch   251: 0.854\n",
      "Loss after mini-batch   261: 0.631\n",
      "Loss after mini-batch   271: 13.489\n",
      "Loss after mini-batch   281: 0.089\n",
      "Loss after mini-batch   291: 1.326\n",
      "Loss after mini-batch   301: 26.683\n",
      "Loss after mini-batch   311: 0.551\n",
      "Loss after mini-batch   321: 0.822\n",
      "Loss after mini-batch   331: 17.724\n",
      "Loss after mini-batch   341: 1.148\n",
      "Loss after mini-batch   351: 0.440\n",
      "Loss after mini-batch   361: 0.400\n",
      "Loss after mini-batch   371: 5.615\n",
      "Training Loss: 19.110 \t\t Validation Loss:20.342\n",
      "Starting epoch 30\n",
      "Loss after mini-batch     1: 0.414\n",
      "Loss after mini-batch    11: 2.224\n",
      "Loss after mini-batch    21: 0.276\n",
      "Loss after mini-batch    31: 28.537\n",
      "Loss after mini-batch    41: 12.729\n",
      "Loss after mini-batch    51: 0.844\n",
      "Loss after mini-batch    61: 1.968\n",
      "Loss after mini-batch    71: 0.275\n",
      "Loss after mini-batch    81: 0.380\n",
      "Loss after mini-batch    91: 2.246\n",
      "Loss after mini-batch   101: 0.300\n",
      "Loss after mini-batch   111: 0.425\n",
      "Loss after mini-batch   121: 13.585\n",
      "Loss after mini-batch   131: 0.119\n",
      "Loss after mini-batch   141: 26.785\n",
      "Loss after mini-batch   151: 0.564\n",
      "Loss after mini-batch   161: 4.858\n",
      "Loss after mini-batch   171: 4.376\n",
      "Loss after mini-batch   181: 1.027\n",
      "Loss after mini-batch   191: 0.333\n",
      "Loss after mini-batch   201: 0.455\n",
      "Loss after mini-batch   211: 1.403\n",
      "Loss after mini-batch   221: 2.476\n",
      "Loss after mini-batch   231: 2.263\n",
      "Loss after mini-batch   241: 6.701\n",
      "Loss after mini-batch   251: 3.340\n",
      "Loss after mini-batch   261: 0.183\n",
      "Loss after mini-batch   271: 0.283\n",
      "Loss after mini-batch   281: 8.226\n",
      "Loss after mini-batch   291: 0.792\n",
      "Loss after mini-batch   301: 0.410\n",
      "Loss after mini-batch   311: 1.586\n",
      "Loss after mini-batch   321: 19.050\n",
      "Loss after mini-batch   331: 3.088\n",
      "Loss after mini-batch   341: 6.955\n",
      "Loss after mini-batch   351: 17.667\n",
      "Loss after mini-batch   361: 0.484\n",
      "Loss after mini-batch   371: 8.195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.328 \t\t Validation Loss:1.423\n",
      "Starting epoch 31\n",
      "Loss after mini-batch     1: 5.797\n",
      "Loss after mini-batch    11: 0.193\n",
      "Loss after mini-batch    21: 0.255\n",
      "Loss after mini-batch    31: 0.067\n",
      "Loss after mini-batch    41: 6.807\n",
      "Loss after mini-batch    51: 7.114\n",
      "Loss after mini-batch    61: 21.453\n",
      "Loss after mini-batch    71: 7.303\n",
      "Loss after mini-batch    81: 0.237\n",
      "Loss after mini-batch    91: 10.617\n",
      "Loss after mini-batch   101: 0.351\n",
      "Loss after mini-batch   111: 1.261\n",
      "Loss after mini-batch   121: 2.783\n",
      "Loss after mini-batch   131: 8.855\n",
      "Loss after mini-batch   141: 0.429\n",
      "Loss after mini-batch   151: 0.211\n",
      "Loss after mini-batch   161: 0.859\n",
      "Loss after mini-batch   171: 1.553\n",
      "Loss after mini-batch   181: 3.346\n",
      "Loss after mini-batch   191: 0.577\n",
      "Loss after mini-batch   201: 0.489\n",
      "Loss after mini-batch   211: 6.658\n",
      "Loss after mini-batch   221: 0.762\n",
      "Loss after mini-batch   231: 0.361\n",
      "Loss after mini-batch   241: 27.737\n",
      "Loss after mini-batch   251: 0.184\n",
      "Loss after mini-batch   261: 0.263\n",
      "Loss after mini-batch   271: 15.529\n",
      "Loss after mini-batch   281: 12.162\n",
      "Loss after mini-batch   291: 0.266\n",
      "Loss after mini-batch   301: 0.440\n",
      "Loss after mini-batch   311: 23.851\n",
      "Loss after mini-batch   321: 15.131\n",
      "Loss after mini-batch   331: 6.274\n",
      "Loss after mini-batch   341: 0.191\n",
      "Loss after mini-batch   351: 0.200\n",
      "Loss after mini-batch   361: 0.218\n",
      "Loss after mini-batch   371: 1.675\n",
      "Training Loss: 12.903 \t\t Validation Loss:13.247\n",
      "Starting epoch 32\n",
      "Loss after mini-batch     1: 2.884\n",
      "Loss after mini-batch    11: 0.432\n",
      "Loss after mini-batch    21: 2.232\n",
      "Loss after mini-batch    31: 7.080\n",
      "Loss after mini-batch    41: 8.086\n",
      "Loss after mini-batch    51: 13.200\n",
      "Loss after mini-batch    61: 0.640\n",
      "Loss after mini-batch    71: 37.055\n",
      "Loss after mini-batch    81: 1.685\n",
      "Loss after mini-batch    91: 0.514\n",
      "Loss after mini-batch   101: 0.376\n",
      "Loss after mini-batch   111: 0.287\n",
      "Loss after mini-batch   121: 7.629\n",
      "Loss after mini-batch   131: 12.065\n",
      "Loss after mini-batch   141: 6.638\n",
      "Loss after mini-batch   151: 1.229\n",
      "Loss after mini-batch   161: 0.139\n",
      "Loss after mini-batch   171: 0.146\n",
      "Loss after mini-batch   181: 17.094\n",
      "Loss after mini-batch   191: 1.741\n",
      "Loss after mini-batch   201: 19.235\n",
      "Loss after mini-batch   211: 0.325\n",
      "Loss after mini-batch   221: 0.976\n",
      "Loss after mini-batch   231: 0.252\n",
      "Loss after mini-batch   241: 2.446\n",
      "Loss after mini-batch   251: 0.158\n",
      "Loss after mini-batch   261: 0.343\n",
      "Loss after mini-batch   271: 6.684\n",
      "Loss after mini-batch   281: 20.907\n",
      "Loss after mini-batch   291: 0.292\n",
      "Loss after mini-batch   301: 2.561\n",
      "Loss after mini-batch   311: 10.256\n",
      "Loss after mini-batch   321: 0.342\n",
      "Loss after mini-batch   331: 0.391\n",
      "Loss after mini-batch   341: 0.436\n",
      "Loss after mini-batch   351: 0.364\n",
      "Loss after mini-batch   361: 0.118\n",
      "Loss after mini-batch   371: 0.640\n",
      "Training Loss: 2.960 \t\t Validation Loss:3.198\n",
      "Starting epoch 33\n",
      "Loss after mini-batch     1: 0.852\n",
      "Loss after mini-batch    11: 0.127\n",
      "Loss after mini-batch    21: 0.023\n",
      "Loss after mini-batch    31: 0.280\n",
      "Loss after mini-batch    41: 7.654\n",
      "Loss after mini-batch    51: 0.265\n",
      "Loss after mini-batch    61: 1.479\n",
      "Loss after mini-batch    71: 1.226\n",
      "Loss after mini-batch    81: 0.329\n",
      "Loss after mini-batch    91: 0.066\n",
      "Loss after mini-batch   101: 13.081\n",
      "Loss after mini-batch   111: 1.642\n",
      "Loss after mini-batch   121: 1.203\n",
      "Loss after mini-batch   131: 3.249\n",
      "Loss after mini-batch   141: 0.975\n",
      "Loss after mini-batch   151: 0.282\n",
      "Loss after mini-batch   161: 0.575\n",
      "Loss after mini-batch   171: 0.465\n",
      "Loss after mini-batch   181: 0.877\n",
      "Loss after mini-batch   191: 6.433\n",
      "Loss after mini-batch   201: 13.383\n",
      "Loss after mini-batch   211: 0.177\n",
      "Loss after mini-batch   221: 12.409\n",
      "Loss after mini-batch   231: 9.242\n",
      "Loss after mini-batch   241: 5.387\n",
      "Loss after mini-batch   251: 13.290\n",
      "Loss after mini-batch   261: 1.006\n",
      "Loss after mini-batch   271: 0.529\n",
      "Loss after mini-batch   281: 0.347\n",
      "Loss after mini-batch   291: 0.326\n",
      "Loss after mini-batch   301: 13.003\n",
      "Loss after mini-batch   311: 0.370\n",
      "Loss after mini-batch   321: 0.278\n",
      "Loss after mini-batch   331: 9.022\n",
      "Loss after mini-batch   341: 2.477\n",
      "Loss after mini-batch   351: 2.322\n",
      "Loss after mini-batch   361: 0.198\n",
      "Loss after mini-batch   371: 0.166\n",
      "Training Loss: 0.250 \t\t Validation Loss:0.516\n",
      "Starting epoch 34\n",
      "Loss after mini-batch     1: 1.911\n",
      "Loss after mini-batch    11: 0.487\n",
      "Loss after mini-batch    21: 2.749\n",
      "Loss after mini-batch    31: 36.673\n",
      "Loss after mini-batch    41: 0.471\n",
      "Loss after mini-batch    51: 17.733\n",
      "Loss after mini-batch    61: 0.724\n",
      "Loss after mini-batch    71: 0.239\n",
      "Loss after mini-batch    81: 0.457\n",
      "Loss after mini-batch    91: 0.331\n",
      "Loss after mini-batch   101: 0.256\n",
      "Loss after mini-batch   111: 8.745\n",
      "Loss after mini-batch   121: 25.419\n",
      "Loss after mini-batch   131: 4.639\n",
      "Loss after mini-batch   141: 0.583\n",
      "Loss after mini-batch   151: 11.887\n",
      "Loss after mini-batch   161: 0.241\n",
      "Loss after mini-batch   171: 0.235\n",
      "Loss after mini-batch   181: 0.292\n",
      "Loss after mini-batch   191: 5.129\n",
      "Loss after mini-batch   201: 0.983\n",
      "Loss after mini-batch   211: 7.503\n",
      "Loss after mini-batch   221: 0.334\n",
      "Loss after mini-batch   231: 1.633\n",
      "Loss after mini-batch   241: 4.072\n",
      "Loss after mini-batch   251: 7.037\n",
      "Loss after mini-batch   261: 2.461\n",
      "Loss after mini-batch   271: 12.755\n",
      "Loss after mini-batch   281: 3.991\n",
      "Loss after mini-batch   291: 0.737\n",
      "Loss after mini-batch   301: 0.864\n",
      "Loss after mini-batch   311: 31.864\n",
      "Loss after mini-batch   321: 0.171\n",
      "Loss after mini-batch   331: 3.370\n",
      "Loss after mini-batch   341: 6.910\n",
      "Loss after mini-batch   351: 0.247\n",
      "Loss after mini-batch   361: 11.154\n",
      "Loss after mini-batch   371: 0.661\n",
      "Training Loss: 30.046 \t\t Validation Loss:34.718\n",
      "Starting epoch 35\n",
      "Loss after mini-batch     1: 0.095\n",
      "Loss after mini-batch    11: 9.992\n",
      "Loss after mini-batch    21: 13.535\n",
      "Loss after mini-batch    31: 0.309\n",
      "Loss after mini-batch    41: 6.116\n",
      "Loss after mini-batch    51: 0.478\n",
      "Loss after mini-batch    61: 1.381\n",
      "Loss after mini-batch    71: 2.060\n",
      "Loss after mini-batch    81: 12.070\n",
      "Loss after mini-batch    91: 0.125\n",
      "Loss after mini-batch   101: 2.580\n",
      "Loss after mini-batch   111: 7.115\n",
      "Loss after mini-batch   121: 9.497\n",
      "Loss after mini-batch   131: 0.677\n",
      "Loss after mini-batch   141: 3.101\n",
      "Loss after mini-batch   151: 27.835\n",
      "Loss after mini-batch   161: 0.417\n",
      "Loss after mini-batch   171: 0.636\n",
      "Loss after mini-batch   181: 0.216\n",
      "Loss after mini-batch   191: 4.287\n",
      "Loss after mini-batch   201: 1.379\n",
      "Loss after mini-batch   211: 0.283\n",
      "Loss after mini-batch   221: 0.072\n",
      "Loss after mini-batch   231: 0.462\n",
      "Loss after mini-batch   241: 0.355\n",
      "Loss after mini-batch   251: 0.743\n",
      "Loss after mini-batch   261: 1.227\n",
      "Loss after mini-batch   271: 0.251\n",
      "Loss after mini-batch   281: 1.510\n",
      "Loss after mini-batch   291: 0.592\n",
      "Loss after mini-batch   301: 0.163\n",
      "Loss after mini-batch   311: 1.227\n",
      "Loss after mini-batch   321: 0.317\n",
      "Loss after mini-batch   331: 0.114\n",
      "Loss after mini-batch   341: 5.270\n",
      "Loss after mini-batch   351: 0.337\n",
      "Loss after mini-batch   361: 0.529\n",
      "Loss after mini-batch   371: 0.341\n",
      "Training Loss: 50.256 \t\t Validation Loss:55.419\n",
      "Starting epoch 36\n",
      "Loss after mini-batch     1: 3.885\n",
      "Loss after mini-batch    11: 0.239\n",
      "Loss after mini-batch    21: 0.415\n",
      "Loss after mini-batch    31: 6.688\n",
      "Loss after mini-batch    41: 0.549\n",
      "Loss after mini-batch    51: 0.975\n",
      "Loss after mini-batch    61: 0.458\n",
      "Loss after mini-batch    71: 15.826\n",
      "Loss after mini-batch    81: 0.457\n",
      "Loss after mini-batch    91: 3.207\n",
      "Loss after mini-batch   101: 7.771\n",
      "Loss after mini-batch   111: 8.957\n",
      "Loss after mini-batch   121: 0.103\n",
      "Loss after mini-batch   131: 0.312\n",
      "Loss after mini-batch   141: 27.695\n",
      "Loss after mini-batch   151: 2.462\n",
      "Loss after mini-batch   161: 21.247\n",
      "Loss after mini-batch   171: 0.508\n",
      "Loss after mini-batch   181: 4.185\n",
      "Loss after mini-batch   191: 0.220\n",
      "Loss after mini-batch   201: 5.068\n",
      "Loss after mini-batch   211: 0.273\n",
      "Loss after mini-batch   221: 34.893\n",
      "Loss after mini-batch   231: 3.446\n",
      "Loss after mini-batch   241: 1.078\n",
      "Loss after mini-batch   251: 0.403\n",
      "Loss after mini-batch   261: 0.810\n",
      "Loss after mini-batch   271: 3.856\n",
      "Loss after mini-batch   281: 29.820\n",
      "Loss after mini-batch   291: 1.795\n",
      "Loss after mini-batch   301: 0.098\n",
      "Loss after mini-batch   311: 0.779\n",
      "Loss after mini-batch   321: 0.611\n",
      "Loss after mini-batch   331: 1.090\n",
      "Loss after mini-batch   341: 1.663\n",
      "Loss after mini-batch   351: 0.328\n",
      "Loss after mini-batch   361: 39.938\n",
      "Loss after mini-batch   371: 0.439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 10.133 \t\t Validation Loss:33.365\n",
      "Starting epoch 37\n",
      "Loss after mini-batch     1: 0.532\n",
      "Loss after mini-batch    11: 0.435\n",
      "Loss after mini-batch    21: 0.332\n",
      "Loss after mini-batch    31: 0.285\n",
      "Loss after mini-batch    41: 5.088\n",
      "Loss after mini-batch    51: 7.521\n",
      "Loss after mini-batch    61: 0.375\n",
      "Loss after mini-batch    71: 0.659\n",
      "Loss after mini-batch    81: 0.218\n",
      "Loss after mini-batch    91: 0.937\n",
      "Loss after mini-batch   101: 0.010\n",
      "Loss after mini-batch   111: 0.737\n",
      "Loss after mini-batch   121: 3.715\n",
      "Loss after mini-batch   131: 12.729\n",
      "Loss after mini-batch   141: 16.297\n",
      "Loss after mini-batch   151: 0.984\n",
      "Loss after mini-batch   161: 27.312\n",
      "Loss after mini-batch   171: 10.904\n",
      "Loss after mini-batch   181: 0.320\n",
      "Loss after mini-batch   191: 4.031\n",
      "Loss after mini-batch   201: 0.629\n",
      "Loss after mini-batch   211: 1.998\n",
      "Loss after mini-batch   221: 2.872\n",
      "Loss after mini-batch   231: 4.250\n",
      "Loss after mini-batch   241: 0.276\n",
      "Loss after mini-batch   251: 3.414\n",
      "Loss after mini-batch   261: 4.551\n",
      "Loss after mini-batch   271: 0.176\n",
      "Loss after mini-batch   281: 0.323\n",
      "Loss after mini-batch   291: 4.993\n",
      "Loss after mini-batch   301: 15.947\n",
      "Loss after mini-batch   311: 45.629\n",
      "Loss after mini-batch   321: 2.414\n",
      "Loss after mini-batch   331: 0.162\n",
      "Loss after mini-batch   341: 2.472\n",
      "Loss after mini-batch   351: 9.070\n",
      "Loss after mini-batch   361: 0.151\n",
      "Loss after mini-batch   371: 0.259\n",
      "Training Loss: 0.084 \t\t Validation Loss:0.622\n",
      "Starting epoch 38\n",
      "Loss after mini-batch     1: 2.929\n",
      "Loss after mini-batch    11: 0.323\n",
      "Loss after mini-batch    21: 1.287\n",
      "Loss after mini-batch    31: 1.674\n",
      "Loss after mini-batch    41: 0.982\n",
      "Loss after mini-batch    51: 0.673\n",
      "Loss after mini-batch    61: 0.480\n",
      "Loss after mini-batch    71: 20.111\n",
      "Loss after mini-batch    81: 0.219\n",
      "Loss after mini-batch    91: 34.648\n",
      "Loss after mini-batch   101: 2.615\n",
      "Loss after mini-batch   111: 0.906\n",
      "Loss after mini-batch   121: 10.955\n",
      "Loss after mini-batch   131: 0.537\n",
      "Loss after mini-batch   141: 2.415\n",
      "Loss after mini-batch   151: 8.318\n",
      "Loss after mini-batch   161: 19.031\n",
      "Loss after mini-batch   171: 14.273\n",
      "Loss after mini-batch   181: 0.919\n",
      "Loss after mini-batch   191: 0.601\n",
      "Loss after mini-batch   201: 3.812\n",
      "Loss after mini-batch   211: 8.370\n",
      "Loss after mini-batch   221: 0.761\n",
      "Loss after mini-batch   231: 0.403\n",
      "Loss after mini-batch   241: 9.467\n",
      "Loss after mini-batch   251: 7.644\n",
      "Loss after mini-batch   261: 1.052\n",
      "Loss after mini-batch   271: 19.174\n",
      "Loss after mini-batch   281: 2.300\n",
      "Loss after mini-batch   291: 0.657\n",
      "Loss after mini-batch   301: 1.030\n",
      "Loss after mini-batch   311: 6.479\n",
      "Loss after mini-batch   321: 0.826\n",
      "Loss after mini-batch   331: 6.227\n",
      "Loss after mini-batch   341: 6.690\n",
      "Loss after mini-batch   351: 11.678\n",
      "Loss after mini-batch   361: 0.231\n",
      "Loss after mini-batch   371: 17.124\n",
      "Training Loss: 2.459 \t\t Validation Loss:2.643\n",
      "Starting epoch 39\n",
      "Loss after mini-batch     1: 2.257\n",
      "Loss after mini-batch    11: 1.119\n",
      "Loss after mini-batch    21: 6.861\n",
      "Loss after mini-batch    31: 4.188\n",
      "Loss after mini-batch    41: 8.858\n",
      "Loss after mini-batch    51: 9.993\n",
      "Loss after mini-batch    61: 12.834\n",
      "Loss after mini-batch    71: 0.290\n",
      "Loss after mini-batch    81: 1.516\n",
      "Loss after mini-batch    91: 0.462\n",
      "Loss after mini-batch   101: 2.259\n",
      "Loss after mini-batch   111: 1.087\n",
      "Loss after mini-batch   121: 0.406\n",
      "Loss after mini-batch   131: 1.030\n",
      "Loss after mini-batch   141: 7.075\n",
      "Loss after mini-batch   151: 0.544\n",
      "Loss after mini-batch   161: 1.218\n",
      "Loss after mini-batch   171: 7.261\n",
      "Loss after mini-batch   181: 9.126\n",
      "Loss after mini-batch   191: 0.428\n",
      "Loss after mini-batch   201: 20.177\n",
      "Loss after mini-batch   211: 0.132\n",
      "Loss after mini-batch   221: 45.002\n",
      "Loss after mini-batch   231: 9.342\n",
      "Loss after mini-batch   241: 2.497\n",
      "Loss after mini-batch   251: 0.157\n",
      "Loss after mini-batch   261: 3.903\n",
      "Loss after mini-batch   271: 0.418\n",
      "Loss after mini-batch   281: 8.567\n",
      "Loss after mini-batch   291: 0.290\n",
      "Loss after mini-batch   301: 0.862\n",
      "Loss after mini-batch   311: 1.087\n",
      "Loss after mini-batch   321: 4.778\n",
      "Loss after mini-batch   331: 28.740\n",
      "Loss after mini-batch   341: 2.319\n",
      "Loss after mini-batch   351: 0.971\n",
      "Loss after mini-batch   361: 0.775\n",
      "Loss after mini-batch   371: 1.459\n",
      "Training Loss: 0.785 \t\t Validation Loss:1.053\n",
      "Starting epoch 40\n",
      "Loss after mini-batch     1: 7.776\n",
      "Loss after mini-batch    11: 30.044\n",
      "Loss after mini-batch    21: 25.642\n",
      "Loss after mini-batch    31: 6.445\n",
      "Loss after mini-batch    41: 0.166\n",
      "Loss after mini-batch    51: 0.354\n",
      "Loss after mini-batch    61: 1.313\n",
      "Loss after mini-batch    71: 0.541\n",
      "Loss after mini-batch    81: 6.628\n",
      "Loss after mini-batch    91: 0.557\n",
      "Loss after mini-batch   101: 5.314\n",
      "Loss after mini-batch   111: 3.364\n",
      "Loss after mini-batch   121: 0.436\n",
      "Loss after mini-batch   131: 0.983\n",
      "Loss after mini-batch   141: 1.320\n",
      "Loss after mini-batch   151: 2.186\n",
      "Loss after mini-batch   161: 0.429\n",
      "Loss after mini-batch   171: 0.535\n",
      "Loss after mini-batch   181: 0.900\n",
      "Loss after mini-batch   191: 21.217\n",
      "Loss after mini-batch   201: 4.599\n",
      "Loss after mini-batch   211: 3.386\n",
      "Loss after mini-batch   221: 44.716\n",
      "Loss after mini-batch   231: 17.823\n",
      "Loss after mini-batch   241: 0.387\n",
      "Loss after mini-batch   251: 12.978\n",
      "Loss after mini-batch   261: 2.582\n",
      "Loss after mini-batch   271: 2.180\n",
      "Loss after mini-batch   281: 30.895\n",
      "Loss after mini-batch   291: 1.296\n",
      "Loss after mini-batch   301: 5.684\n",
      "Loss after mini-batch   311: 0.425\n",
      "Loss after mini-batch   321: 5.191\n",
      "Loss after mini-batch   331: 0.528\n",
      "Loss after mini-batch   341: 9.789\n",
      "Loss after mini-batch   351: 0.579\n",
      "Loss after mini-batch   361: 1.336\n",
      "Loss after mini-batch   371: 8.072\n",
      "Training Loss: 19.119 \t\t Validation Loss:19.331\n",
      "Starting epoch 41\n",
      "Loss after mini-batch     1: 1.530\n",
      "Loss after mini-batch    11: 35.232\n",
      "Loss after mini-batch    21: 0.976\n",
      "Loss after mini-batch    31: 3.329\n",
      "Loss after mini-batch    41: 15.057\n",
      "Loss after mini-batch    51: 1.143\n",
      "Loss after mini-batch    61: 2.703\n",
      "Loss after mini-batch    71: 2.134\n",
      "Loss after mini-batch    81: 2.046\n",
      "Loss after mini-batch    91: 0.635\n",
      "Loss after mini-batch   101: 5.778\n",
      "Loss after mini-batch   111: 0.285\n",
      "Loss after mini-batch   121: 6.926\n",
      "Loss after mini-batch   131: 0.212\n",
      "Loss after mini-batch   141: 0.874\n",
      "Loss after mini-batch   151: 0.585\n",
      "Loss after mini-batch   161: 0.818\n",
      "Loss after mini-batch   171: 1.410\n",
      "Loss after mini-batch   181: 7.269\n",
      "Loss after mini-batch   191: 15.491\n",
      "Loss after mini-batch   201: 1.467\n",
      "Loss after mini-batch   211: 0.597\n",
      "Loss after mini-batch   221: 9.847\n",
      "Loss after mini-batch   231: 0.830\n",
      "Loss after mini-batch   241: 4.242\n",
      "Loss after mini-batch   251: 24.911\n",
      "Loss after mini-batch   261: 4.162\n",
      "Loss after mini-batch   271: 0.649\n",
      "Loss after mini-batch   281: 0.458\n",
      "Loss after mini-batch   291: 0.487\n",
      "Loss after mini-batch   301: 24.821\n",
      "Loss after mini-batch   311: 2.195\n",
      "Loss after mini-batch   321: 0.214\n",
      "Loss after mini-batch   331: 0.674\n",
      "Loss after mini-batch   341: 9.329\n",
      "Loss after mini-batch   351: 0.452\n",
      "Loss after mini-batch   361: 0.310\n",
      "Loss after mini-batch   371: 19.199\n",
      "Training Loss: 1.435 \t\t Validation Loss:5.728\n",
      "Starting epoch 42\n",
      "Loss after mini-batch     1: 0.144\n",
      "Loss after mini-batch    11: 0.179\n",
      "Loss after mini-batch    21: 0.498\n",
      "Loss after mini-batch    31: 2.717\n",
      "Loss after mini-batch    41: 1.059\n",
      "Loss after mini-batch    51: 0.795\n",
      "Loss after mini-batch    61: 40.705\n",
      "Loss after mini-batch    71: 2.722\n",
      "Loss after mini-batch    81: 0.905\n",
      "Loss after mini-batch    91: 0.192\n",
      "Loss after mini-batch   101: 3.749\n",
      "Loss after mini-batch   111: 0.621\n",
      "Loss after mini-batch   121: 3.013\n",
      "Loss after mini-batch   131: 12.974\n",
      "Loss after mini-batch   141: 1.492\n",
      "Loss after mini-batch   151: 0.642\n",
      "Loss after mini-batch   161: 3.998\n",
      "Loss after mini-batch   171: 2.076\n",
      "Loss after mini-batch   181: 0.743\n",
      "Loss after mini-batch   191: 2.329\n",
      "Loss after mini-batch   201: 0.845\n",
      "Loss after mini-batch   211: 0.676\n",
      "Loss after mini-batch   221: 7.741\n",
      "Loss after mini-batch   231: 27.877\n",
      "Loss after mini-batch   241: 24.888\n",
      "Loss after mini-batch   251: 1.594\n",
      "Loss after mini-batch   261: 0.234\n",
      "Loss after mini-batch   271: 17.161\n",
      "Loss after mini-batch   281: 1.112\n",
      "Loss after mini-batch   291: 27.211\n",
      "Loss after mini-batch   301: 31.814\n",
      "Loss after mini-batch   311: 0.538\n",
      "Loss after mini-batch   321: 0.251\n",
      "Loss after mini-batch   331: 6.301\n",
      "Loss after mini-batch   341: 4.424\n",
      "Loss after mini-batch   351: 0.870\n",
      "Loss after mini-batch   361: 1.622\n",
      "Loss after mini-batch   371: 0.492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.510 \t\t Validation Loss:21.933\n",
      "Starting epoch 43\n",
      "Loss after mini-batch     1: 1.491\n",
      "Loss after mini-batch    11: 5.344\n",
      "Loss after mini-batch    21: 0.127\n",
      "Loss after mini-batch    31: 7.323\n",
      "Loss after mini-batch    41: 9.631\n",
      "Loss after mini-batch    51: 0.456\n",
      "Loss after mini-batch    61: 19.383\n",
      "Loss after mini-batch    71: 11.973\n",
      "Loss after mini-batch    81: 1.055\n",
      "Loss after mini-batch    91: 2.360\n",
      "Loss after mini-batch   101: 0.578\n",
      "Loss after mini-batch   111: 0.913\n",
      "Loss after mini-batch   121: 0.699\n",
      "Loss after mini-batch   131: 0.603\n",
      "Loss after mini-batch   141: 2.157\n",
      "Loss after mini-batch   151: 0.318\n",
      "Loss after mini-batch   161: 11.197\n",
      "Loss after mini-batch   171: 7.771\n",
      "Loss after mini-batch   181: 3.819\n",
      "Loss after mini-batch   191: 1.448\n",
      "Loss after mini-batch   201: 0.780\n",
      "Loss after mini-batch   211: 0.876\n",
      "Loss after mini-batch   221: 1.022\n",
      "Loss after mini-batch   231: 0.482\n",
      "Loss after mini-batch   241: 2.760\n",
      "Loss after mini-batch   251: 13.977\n",
      "Loss after mini-batch   261: 0.008\n",
      "Loss after mini-batch   271: 0.526\n",
      "Loss after mini-batch   281: 0.132\n",
      "Loss after mini-batch   291: 0.018\n",
      "Loss after mini-batch   301: 18.063\n",
      "Loss after mini-batch   311: 8.583\n",
      "Loss after mini-batch   321: 0.832\n",
      "Loss after mini-batch   331: 0.464\n",
      "Loss after mini-batch   341: 0.309\n",
      "Loss after mini-batch   351: 16.261\n",
      "Loss after mini-batch   361: 6.335\n",
      "Loss after mini-batch   371: 7.659\n",
      "Training Loss: 7.499 \t\t Validation Loss:7.763\n",
      "Starting epoch 44\n",
      "Loss after mini-batch     1: 0.788\n",
      "Loss after mini-batch    11: 1.195\n",
      "Loss after mini-batch    21: 0.605\n",
      "Loss after mini-batch    31: 1.428\n",
      "Loss after mini-batch    41: 0.183\n",
      "Loss after mini-batch    51: 5.596\n",
      "Loss after mini-batch    61: 1.352\n",
      "Loss after mini-batch    71: 2.204\n",
      "Loss after mini-batch    81: 0.595\n",
      "Loss after mini-batch    91: 5.526\n",
      "Loss after mini-batch   101: 9.753\n",
      "Loss after mini-batch   111: 0.660\n",
      "Loss after mini-batch   121: 0.459\n",
      "Loss after mini-batch   131: 2.419\n",
      "Loss after mini-batch   141: 2.608\n",
      "Loss after mini-batch   151: 8.387\n",
      "Loss after mini-batch   161: 0.894\n",
      "Loss after mini-batch   171: 11.331\n",
      "Loss after mini-batch   181: 8.105\n",
      "Loss after mini-batch   191: 2.783\n",
      "Loss after mini-batch   201: 38.138\n",
      "Loss after mini-batch   211: 0.091\n",
      "Loss after mini-batch   221: 1.854\n",
      "Loss after mini-batch   231: 0.479\n",
      "Loss after mini-batch   241: 0.413\n",
      "Loss after mini-batch   251: 0.129\n",
      "Loss after mini-batch   261: 15.224\n",
      "Loss after mini-batch   271: 0.797\n",
      "Loss after mini-batch   281: 3.278\n",
      "Loss after mini-batch   291: 43.947\n",
      "Loss after mini-batch   301: 3.276\n",
      "Loss after mini-batch   311: 3.208\n",
      "Loss after mini-batch   321: 4.355\n",
      "Loss after mini-batch   331: 13.030\n",
      "Loss after mini-batch   341: 0.624\n",
      "Loss after mini-batch   351: 2.255\n",
      "Loss after mini-batch   361: 0.579\n",
      "Loss after mini-batch   371: 5.499\n",
      "Training Loss: 0.224 \t\t Validation Loss:3.354\n",
      "Starting epoch 45\n",
      "Loss after mini-batch     1: 12.989\n",
      "Loss after mini-batch    11: 0.276\n",
      "Loss after mini-batch    21: 2.947\n",
      "Loss after mini-batch    31: 0.976\n",
      "Loss after mini-batch    41: 0.244\n",
      "Loss after mini-batch    51: 0.411\n",
      "Loss after mini-batch    61: 1.473\n",
      "Loss after mini-batch    71: 0.325\n",
      "Loss after mini-batch    81: 10.239\n",
      "Loss after mini-batch    91: 0.289\n",
      "Loss after mini-batch   101: 2.060\n",
      "Loss after mini-batch   111: 18.966\n",
      "Loss after mini-batch   121: 0.122\n",
      "Loss after mini-batch   131: 0.154\n",
      "Loss after mini-batch   141: 0.879\n",
      "Loss after mini-batch   151: 0.876\n",
      "Loss after mini-batch   161: 0.273\n",
      "Loss after mini-batch   171: 0.602\n",
      "Loss after mini-batch   181: 6.166\n",
      "Loss after mini-batch   191: 0.080\n",
      "Loss after mini-batch   201: 0.155\n",
      "Loss after mini-batch   211: 0.107\n",
      "Loss after mini-batch   221: 0.640\n",
      "Loss after mini-batch   231: 73.468\n",
      "Loss after mini-batch   241: 4.221\n",
      "Loss after mini-batch   251: 0.504\n",
      "Loss after mini-batch   261: 0.660\n",
      "Loss after mini-batch   271: 0.050\n",
      "Loss after mini-batch   281: 1.099\n",
      "Loss after mini-batch   291: 0.567\n",
      "Loss after mini-batch   301: 12.424\n",
      "Loss after mini-batch   311: 0.747\n",
      "Loss after mini-batch   321: 12.672\n",
      "Loss after mini-batch   331: 3.479\n",
      "Loss after mini-batch   341: 1.275\n",
      "Loss after mini-batch   351: 0.400\n",
      "Loss after mini-batch   361: 0.480\n",
      "Loss after mini-batch   371: 1.556\n",
      "Training Loss: 0.201 \t\t Validation Loss:0.832\n",
      "Starting epoch 46\n",
      "Loss after mini-batch     1: 46.270\n",
      "Loss after mini-batch    11: 1.043\n",
      "Loss after mini-batch    21: 0.403\n",
      "Loss after mini-batch    31: 0.202\n",
      "Loss after mini-batch    41: 0.624\n",
      "Loss after mini-batch    51: 0.269\n",
      "Loss after mini-batch    61: 0.095\n",
      "Loss after mini-batch    71: 0.114\n",
      "Loss after mini-batch    81: 0.228\n",
      "Loss after mini-batch    91: 2.229\n",
      "Loss after mini-batch   101: 12.587\n",
      "Loss after mini-batch   111: 1.861\n",
      "Loss after mini-batch   121: 0.857\n",
      "Loss after mini-batch   131: 0.191\n",
      "Loss after mini-batch   141: 0.556\n",
      "Loss after mini-batch   151: 2.938\n",
      "Loss after mini-batch   161: 1.923\n",
      "Loss after mini-batch   171: 0.366\n",
      "Loss after mini-batch   181: 0.680\n",
      "Loss after mini-batch   191: 0.539\n",
      "Loss after mini-batch   201: 0.111\n",
      "Loss after mini-batch   211: 0.434\n",
      "Loss after mini-batch   221: 6.498\n",
      "Loss after mini-batch   231: 17.506\n",
      "Loss after mini-batch   241: 1.151\n",
      "Loss after mini-batch   251: 6.635\n",
      "Loss after mini-batch   261: 0.247\n",
      "Loss after mini-batch   271: 0.367\n",
      "Loss after mini-batch   281: 0.236\n",
      "Loss after mini-batch   291: 5.945\n",
      "Loss after mini-batch   301: 9.906\n",
      "Loss after mini-batch   311: 1.945\n",
      "Loss after mini-batch   321: 16.441\n",
      "Loss after mini-batch   331: 15.985\n",
      "Loss after mini-batch   341: 0.151\n",
      "Loss after mini-batch   351: 23.689\n",
      "Loss after mini-batch   361: 1.698\n",
      "Loss after mini-batch   371: 0.908\n",
      "Training Loss: 0.752 \t\t Validation Loss:5.928\n",
      "Starting epoch 47\n",
      "Loss after mini-batch     1: 0.313\n",
      "Loss after mini-batch    11: 10.845\n",
      "Loss after mini-batch    21: 0.371\n",
      "Loss after mini-batch    31: 6.046\n",
      "Loss after mini-batch    41: 10.517\n",
      "Loss after mini-batch    51: 0.258\n",
      "Loss after mini-batch    61: 1.894\n",
      "Loss after mini-batch    71: 2.395\n",
      "Loss after mini-batch    81: 0.612\n",
      "Loss after mini-batch    91: 0.725\n",
      "Loss after mini-batch   101: 10.666\n",
      "Loss after mini-batch   111: 1.190\n",
      "Loss after mini-batch   121: 0.571\n",
      "Loss after mini-batch   131: 0.541\n",
      "Loss after mini-batch   141: 0.382\n",
      "Loss after mini-batch   151: 0.483\n",
      "Loss after mini-batch   161: 0.759\n",
      "Loss after mini-batch   171: 0.928\n",
      "Loss after mini-batch   181: 32.723\n",
      "Loss after mini-batch   191: 0.829\n",
      "Loss after mini-batch   201: 1.165\n",
      "Loss after mini-batch   211: 0.766\n",
      "Loss after mini-batch   221: 38.842\n",
      "Loss after mini-batch   231: 2.382\n",
      "Loss after mini-batch   241: 0.470\n",
      "Loss after mini-batch   251: 14.918\n",
      "Loss after mini-batch   261: 0.214\n",
      "Loss after mini-batch   271: 0.057\n",
      "Loss after mini-batch   281: 9.600\n",
      "Loss after mini-batch   291: 20.050\n",
      "Loss after mini-batch   301: 1.296\n",
      "Loss after mini-batch   311: 46.307\n",
      "Loss after mini-batch   321: 30.790\n",
      "Loss after mini-batch   331: 0.325\n",
      "Loss after mini-batch   341: 1.680\n",
      "Loss after mini-batch   351: 0.964\n",
      "Loss after mini-batch   361: 0.038\n",
      "Loss after mini-batch   371: 0.619\n",
      "Training Loss: 27.567 \t\t Validation Loss:27.989\n",
      "Starting epoch 48\n",
      "Loss after mini-batch     1: 3.885\n",
      "Loss after mini-batch    11: 0.084\n",
      "Loss after mini-batch    21: 0.319\n",
      "Loss after mini-batch    31: 1.578\n",
      "Loss after mini-batch    41: 1.206\n",
      "Loss after mini-batch    51: 0.417\n",
      "Loss after mini-batch    61: 2.690\n",
      "Loss after mini-batch    71: 0.507\n",
      "Loss after mini-batch    81: 6.293\n",
      "Loss after mini-batch    91: 8.091\n",
      "Loss after mini-batch   101: 0.065\n",
      "Loss after mini-batch   111: 0.047\n",
      "Loss after mini-batch   121: 0.206\n",
      "Loss after mini-batch   131: 0.856\n",
      "Loss after mini-batch   141: 0.189\n",
      "Loss after mini-batch   151: 0.175\n",
      "Loss after mini-batch   161: 0.160\n",
      "Loss after mini-batch   171: 2.273\n",
      "Loss after mini-batch   181: 1.230\n",
      "Loss after mini-batch   191: 0.671\n",
      "Loss after mini-batch   201: 0.224\n",
      "Loss after mini-batch   211: 7.176\n",
      "Loss after mini-batch   221: 0.676\n",
      "Loss after mini-batch   231: 25.509\n",
      "Loss after mini-batch   241: 22.964\n",
      "Loss after mini-batch   251: 2.237\n",
      "Loss after mini-batch   261: 28.220\n",
      "Loss after mini-batch   271: 2.208\n",
      "Loss after mini-batch   281: 9.807\n",
      "Loss after mini-batch   291: 0.833\n",
      "Loss after mini-batch   301: 11.381\n",
      "Loss after mini-batch   311: 10.050\n",
      "Loss after mini-batch   321: 0.037\n",
      "Loss after mini-batch   331: 0.445\n",
      "Loss after mini-batch   341: 0.475\n",
      "Loss after mini-batch   351: 1.510\n",
      "Loss after mini-batch   361: 0.489\n",
      "Loss after mini-batch   371: 0.149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.075 \t\t Validation Loss:3.323\n",
      "Starting epoch 49\n",
      "Loss after mini-batch     1: 1.788\n",
      "Loss after mini-batch    11: 17.835\n",
      "Loss after mini-batch    21: 1.669\n",
      "Loss after mini-batch    31: 19.001\n",
      "Loss after mini-batch    41: 1.934\n",
      "Loss after mini-batch    51: 0.454\n",
      "Loss after mini-batch    61: 3.196\n",
      "Loss after mini-batch    71: 7.472\n",
      "Loss after mini-batch    81: 0.338\n",
      "Loss after mini-batch    91: 1.130\n",
      "Loss after mini-batch   101: 1.154\n",
      "Loss after mini-batch   111: 0.813\n",
      "Loss after mini-batch   121: 20.553\n",
      "Loss after mini-batch   131: 3.773\n",
      "Loss after mini-batch   141: 0.065\n",
      "Loss after mini-batch   151: 1.644\n",
      "Loss after mini-batch   161: 2.894\n",
      "Loss after mini-batch   171: 0.129\n",
      "Loss after mini-batch   181: 6.603\n",
      "Loss after mini-batch   191: 14.167\n",
      "Loss after mini-batch   201: 7.296\n",
      "Loss after mini-batch   211: 0.920\n",
      "Loss after mini-batch   221: 3.482\n",
      "Loss after mini-batch   231: 0.683\n",
      "Loss after mini-batch   241: 2.309\n",
      "Loss after mini-batch   251: 8.427\n",
      "Loss after mini-batch   261: 7.942\n",
      "Loss after mini-batch   271: 4.834\n",
      "Loss after mini-batch   281: 1.388\n",
      "Loss after mini-batch   291: 1.656\n",
      "Loss after mini-batch   301: 0.879\n",
      "Loss after mini-batch   311: 0.811\n",
      "Loss after mini-batch   321: 2.024\n",
      "Loss after mini-batch   331: 18.391\n",
      "Loss after mini-batch   341: 1.551\n",
      "Loss after mini-batch   351: 11.740\n",
      "Loss after mini-batch   361: 0.198\n",
      "Loss after mini-batch   371: 0.047\n",
      "Training Loss: 2.899 \t\t Validation Loss:12.600\n",
      "Starting epoch 50\n",
      "Loss after mini-batch     1: 1.439\n",
      "Loss after mini-batch    11: 1.009\n",
      "Loss after mini-batch    21: 0.168\n",
      "Loss after mini-batch    31: 0.548\n",
      "Loss after mini-batch    41: 10.865\n",
      "Loss after mini-batch    51: 1.513\n",
      "Loss after mini-batch    61: 7.928\n",
      "Loss after mini-batch    71: 11.694\n",
      "Loss after mini-batch    81: 0.933\n",
      "Loss after mini-batch    91: 0.240\n",
      "Loss after mini-batch   101: 1.007\n",
      "Loss after mini-batch   111: 1.133\n",
      "Loss after mini-batch   121: 0.820\n",
      "Loss after mini-batch   131: 1.744\n",
      "Loss after mini-batch   141: 0.236\n",
      "Loss after mini-batch   151: 0.999\n",
      "Loss after mini-batch   161: 1.244\n",
      "Loss after mini-batch   171: 1.033\n",
      "Loss after mini-batch   181: 0.629\n",
      "Loss after mini-batch   191: 0.405\n",
      "Loss after mini-batch   201: 0.984\n",
      "Loss after mini-batch   211: 1.315\n",
      "Loss after mini-batch   221: 0.059\n",
      "Loss after mini-batch   231: 1.128\n",
      "Loss after mini-batch   241: 18.600\n",
      "Loss after mini-batch   251: 2.293\n",
      "Loss after mini-batch   261: 10.719\n",
      "Loss after mini-batch   271: 0.677\n",
      "Loss after mini-batch   281: 1.204\n",
      "Loss after mini-batch   291: 0.395\n",
      "Loss after mini-batch   301: 2.032\n",
      "Loss after mini-batch   311: 1.926\n",
      "Loss after mini-batch   321: 1.698\n",
      "Loss after mini-batch   331: 0.040\n",
      "Loss after mini-batch   341: 0.437\n",
      "Loss after mini-batch   351: 0.113\n",
      "Loss after mini-batch   361: 1.054\n",
      "Loss after mini-batch   371: 0.218\n",
      "Training Loss: 9.842 \t\t Validation Loss:17.146\n",
      "Starting epoch 51\n",
      "Loss after mini-batch     1: 22.813\n",
      "Loss after mini-batch    11: 0.960\n",
      "Loss after mini-batch    21: 0.114\n",
      "Loss after mini-batch    31: 0.135\n",
      "Loss after mini-batch    41: 27.239\n",
      "Loss after mini-batch    51: 0.149\n",
      "Loss after mini-batch    61: 11.574\n",
      "Loss after mini-batch    71: 1.321\n",
      "Loss after mini-batch    81: 1.350\n",
      "Loss after mini-batch    91: 0.120\n",
      "Loss after mini-batch   101: 0.216\n",
      "Loss after mini-batch   111: 0.275\n",
      "Loss after mini-batch   121: 10.607\n",
      "Loss after mini-batch   131: 0.080\n",
      "Loss after mini-batch   141: 0.399\n",
      "Loss after mini-batch   151: 5.073\n",
      "Loss after mini-batch   161: 2.075\n",
      "Loss after mini-batch   171: 0.387\n",
      "Loss after mini-batch   181: 4.064\n",
      "Loss after mini-batch   191: 3.080\n",
      "Loss after mini-batch   201: 6.408\n",
      "Loss after mini-batch   211: 0.237\n",
      "Loss after mini-batch   221: 0.661\n",
      "Loss after mini-batch   231: 0.012\n",
      "Loss after mini-batch   241: 14.049\n",
      "Loss after mini-batch   251: 18.493\n",
      "Loss after mini-batch   261: 1.241\n",
      "Loss after mini-batch   271: 45.269\n",
      "Loss after mini-batch   281: 5.184\n",
      "Loss after mini-batch   291: 1.099\n",
      "Loss after mini-batch   301: 0.077\n",
      "Loss after mini-batch   311: 7.849\n",
      "Loss after mini-batch   321: 26.518\n",
      "Loss after mini-batch   331: 3.963\n",
      "Loss after mini-batch   341: 0.290\n",
      "Loss after mini-batch   351: 0.728\n",
      "Loss after mini-batch   361: 0.302\n",
      "Loss after mini-batch   371: 0.879\n",
      "Training Loss: 0.314 \t\t Validation Loss:3.661\n",
      "Starting epoch 52\n",
      "Loss after mini-batch     1: 0.149\n",
      "Loss after mini-batch    11: 2.337\n",
      "Loss after mini-batch    21: 3.954\n",
      "Loss after mini-batch    31: 8.513\n",
      "Loss after mini-batch    41: 1.223\n",
      "Loss after mini-batch    51: 5.533\n",
      "Loss after mini-batch    61: 0.739\n",
      "Loss after mini-batch    71: 2.086\n",
      "Loss after mini-batch    81: 5.279\n",
      "Loss after mini-batch    91: 0.107\n",
      "Loss after mini-batch   101: 1.139\n",
      "Loss after mini-batch   111: 0.216\n",
      "Loss after mini-batch   121: 1.734\n",
      "Loss after mini-batch   131: 17.690\n",
      "Loss after mini-batch   141: 2.931\n",
      "Loss after mini-batch   151: 14.970\n",
      "Loss after mini-batch   161: 1.770\n",
      "Loss after mini-batch   171: 0.146\n",
      "Loss after mini-batch   181: 1.442\n",
      "Loss after mini-batch   191: 2.416\n",
      "Loss after mini-batch   201: 0.118\n",
      "Loss after mini-batch   211: 0.383\n",
      "Loss after mini-batch   221: 0.990\n",
      "Loss after mini-batch   231: 0.102\n",
      "Loss after mini-batch   241: 0.589\n",
      "Loss after mini-batch   251: 0.045\n",
      "Loss after mini-batch   261: 1.873\n",
      "Loss after mini-batch   271: 0.792\n",
      "Loss after mini-batch   281: 0.530\n",
      "Loss after mini-batch   291: 0.213\n",
      "Loss after mini-batch   301: 0.345\n",
      "Loss after mini-batch   311: 1.158\n",
      "Loss after mini-batch   321: 0.604\n",
      "Loss after mini-batch   331: 0.442\n",
      "Loss after mini-batch   341: 6.799\n",
      "Loss after mini-batch   351: 0.045\n",
      "Loss after mini-batch   361: 18.701\n",
      "Loss after mini-batch   371: 12.642\n",
      "Training Loss: 0.263 \t\t Validation Loss:0.839\n",
      "Starting epoch 53\n",
      "Loss after mini-batch     1: 4.067\n",
      "Loss after mini-batch    11: 4.251\n",
      "Loss after mini-batch    21: 0.673\n",
      "Loss after mini-batch    31: 13.262\n",
      "Loss after mini-batch    41: 1.175\n",
      "Loss after mini-batch    51: 0.499\n",
      "Loss after mini-batch    61: 0.389\n",
      "Loss after mini-batch    71: 1.188\n",
      "Loss after mini-batch    81: 6.538\n",
      "Loss after mini-batch    91: 1.614\n",
      "Loss after mini-batch   101: 3.944\n",
      "Loss after mini-batch   111: 2.051\n",
      "Loss after mini-batch   121: 30.840\n",
      "Loss after mini-batch   131: 10.096\n",
      "Loss after mini-batch   141: 0.261\n",
      "Loss after mini-batch   151: 0.083\n",
      "Loss after mini-batch   161: 14.505\n",
      "Loss after mini-batch   171: 2.475\n",
      "Loss after mini-batch   181: 0.572\n",
      "Loss after mini-batch   191: 1.184\n",
      "Loss after mini-batch   201: 0.082\n",
      "Loss after mini-batch   211: 1.690\n",
      "Loss after mini-batch   221: 9.123\n",
      "Loss after mini-batch   231: 0.278\n",
      "Loss after mini-batch   241: 10.774\n",
      "Loss after mini-batch   251: 0.587\n",
      "Loss after mini-batch   261: 19.910\n",
      "Loss after mini-batch   271: 7.857\n",
      "Loss after mini-batch   281: 0.694\n",
      "Loss after mini-batch   291: 0.059\n",
      "Loss after mini-batch   301: 0.768\n",
      "Loss after mini-batch   311: 2.953\n",
      "Loss after mini-batch   321: 1.951\n",
      "Loss after mini-batch   331: 0.536\n",
      "Loss after mini-batch   341: 0.739\n",
      "Loss after mini-batch   351: 8.845\n",
      "Loss after mini-batch   361: 8.193\n",
      "Loss after mini-batch   371: 0.432\n",
      "Training Loss: 0.168 \t\t Validation Loss:2.704\n",
      "Starting epoch 54\n",
      "Loss after mini-batch     1: 0.326\n",
      "Loss after mini-batch    11: 1.176\n",
      "Loss after mini-batch    21: 0.040\n",
      "Loss after mini-batch    31: 0.698\n",
      "Loss after mini-batch    41: 1.652\n",
      "Loss after mini-batch    51: 5.242\n",
      "Loss after mini-batch    61: 11.939\n",
      "Loss after mini-batch    71: 1.115\n",
      "Loss after mini-batch    81: 3.991\n",
      "Loss after mini-batch    91: 3.416\n",
      "Loss after mini-batch   101: 2.547\n",
      "Loss after mini-batch   111: 0.085\n",
      "Loss after mini-batch   121: 8.901\n",
      "Loss after mini-batch   131: 0.148\n",
      "Loss after mini-batch   141: 0.116\n",
      "Loss after mini-batch   151: 1.061\n",
      "Loss after mini-batch   161: 0.588\n",
      "Loss after mini-batch   171: 0.222\n",
      "Loss after mini-batch   181: 0.101\n",
      "Loss after mini-batch   191: 0.922\n",
      "Loss after mini-batch   201: 3.956\n",
      "Loss after mini-batch   211: 1.012\n",
      "Loss after mini-batch   221: 2.912\n",
      "Loss after mini-batch   231: 1.386\n",
      "Loss after mini-batch   241: 0.898\n",
      "Loss after mini-batch   251: 7.683\n",
      "Loss after mini-batch   261: 0.786\n",
      "Loss after mini-batch   271: 16.046\n",
      "Loss after mini-batch   281: 0.811\n",
      "Loss after mini-batch   291: 1.757\n",
      "Loss after mini-batch   301: 0.578\n",
      "Loss after mini-batch   311: 2.017\n",
      "Loss after mini-batch   321: 2.644\n",
      "Loss after mini-batch   331: 27.539\n",
      "Loss after mini-batch   341: 2.405\n",
      "Loss after mini-batch   351: 0.324\n",
      "Loss after mini-batch   361: 0.297\n",
      "Loss after mini-batch   371: 23.289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 11.977 \t\t Validation Loss:12.199\n",
      "Starting epoch 55\n",
      "Loss after mini-batch     1: 10.602\n",
      "Loss after mini-batch    11: 2.259\n",
      "Loss after mini-batch    21: 0.228\n",
      "Loss after mini-batch    31: 0.037\n",
      "Loss after mini-batch    41: 5.920\n",
      "Loss after mini-batch    51: 2.031\n",
      "Loss after mini-batch    61: 0.226\n",
      "Loss after mini-batch    71: 1.189\n",
      "Loss after mini-batch    81: 1.770\n",
      "Loss after mini-batch    91: 13.459\n",
      "Loss after mini-batch   101: 2.026\n",
      "Loss after mini-batch   111: 0.122\n",
      "Loss after mini-batch   121: 0.689\n",
      "Loss after mini-batch   131: 6.100\n",
      "Loss after mini-batch   141: 5.712\n",
      "Loss after mini-batch   151: 3.977\n",
      "Loss after mini-batch   161: 0.032\n",
      "Loss after mini-batch   171: 0.204\n",
      "Loss after mini-batch   181: 7.656\n",
      "Loss after mini-batch   191: 0.633\n",
      "Loss after mini-batch   201: 0.617\n",
      "Loss after mini-batch   211: 1.973\n",
      "Loss after mini-batch   221: 6.369\n",
      "Loss after mini-batch   231: 2.310\n",
      "Loss after mini-batch   241: 0.799\n",
      "Loss after mini-batch   251: 0.433\n",
      "Loss after mini-batch   261: 2.552\n",
      "Loss after mini-batch   271: 0.832\n",
      "Loss after mini-batch   281: 0.321\n",
      "Loss after mini-batch   291: 9.766\n",
      "Loss after mini-batch   301: 5.345\n",
      "Loss after mini-batch   311: 0.894\n",
      "Loss after mini-batch   321: 1.113\n",
      "Loss after mini-batch   331: 1.254\n",
      "Loss after mini-batch   341: 1.151\n",
      "Loss after mini-batch   351: 6.343\n",
      "Loss after mini-batch   361: 7.686\n",
      "Loss after mini-batch   371: 4.538\n",
      "Training Loss: 0.401 \t\t Validation Loss:0.534\n",
      "Starting epoch 56\n",
      "Loss after mini-batch     1: 1.065\n",
      "Loss after mini-batch    11: 5.386\n",
      "Loss after mini-batch    21: 0.068\n",
      "Loss after mini-batch    31: 0.655\n",
      "Loss after mini-batch    41: 0.541\n",
      "Loss after mini-batch    51: 0.281\n",
      "Loss after mini-batch    61: 0.168\n",
      "Loss after mini-batch    71: 1.084\n",
      "Loss after mini-batch    81: 0.205\n",
      "Loss after mini-batch    91: 0.186\n",
      "Loss after mini-batch   101: 11.383\n",
      "Loss after mini-batch   111: 0.059\n",
      "Loss after mini-batch   121: 5.877\n",
      "Loss after mini-batch   131: 8.607\n",
      "Loss after mini-batch   141: 0.617\n",
      "Loss after mini-batch   151: 8.348\n",
      "Loss after mini-batch   161: 2.318\n",
      "Loss after mini-batch   171: 3.763\n",
      "Loss after mini-batch   181: 4.601\n",
      "Loss after mini-batch   191: 21.412\n",
      "Loss after mini-batch   201: 0.922\n",
      "Loss after mini-batch   211: 0.246\n",
      "Loss after mini-batch   221: 0.870\n",
      "Loss after mini-batch   231: 0.771\n",
      "Loss after mini-batch   241: 5.688\n",
      "Loss after mini-batch   251: 0.183\n",
      "Loss after mini-batch   261: 5.783\n",
      "Loss after mini-batch   271: 0.095\n",
      "Loss after mini-batch   281: 2.438\n",
      "Loss after mini-batch   291: 0.778\n",
      "Loss after mini-batch   301: 5.584\n",
      "Loss after mini-batch   311: 0.884\n",
      "Loss after mini-batch   321: 0.332\n",
      "Loss after mini-batch   331: 1.348\n",
      "Loss after mini-batch   341: 3.068\n",
      "Loss after mini-batch   351: 0.212\n",
      "Loss after mini-batch   361: 1.031\n",
      "Loss after mini-batch   371: 4.087\n",
      "Training Loss: 3.593 \t\t Validation Loss:5.913\n",
      "Starting epoch 57\n",
      "Loss after mini-batch     1: 13.107\n",
      "Loss after mini-batch    11: 0.623\n",
      "Loss after mini-batch    21: 2.331\n",
      "Loss after mini-batch    31: 1.719\n",
      "Loss after mini-batch    41: 0.138\n",
      "Loss after mini-batch    51: 0.355\n",
      "Loss after mini-batch    61: 0.280\n",
      "Loss after mini-batch    71: 0.850\n",
      "Loss after mini-batch    81: 9.228\n",
      "Loss after mini-batch    91: 9.732\n",
      "Loss after mini-batch   101: 0.101\n",
      "Loss after mini-batch   111: 0.162\n",
      "Loss after mini-batch   121: 0.050\n",
      "Loss after mini-batch   131: 7.074\n",
      "Loss after mini-batch   141: 1.186\n",
      "Loss after mini-batch   151: 0.991\n",
      "Loss after mini-batch   161: 0.083\n",
      "Loss after mini-batch   171: 1.351\n",
      "Loss after mini-batch   181: 18.282\n",
      "Loss after mini-batch   191: 0.964\n",
      "Loss after mini-batch   201: 15.220\n",
      "Loss after mini-batch   211: 1.614\n",
      "Loss after mini-batch   221: 0.345\n",
      "Loss after mini-batch   231: 0.768\n",
      "Loss after mini-batch   241: 7.400\n",
      "Loss after mini-batch   251: 3.925\n",
      "Loss after mini-batch   261: 2.280\n",
      "Loss after mini-batch   271: 1.334\n",
      "Loss after mini-batch   281: 0.450\n",
      "Loss after mini-batch   291: 9.468\n",
      "Loss after mini-batch   301: 2.862\n",
      "Loss after mini-batch   311: 0.677\n",
      "Loss after mini-batch   321: 9.083\n",
      "Loss after mini-batch   331: 3.575\n",
      "Loss after mini-batch   341: 0.740\n",
      "Loss after mini-batch   351: 0.622\n",
      "Loss after mini-batch   361: 0.493\n",
      "Loss after mini-batch   371: 1.491\n",
      "Training Loss: 12.519 \t\t Validation Loss:12.766\n",
      "Starting epoch 58\n",
      "Loss after mini-batch     1: 16.540\n",
      "Loss after mini-batch    11: 2.396\n",
      "Loss after mini-batch    21: 5.602\n",
      "Loss after mini-batch    31: 6.228\n",
      "Loss after mini-batch    41: 35.873\n",
      "Loss after mini-batch    51: 8.675\n",
      "Loss after mini-batch    61: 0.181\n",
      "Loss after mini-batch    71: 1.524\n",
      "Loss after mini-batch    81: 3.535\n",
      "Loss after mini-batch    91: 30.230\n",
      "Loss after mini-batch   101: 3.012\n",
      "Loss after mini-batch   111: 0.118\n",
      "Loss after mini-batch   121: 0.771\n",
      "Loss after mini-batch   131: 3.465\n",
      "Loss after mini-batch   141: 0.824\n",
      "Loss after mini-batch   151: 12.424\n",
      "Loss after mini-batch   161: 1.697\n",
      "Loss after mini-batch   171: 0.455\n",
      "Loss after mini-batch   181: 8.165\n",
      "Loss after mini-batch   191: 0.551\n",
      "Loss after mini-batch   201: 0.714\n",
      "Loss after mini-batch   211: 0.058\n",
      "Loss after mini-batch   221: 0.205\n",
      "Loss after mini-batch   231: 0.030\n",
      "Loss after mini-batch   241: 0.254\n",
      "Loss after mini-batch   251: 24.746\n",
      "Loss after mini-batch   261: 1.173\n",
      "Loss after mini-batch   271: 0.500\n",
      "Loss after mini-batch   281: 0.654\n",
      "Loss after mini-batch   291: 3.560\n",
      "Loss after mini-batch   301: 13.887\n",
      "Loss after mini-batch   311: 1.156\n",
      "Loss after mini-batch   321: 2.780\n",
      "Loss after mini-batch   331: 7.357\n",
      "Loss after mini-batch   341: 1.174\n",
      "Loss after mini-batch   351: 0.419\n",
      "Loss after mini-batch   361: 1.049\n",
      "Loss after mini-batch   371: 1.241\n",
      "Training Loss: 0.654 \t\t Validation Loss:4.484\n",
      "Starting epoch 59\n",
      "Loss after mini-batch     1: 1.337\n",
      "Loss after mini-batch    11: 0.603\n",
      "Loss after mini-batch    21: 5.212\n",
      "Loss after mini-batch    31: 0.097\n",
      "Loss after mini-batch    41: 6.826\n",
      "Loss after mini-batch    51: 3.578\n",
      "Loss after mini-batch    61: 0.114\n",
      "Loss after mini-batch    71: 2.282\n",
      "Loss after mini-batch    81: 0.219\n",
      "Loss after mini-batch    91: 12.049\n",
      "Loss after mini-batch   101: 0.100\n",
      "Loss after mini-batch   111: 2.827\n",
      "Loss after mini-batch   121: 1.323\n",
      "Loss after mini-batch   131: 1.634\n",
      "Loss after mini-batch   141: 2.068\n",
      "Loss after mini-batch   151: 1.111\n",
      "Loss after mini-batch   161: 1.850\n",
      "Loss after mini-batch   171: 9.187\n",
      "Loss after mini-batch   181: 7.327\n",
      "Loss after mini-batch   191: 5.917\n",
      "Loss after mini-batch   201: 0.065\n",
      "Loss after mini-batch   211: 0.373\n",
      "Loss after mini-batch   221: 0.262\n",
      "Loss after mini-batch   231: 2.626\n",
      "Loss after mini-batch   241: 44.547\n",
      "Loss after mini-batch   251: 2.026\n",
      "Loss after mini-batch   261: 1.196\n",
      "Loss after mini-batch   271: 1.443\n",
      "Loss after mini-batch   281: 6.197\n",
      "Loss after mini-batch   291: 0.159\n",
      "Loss after mini-batch   301: 0.235\n",
      "Loss after mini-batch   311: 0.098\n",
      "Loss after mini-batch   321: 0.079\n",
      "Loss after mini-batch   331: 29.628\n",
      "Loss after mini-batch   341: 4.831\n",
      "Loss after mini-batch   351: 0.224\n",
      "Loss after mini-batch   361: 0.470\n",
      "Loss after mini-batch   371: 26.803\n",
      "Training Loss: 0.054 \t\t Validation Loss:16.520\n",
      "Starting epoch 60\n",
      "Loss after mini-batch     1: 0.072\n",
      "Loss after mini-batch    11: 12.291\n",
      "Loss after mini-batch    21: 11.154\n",
      "Loss after mini-batch    31: 20.473\n",
      "Loss after mini-batch    41: 0.589\n",
      "Loss after mini-batch    51: 3.517\n",
      "Loss after mini-batch    61: 13.362\n",
      "Loss after mini-batch    71: 16.791\n",
      "Loss after mini-batch    81: 0.084\n",
      "Loss after mini-batch    91: 8.707\n",
      "Loss after mini-batch   101: 1.077\n",
      "Loss after mini-batch   111: 1.475\n",
      "Loss after mini-batch   121: 0.228\n",
      "Loss after mini-batch   131: 1.127\n",
      "Loss after mini-batch   141: 0.398\n",
      "Loss after mini-batch   151: 2.139\n",
      "Loss after mini-batch   161: 3.798\n",
      "Loss after mini-batch   171: 0.612\n",
      "Loss after mini-batch   181: 0.186\n",
      "Loss after mini-batch   191: 2.740\n",
      "Loss after mini-batch   201: 2.954\n",
      "Loss after mini-batch   211: 15.141\n",
      "Loss after mini-batch   221: 1.969\n",
      "Loss after mini-batch   231: 1.651\n",
      "Loss after mini-batch   241: 8.664\n",
      "Loss after mini-batch   251: 0.139\n",
      "Loss after mini-batch   261: 14.677\n",
      "Loss after mini-batch   271: 0.882\n",
      "Loss after mini-batch   281: 0.273\n",
      "Loss after mini-batch   291: 0.128\n",
      "Loss after mini-batch   301: 0.184\n",
      "Loss after mini-batch   311: 0.138\n",
      "Loss after mini-batch   321: 3.452\n",
      "Loss after mini-batch   331: 5.559\n",
      "Loss after mini-batch   341: 0.505\n",
      "Loss after mini-batch   351: 3.122\n",
      "Loss after mini-batch   361: 5.497\n",
      "Loss after mini-batch   371: 0.161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.324 \t\t Validation Loss:34.815\n",
      "Starting epoch 61\n",
      "Loss after mini-batch     1: 26.219\n",
      "Loss after mini-batch    11: 1.041\n",
      "Loss after mini-batch    21: 0.621\n",
      "Loss after mini-batch    31: 0.199\n",
      "Loss after mini-batch    41: 1.489\n",
      "Loss after mini-batch    51: 1.840\n",
      "Loss after mini-batch    61: 0.162\n",
      "Loss after mini-batch    71: 5.880\n",
      "Loss after mini-batch    81: 0.108\n",
      "Loss after mini-batch    91: 1.593\n",
      "Loss after mini-batch   101: 0.028\n",
      "Loss after mini-batch   111: 0.023\n",
      "Loss after mini-batch   121: 0.471\n",
      "Loss after mini-batch   131: 5.664\n",
      "Loss after mini-batch   141: 1.306\n",
      "Loss after mini-batch   151: 0.270\n",
      "Loss after mini-batch   161: 9.272\n",
      "Loss after mini-batch   171: 0.107\n",
      "Loss after mini-batch   181: 0.920\n",
      "Loss after mini-batch   191: 0.195\n",
      "Loss after mini-batch   201: 0.940\n",
      "Loss after mini-batch   211: 2.205\n",
      "Loss after mini-batch   221: 3.318\n",
      "Loss after mini-batch   231: 0.104\n",
      "Loss after mini-batch   241: 17.908\n",
      "Loss after mini-batch   251: 1.176\n",
      "Loss after mini-batch   261: 11.053\n",
      "Loss after mini-batch   271: 2.299\n",
      "Loss after mini-batch   281: 1.200\n",
      "Loss after mini-batch   291: 1.061\n",
      "Loss after mini-batch   301: 1.276\n",
      "Loss after mini-batch   311: 0.116\n",
      "Loss after mini-batch   321: 1.201\n",
      "Loss after mini-batch   331: 0.270\n",
      "Loss after mini-batch   341: 0.074\n",
      "Loss after mini-batch   351: 0.103\n",
      "Loss after mini-batch   361: 6.486\n",
      "Loss after mini-batch   371: 0.257\n",
      "Training Loss: 0.265 \t\t Validation Loss:7.525\n",
      "Starting epoch 62\n",
      "Loss after mini-batch     1: 1.266\n",
      "Loss after mini-batch    11: 0.049\n",
      "Loss after mini-batch    21: 0.127\n",
      "Loss after mini-batch    31: 0.517\n",
      "Loss after mini-batch    41: 0.930\n",
      "Loss after mini-batch    51: 4.750\n",
      "Loss after mini-batch    61: 1.135\n",
      "Loss after mini-batch    71: 2.557\n",
      "Loss after mini-batch    81: 3.927\n",
      "Loss after mini-batch    91: 2.771\n",
      "Loss after mini-batch   101: 5.567\n",
      "Loss after mini-batch   111: 14.908\n",
      "Loss after mini-batch   121: 3.677\n",
      "Loss after mini-batch   131: 0.410\n",
      "Loss after mini-batch   141: 0.119\n",
      "Loss after mini-batch   151: 23.080\n",
      "Loss after mini-batch   161: 9.044\n",
      "Loss after mini-batch   171: 6.936\n",
      "Loss after mini-batch   181: 1.779\n",
      "Loss after mini-batch   191: 1.736\n",
      "Loss after mini-batch   201: 1.110\n",
      "Loss after mini-batch   211: 6.912\n",
      "Loss after mini-batch   221: 0.167\n",
      "Loss after mini-batch   231: 2.456\n",
      "Loss after mini-batch   241: 4.102\n",
      "Loss after mini-batch   251: 0.203\n",
      "Loss after mini-batch   261: 48.037\n",
      "Loss after mini-batch   271: 2.133\n",
      "Loss after mini-batch   281: 15.480\n",
      "Loss after mini-batch   291: 1.094\n",
      "Loss after mini-batch   301: 0.470\n",
      "Loss after mini-batch   311: 0.046\n",
      "Loss after mini-batch   321: 0.515\n",
      "Loss after mini-batch   331: 11.567\n",
      "Loss after mini-batch   341: 28.438\n",
      "Loss after mini-batch   351: 6.814\n",
      "Loss after mini-batch   361: 0.371\n",
      "Loss after mini-batch   371: 0.297\n",
      "Training Loss: 0.158 \t\t Validation Loss:8.514\n",
      "Starting epoch 63\n",
      "Loss after mini-batch     1: 32.265\n",
      "Loss after mini-batch    11: 10.475\n",
      "Loss after mini-batch    21: 0.254\n",
      "Loss after mini-batch    31: 19.330\n",
      "Loss after mini-batch    41: 1.414\n",
      "Loss after mini-batch    51: 17.138\n",
      "Loss after mini-batch    61: 0.254\n",
      "Loss after mini-batch    71: 2.095\n",
      "Loss after mini-batch    81: 0.048\n",
      "Loss after mini-batch    91: 2.018\n",
      "Loss after mini-batch   101: 4.047\n",
      "Loss after mini-batch   111: 8.955\n",
      "Loss after mini-batch   121: 36.228\n",
      "Loss after mini-batch   131: 13.268\n",
      "Loss after mini-batch   141: 0.465\n",
      "Loss after mini-batch   151: 0.156\n",
      "Loss after mini-batch   161: 0.141\n",
      "Loss after mini-batch   171: 0.087\n",
      "Loss after mini-batch   181: 0.586\n",
      "Loss after mini-batch   191: 0.144\n",
      "Loss after mini-batch   201: 13.515\n",
      "Loss after mini-batch   211: 0.653\n",
      "Loss after mini-batch   221: 4.405\n",
      "Loss after mini-batch   231: 0.119\n",
      "Loss after mini-batch   241: 1.792\n",
      "Loss after mini-batch   251: 0.030\n",
      "Loss after mini-batch   261: 0.029\n",
      "Loss after mini-batch   271: 0.261\n",
      "Loss after mini-batch   281: 0.223\n",
      "Loss after mini-batch   291: 2.057\n",
      "Loss after mini-batch   301: 20.545\n",
      "Loss after mini-batch   311: 1.081\n",
      "Loss after mini-batch   321: 0.551\n",
      "Loss after mini-batch   331: 0.317\n",
      "Loss after mini-batch   341: 9.187\n",
      "Loss after mini-batch   351: 41.262\n",
      "Loss after mini-batch   361: 10.393\n",
      "Loss after mini-batch   371: 10.049\n",
      "Training Loss: 6.789 \t\t Validation Loss:8.428\n",
      "Starting epoch 64\n",
      "Loss after mini-batch     1: 0.617\n",
      "Loss after mini-batch    11: 9.400\n",
      "Loss after mini-batch    21: 0.088\n",
      "Loss after mini-batch    31: 9.744\n",
      "Loss after mini-batch    41: 0.508\n",
      "Loss after mini-batch    51: 1.493\n",
      "Loss after mini-batch    61: 0.031\n",
      "Loss after mini-batch    71: 0.063\n",
      "Loss after mini-batch    81: 15.289\n",
      "Loss after mini-batch    91: 13.673\n",
      "Loss after mini-batch   101: 5.415\n",
      "Loss after mini-batch   111: 1.073\n",
      "Loss after mini-batch   121: 1.799\n",
      "Loss after mini-batch   131: 14.401\n",
      "Loss after mini-batch   141: 0.313\n",
      "Loss after mini-batch   151: 0.533\n",
      "Loss after mini-batch   161: 1.383\n",
      "Loss after mini-batch   171: 1.132\n",
      "Loss after mini-batch   181: 1.016\n",
      "Loss after mini-batch   191: 3.472\n",
      "Loss after mini-batch   201: 10.202\n",
      "Loss after mini-batch   211: 6.562\n",
      "Loss after mini-batch   221: 0.953\n",
      "Loss after mini-batch   231: 29.067\n",
      "Loss after mini-batch   241: 6.736\n",
      "Loss after mini-batch   251: 2.256\n",
      "Loss after mini-batch   261: 0.213\n",
      "Loss after mini-batch   271: 6.729\n",
      "Loss after mini-batch   281: 0.974\n",
      "Loss after mini-batch   291: 0.961\n",
      "Loss after mini-batch   301: 1.930\n",
      "Loss after mini-batch   311: 3.329\n",
      "Loss after mini-batch   321: 1.205\n",
      "Loss after mini-batch   331: 0.075\n",
      "Loss after mini-batch   341: 5.156\n",
      "Loss after mini-batch   351: 0.743\n",
      "Loss after mini-batch   361: 0.443\n",
      "Loss after mini-batch   371: 8.561\n",
      "Training Loss: 2.802 \t\t Validation Loss:3.190\n",
      "Starting epoch 65\n",
      "Loss after mini-batch     1: 13.365\n",
      "Loss after mini-batch    11: 2.888\n",
      "Loss after mini-batch    21: 1.536\n",
      "Loss after mini-batch    31: 1.058\n",
      "Loss after mini-batch    41: 12.874\n",
      "Loss after mini-batch    51: 0.546\n",
      "Loss after mini-batch    61: 2.488\n",
      "Loss after mini-batch    71: 1.527\n",
      "Loss after mini-batch    81: 1.581\n",
      "Loss after mini-batch    91: 4.156\n",
      "Loss after mini-batch   101: 0.038\n",
      "Loss after mini-batch   111: 0.920\n",
      "Loss after mini-batch   121: 0.089\n",
      "Loss after mini-batch   131: 0.037\n",
      "Loss after mini-batch   141: 0.134\n",
      "Loss after mini-batch   151: 7.421\n",
      "Loss after mini-batch   161: 0.229\n",
      "Loss after mini-batch   171: 0.064\n",
      "Loss after mini-batch   181: 0.009\n",
      "Loss after mini-batch   191: 3.478\n",
      "Loss after mini-batch   201: 1.457\n",
      "Loss after mini-batch   211: 6.519\n",
      "Loss after mini-batch   221: 1.314\n",
      "Loss after mini-batch   231: 0.177\n",
      "Loss after mini-batch   241: 0.053\n",
      "Loss after mini-batch   251: 1.225\n",
      "Loss after mini-batch   261: 0.379\n",
      "Loss after mini-batch   271: 35.297\n",
      "Loss after mini-batch   281: 0.066\n",
      "Loss after mini-batch   291: 10.085\n",
      "Loss after mini-batch   301: 0.191\n",
      "Loss after mini-batch   311: 0.579\n",
      "Loss after mini-batch   321: 10.908\n",
      "Loss after mini-batch   331: 3.532\n",
      "Loss after mini-batch   341: 11.645\n",
      "Loss after mini-batch   351: 1.068\n",
      "Loss after mini-batch   361: 0.302\n",
      "Loss after mini-batch   371: 27.150\n",
      "Training Loss: 1.670 \t\t Validation Loss:1.747\n",
      "Starting epoch 66\n",
      "Loss after mini-batch     1: 0.823\n",
      "Loss after mini-batch    11: 0.266\n",
      "Loss after mini-batch    21: 18.084\n",
      "Loss after mini-batch    31: 6.199\n",
      "Loss after mini-batch    41: 0.641\n",
      "Loss after mini-batch    51: 1.983\n",
      "Loss after mini-batch    61: 1.316\n",
      "Loss after mini-batch    71: 0.272\n",
      "Loss after mini-batch    81: 0.285\n",
      "Loss after mini-batch    91: 0.372\n",
      "Loss after mini-batch   101: 0.095\n",
      "Loss after mini-batch   111: 0.269\n",
      "Loss after mini-batch   121: 0.532\n",
      "Loss after mini-batch   131: 0.211\n",
      "Loss after mini-batch   141: 0.036\n",
      "Loss after mini-batch   151: 4.866\n",
      "Loss after mini-batch   161: 2.460\n",
      "Loss after mini-batch   171: 9.621\n",
      "Loss after mini-batch   181: 8.008\n",
      "Loss after mini-batch   191: 0.929\n",
      "Loss after mini-batch   201: 1.117\n",
      "Loss after mini-batch   211: 1.605\n",
      "Loss after mini-batch   221: 1.072\n",
      "Loss after mini-batch   231: 0.113\n",
      "Loss after mini-batch   241: 2.176\n",
      "Loss after mini-batch   251: 0.977\n",
      "Loss after mini-batch   261: 7.119\n",
      "Loss after mini-batch   271: 0.520\n",
      "Loss after mini-batch   281: 0.306\n",
      "Loss after mini-batch   291: 7.201\n",
      "Loss after mini-batch   301: 8.468\n",
      "Loss after mini-batch   311: 0.192\n",
      "Loss after mini-batch   321: 20.735\n",
      "Loss after mini-batch   331: 4.033\n",
      "Loss after mini-batch   341: 8.244\n",
      "Loss after mini-batch   351: 0.123\n",
      "Loss after mini-batch   361: 5.327\n",
      "Loss after mini-batch   371: 1.734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.103 \t\t Validation Loss:0.357\n",
      "Starting epoch 67\n",
      "Loss after mini-batch     1: 0.372\n",
      "Loss after mini-batch    11: 1.386\n",
      "Loss after mini-batch    21: 1.463\n",
      "Loss after mini-batch    31: 3.059\n",
      "Loss after mini-batch    41: 1.079\n",
      "Loss after mini-batch    51: 0.013\n",
      "Loss after mini-batch    61: 5.314\n",
      "Loss after mini-batch    71: 0.614\n",
      "Loss after mini-batch    81: 5.193\n",
      "Loss after mini-batch    91: 6.718\n",
      "Loss after mini-batch   101: 0.218\n",
      "Loss after mini-batch   111: 0.839\n",
      "Loss after mini-batch   121: 1.714\n",
      "Loss after mini-batch   131: 4.407\n",
      "Loss after mini-batch   141: 0.449\n",
      "Loss after mini-batch   151: 0.096\n",
      "Loss after mini-batch   161: 9.628\n",
      "Loss after mini-batch   171: 0.403\n",
      "Loss after mini-batch   181: 4.083\n",
      "Loss after mini-batch   191: 0.047\n",
      "Loss after mini-batch   201: 2.483\n",
      "Loss after mini-batch   211: 6.430\n",
      "Loss after mini-batch   221: 1.036\n",
      "Loss after mini-batch   231: 3.754\n",
      "Loss after mini-batch   241: 8.161\n",
      "Loss after mini-batch   251: 3.762\n",
      "Loss after mini-batch   261: 4.695\n",
      "Loss after mini-batch   271: 0.427\n",
      "Loss after mini-batch   281: 1.945\n",
      "Loss after mini-batch   291: 0.114\n",
      "Loss after mini-batch   301: 0.811\n",
      "Loss after mini-batch   311: 0.681\n",
      "Loss after mini-batch   321: 1.958\n",
      "Loss after mini-batch   331: 0.320\n",
      "Loss after mini-batch   341: 1.048\n",
      "Loss after mini-batch   351: 1.360\n",
      "Loss after mini-batch   361: 3.685\n",
      "Loss after mini-batch   371: 15.842\n",
      "Training Loss: 0.219 \t\t Validation Loss:0.558\n",
      "Starting epoch 68\n",
      "Loss after mini-batch     1: 2.246\n",
      "Loss after mini-batch    11: 0.222\n",
      "Loss after mini-batch    21: 0.954\n",
      "Loss after mini-batch    31: 1.946\n",
      "Loss after mini-batch    41: 10.838\n",
      "Loss after mini-batch    51: 0.130\n",
      "Loss after mini-batch    61: 0.508\n",
      "Loss after mini-batch    71: 1.178\n",
      "Loss after mini-batch    81: 1.318\n",
      "Loss after mini-batch    91: 4.252\n",
      "Loss after mini-batch   101: 0.237\n",
      "Loss after mini-batch   111: 0.343\n",
      "Loss after mini-batch   121: 0.633\n",
      "Loss after mini-batch   131: 0.770\n",
      "Loss after mini-batch   141: 5.478\n",
      "Loss after mini-batch   151: 0.212\n",
      "Loss after mini-batch   161: 0.362\n",
      "Loss after mini-batch   171: 0.184\n",
      "Loss after mini-batch   181: 0.029\n",
      "Loss after mini-batch   191: 2.948\n",
      "Loss after mini-batch   201: 0.098\n",
      "Loss after mini-batch   211: 5.063\n",
      "Loss after mini-batch   221: 0.496\n",
      "Loss after mini-batch   231: 12.003\n",
      "Loss after mini-batch   241: 2.095\n",
      "Loss after mini-batch   251: 2.424\n",
      "Loss after mini-batch   261: 26.353\n",
      "Loss after mini-batch   271: 0.390\n",
      "Loss after mini-batch   281: 0.367\n",
      "Loss after mini-batch   291: 1.324\n",
      "Loss after mini-batch   301: 0.122\n",
      "Loss after mini-batch   311: 17.915\n",
      "Loss after mini-batch   321: 10.626\n",
      "Loss after mini-batch   331: 2.396\n",
      "Loss after mini-batch   341: 1.493\n",
      "Loss after mini-batch   351: 1.654\n",
      "Loss after mini-batch   361: 4.059\n",
      "Loss after mini-batch   371: 6.979\n",
      "Training Loss: 1.329 \t\t Validation Loss:1.377\n",
      "Starting epoch 69\n",
      "Loss after mini-batch     1: 0.046\n",
      "Loss after mini-batch    11: 6.131\n",
      "Loss after mini-batch    21: 0.461\n",
      "Loss after mini-batch    31: 1.043\n",
      "Loss after mini-batch    41: 0.182\n",
      "Loss after mini-batch    51: 1.622\n",
      "Loss after mini-batch    61: 0.409\n",
      "Loss after mini-batch    71: 0.614\n",
      "Loss after mini-batch    81: 2.743\n",
      "Loss after mini-batch    91: 6.251\n",
      "Loss after mini-batch   101: 13.247\n",
      "Loss after mini-batch   111: 0.027\n",
      "Loss after mini-batch   121: 0.247\n",
      "Loss after mini-batch   131: 0.529\n",
      "Loss after mini-batch   141: 1.259\n",
      "Loss after mini-batch   151: 6.831\n",
      "Loss after mini-batch   161: 3.602\n",
      "Loss after mini-batch   171: 8.030\n",
      "Loss after mini-batch   181: 0.118\n",
      "Loss after mini-batch   191: 0.078\n",
      "Loss after mini-batch   201: 0.817\n",
      "Loss after mini-batch   211: 3.628\n",
      "Loss after mini-batch   221: 0.052\n",
      "Loss after mini-batch   231: 0.076\n",
      "Loss after mini-batch   241: 0.181\n",
      "Loss after mini-batch   251: 1.993\n",
      "Loss after mini-batch   261: 0.790\n",
      "Loss after mini-batch   271: 2.862\n",
      "Loss after mini-batch   281: 3.477\n",
      "Loss after mini-batch   291: 3.819\n",
      "Loss after mini-batch   301: 0.108\n",
      "Loss after mini-batch   311: 4.954\n",
      "Loss after mini-batch   321: 1.576\n",
      "Loss after mini-batch   331: 0.407\n",
      "Loss after mini-batch   341: 0.119\n",
      "Loss after mini-batch   351: 2.515\n",
      "Loss after mini-batch   361: 0.457\n",
      "Loss after mini-batch   371: 0.397\n",
      "Training Loss: 4.898 \t\t Validation Loss:7.424\n",
      "Starting epoch 70\n",
      "Loss after mini-batch     1: 0.297\n",
      "Loss after mini-batch    11: 4.687\n",
      "Loss after mini-batch    21: 2.141\n",
      "Loss after mini-batch    31: 1.745\n",
      "Loss after mini-batch    41: 24.109\n",
      "Loss after mini-batch    51: 0.981\n",
      "Loss after mini-batch    61: 0.039\n",
      "Loss after mini-batch    71: 0.031\n",
      "Loss after mini-batch    81: 26.459\n",
      "Loss after mini-batch    91: 26.895\n",
      "Loss after mini-batch   101: 0.104\n",
      "Loss after mini-batch   111: 0.910\n",
      "Loss after mini-batch   121: 2.006\n",
      "Loss after mini-batch   131: 3.457\n",
      "Loss after mini-batch   141: 0.175\n",
      "Loss after mini-batch   151: 13.757\n",
      "Loss after mini-batch   161: 1.593\n",
      "Loss after mini-batch   171: 2.251\n",
      "Loss after mini-batch   181: 0.532\n",
      "Loss after mini-batch   191: 0.248\n",
      "Loss after mini-batch   201: 2.608\n",
      "Loss after mini-batch   211: 24.897\n",
      "Loss after mini-batch   221: 0.157\n",
      "Loss after mini-batch   231: 4.071\n",
      "Loss after mini-batch   241: 6.290\n",
      "Loss after mini-batch   251: 0.549\n",
      "Loss after mini-batch   261: 1.708\n",
      "Loss after mini-batch   271: 1.317\n",
      "Loss after mini-batch   281: 0.673\n",
      "Loss after mini-batch   291: 8.619\n",
      "Loss after mini-batch   301: 19.105\n",
      "Loss after mini-batch   311: 1.463\n",
      "Loss after mini-batch   321: 0.550\n",
      "Loss after mini-batch   331: 0.288\n",
      "Loss after mini-batch   341: 1.338\n",
      "Loss after mini-batch   351: 0.127\n",
      "Loss after mini-batch   361: 0.239\n",
      "Loss after mini-batch   371: 8.440\n",
      "Training Loss: 0.488 \t\t Validation Loss:1.702\n",
      "Starting epoch 71\n",
      "Loss after mini-batch     1: 1.310\n",
      "Loss after mini-batch    11: 8.613\n",
      "Loss after mini-batch    21: 0.194\n",
      "Loss after mini-batch    31: 7.832\n",
      "Loss after mini-batch    41: 0.192\n",
      "Loss after mini-batch    51: 0.884\n",
      "Loss after mini-batch    61: 2.149\n",
      "Loss after mini-batch    71: 0.923\n",
      "Loss after mini-batch    81: 0.146\n",
      "Loss after mini-batch    91: 0.310\n",
      "Loss after mini-batch   101: 0.298\n",
      "Loss after mini-batch   111: 2.458\n",
      "Loss after mini-batch   121: 2.342\n",
      "Loss after mini-batch   131: 2.458\n",
      "Loss after mini-batch   141: 3.580\n",
      "Loss after mini-batch   151: 11.914\n",
      "Loss after mini-batch   161: 2.566\n",
      "Loss after mini-batch   171: 0.187\n",
      "Loss after mini-batch   181: 23.237\n",
      "Loss after mini-batch   191: 5.328\n",
      "Loss after mini-batch   201: 0.027\n",
      "Loss after mini-batch   211: 7.588\n",
      "Loss after mini-batch   221: 0.603\n",
      "Loss after mini-batch   231: 0.254\n",
      "Loss after mini-batch   241: 0.223\n",
      "Loss after mini-batch   251: 1.963\n",
      "Loss after mini-batch   261: 9.291\n",
      "Loss after mini-batch   271: 0.150\n",
      "Loss after mini-batch   281: 0.334\n",
      "Loss after mini-batch   291: 0.266\n",
      "Loss after mini-batch   301: 5.475\n",
      "Loss after mini-batch   311: 9.796\n",
      "Loss after mini-batch   321: 0.275\n",
      "Loss after mini-batch   331: 0.818\n",
      "Loss after mini-batch   341: 0.067\n",
      "Loss after mini-batch   351: 1.587\n",
      "Loss after mini-batch   361: 1.821\n",
      "Loss after mini-batch   371: 1.164\n",
      "Training Loss: 4.394 \t\t Validation Loss:4.855\n",
      "Starting epoch 72\n",
      "Loss after mini-batch     1: 0.073\n",
      "Loss after mini-batch    11: 1.604\n",
      "Loss after mini-batch    21: 0.194\n",
      "Loss after mini-batch    31: 1.130\n",
      "Loss after mini-batch    41: 1.854\n",
      "Loss after mini-batch    51: 0.915\n",
      "Loss after mini-batch    61: 0.149\n",
      "Loss after mini-batch    71: 0.722\n",
      "Loss after mini-batch    81: 2.412\n",
      "Loss after mini-batch    91: 8.754\n",
      "Loss after mini-batch   101: 2.035\n",
      "Loss after mini-batch   111: 0.188\n",
      "Loss after mini-batch   121: 0.264\n",
      "Loss after mini-batch   131: 1.904\n",
      "Loss after mini-batch   141: 0.337\n",
      "Loss after mini-batch   151: 6.602\n",
      "Loss after mini-batch   161: 0.798\n",
      "Loss after mini-batch   171: 5.707\n",
      "Loss after mini-batch   181: 5.270\n",
      "Loss after mini-batch   191: 0.286\n",
      "Loss after mini-batch   201: 3.068\n",
      "Loss after mini-batch   211: 8.565\n",
      "Loss after mini-batch   221: 0.299\n",
      "Loss after mini-batch   231: 9.108\n",
      "Loss after mini-batch   241: 2.583\n",
      "Loss after mini-batch   251: 3.484\n",
      "Loss after mini-batch   261: 1.347\n",
      "Loss after mini-batch   271: 0.063\n",
      "Loss after mini-batch   281: 0.328\n",
      "Loss after mini-batch   291: 2.967\n",
      "Loss after mini-batch   301: 0.050\n",
      "Loss after mini-batch   311: 0.038\n",
      "Loss after mini-batch   321: 4.041\n",
      "Loss after mini-batch   331: 1.065\n",
      "Loss after mini-batch   341: 0.329\n",
      "Loss after mini-batch   351: 0.053\n",
      "Loss after mini-batch   361: 3.366\n",
      "Loss after mini-batch   371: 1.444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.733 \t\t Validation Loss:9.333\n",
      "Starting epoch 73\n",
      "Loss after mini-batch     1: 3.955\n",
      "Loss after mini-batch    11: 15.072\n",
      "Loss after mini-batch    21: 1.375\n",
      "Loss after mini-batch    31: 5.590\n",
      "Loss after mini-batch    41: 14.057\n",
      "Loss after mini-batch    51: 3.159\n",
      "Loss after mini-batch    61: 0.286\n",
      "Loss after mini-batch    71: 0.805\n",
      "Loss after mini-batch    81: 1.655\n",
      "Loss after mini-batch    91: 0.151\n",
      "Loss after mini-batch   101: 0.151\n",
      "Loss after mini-batch   111: 6.939\n",
      "Loss after mini-batch   121: 18.936\n",
      "Loss after mini-batch   131: 1.734\n",
      "Loss after mini-batch   141: 1.857\n",
      "Loss after mini-batch   151: 2.146\n",
      "Loss after mini-batch   161: 1.595\n",
      "Loss after mini-batch   171: 1.941\n",
      "Loss after mini-batch   181: 0.915\n",
      "Loss after mini-batch   191: 7.629\n",
      "Loss after mini-batch   201: 0.542\n",
      "Loss after mini-batch   211: 2.640\n",
      "Loss after mini-batch   221: 0.646\n",
      "Loss after mini-batch   231: 0.066\n",
      "Loss after mini-batch   241: 1.549\n",
      "Loss after mini-batch   251: 1.141\n",
      "Loss after mini-batch   261: 0.264\n",
      "Loss after mini-batch   271: 0.087\n",
      "Loss after mini-batch   281: 1.344\n",
      "Loss after mini-batch   291: 7.871\n",
      "Loss after mini-batch   301: 0.065\n",
      "Loss after mini-batch   311: 0.828\n",
      "Loss after mini-batch   321: 0.292\n",
      "Loss after mini-batch   331: 0.350\n",
      "Loss after mini-batch   341: 0.507\n",
      "Loss after mini-batch   351: 5.233\n",
      "Loss after mini-batch   361: 0.158\n",
      "Loss after mini-batch   371: 0.383\n",
      "Training Loss: 0.992 \t\t Validation Loss:2.797\n",
      "Starting epoch 74\n",
      "Loss after mini-batch     1: 0.133\n",
      "Loss after mini-batch    11: 1.958\n",
      "Loss after mini-batch    21: 0.330\n",
      "Loss after mini-batch    31: 0.131\n",
      "Loss after mini-batch    41: 8.540\n",
      "Loss after mini-batch    51: 15.862\n",
      "Loss after mini-batch    61: 0.141\n",
      "Loss after mini-batch    71: 0.453\n",
      "Loss after mini-batch    81: 0.034\n",
      "Loss after mini-batch    91: 0.199\n",
      "Loss after mini-batch   101: 2.753\n",
      "Loss after mini-batch   111: 0.647\n",
      "Loss after mini-batch   121: 0.091\n",
      "Loss after mini-batch   131: 1.289\n",
      "Loss after mini-batch   141: 0.069\n",
      "Loss after mini-batch   151: 0.976\n",
      "Loss after mini-batch   161: 24.510\n",
      "Loss after mini-batch   171: 1.812\n",
      "Loss after mini-batch   181: 5.266\n",
      "Loss after mini-batch   191: 0.058\n",
      "Loss after mini-batch   201: 13.966\n",
      "Loss after mini-batch   211: 4.853\n",
      "Loss after mini-batch   221: 0.273\n",
      "Loss after mini-batch   231: 2.449\n",
      "Loss after mini-batch   241: 0.041\n",
      "Loss after mini-batch   251: 6.971\n",
      "Loss after mini-batch   261: 8.404\n",
      "Loss after mini-batch   271: 0.262\n",
      "Loss after mini-batch   281: 0.040\n",
      "Loss after mini-batch   291: 1.838\n",
      "Loss after mini-batch   301: 0.122\n",
      "Loss after mini-batch   311: 7.475\n",
      "Loss after mini-batch   321: 0.751\n",
      "Loss after mini-batch   331: 0.397\n",
      "Loss after mini-batch   341: 0.219\n",
      "Loss after mini-batch   351: 8.734\n",
      "Loss after mini-batch   361: 0.376\n",
      "Loss after mini-batch   371: 0.123\n",
      "Training Loss: 2.532 \t\t Validation Loss:4.131\n",
      "Starting epoch 75\n",
      "Loss after mini-batch     1: 1.329\n",
      "Loss after mini-batch    11: 11.918\n",
      "Loss after mini-batch    21: 0.536\n",
      "Loss after mini-batch    31: 3.684\n",
      "Loss after mini-batch    41: 6.347\n",
      "Loss after mini-batch    51: 4.967\n",
      "Loss after mini-batch    61: 0.213\n",
      "Loss after mini-batch    71: 1.587\n",
      "Loss after mini-batch    81: 0.402\n",
      "Loss after mini-batch    91: 1.070\n",
      "Loss after mini-batch   101: 6.624\n",
      "Loss after mini-batch   111: 0.318\n",
      "Loss after mini-batch   121: 0.552\n",
      "Loss after mini-batch   131: 30.549\n",
      "Loss after mini-batch   141: 0.261\n",
      "Loss after mini-batch   151: 0.183\n",
      "Loss after mini-batch   161: 1.745\n",
      "Loss after mini-batch   171: 1.894\n",
      "Loss after mini-batch   181: 3.129\n",
      "Loss after mini-batch   191: 0.104\n",
      "Loss after mini-batch   201: 7.208\n",
      "Loss after mini-batch   211: 0.711\n",
      "Loss after mini-batch   221: 3.726\n",
      "Loss after mini-batch   231: 0.103\n",
      "Loss after mini-batch   241: 0.192\n",
      "Loss after mini-batch   251: 0.178\n",
      "Loss after mini-batch   261: 3.940\n",
      "Loss after mini-batch   271: 0.060\n",
      "Loss after mini-batch   281: 3.202\n",
      "Loss after mini-batch   291: 0.528\n",
      "Loss after mini-batch   301: 0.710\n",
      "Loss after mini-batch   311: 1.682\n",
      "Loss after mini-batch   321: 0.228\n",
      "Loss after mini-batch   331: 0.734\n",
      "Loss after mini-batch   341: 1.357\n",
      "Loss after mini-batch   351: 4.944\n",
      "Loss after mini-batch   361: 0.156\n",
      "Loss after mini-batch   371: 0.905\n",
      "Training Loss: 9.096 \t\t Validation Loss:9.821\n",
      "Starting epoch 76\n",
      "Loss after mini-batch     1: 1.807\n",
      "Loss after mini-batch    11: 0.389\n",
      "Loss after mini-batch    21: 0.105\n",
      "Loss after mini-batch    31: 18.808\n",
      "Loss after mini-batch    41: 5.386\n",
      "Loss after mini-batch    51: 6.037\n",
      "Loss after mini-batch    61: 0.060\n",
      "Loss after mini-batch    71: 7.474\n",
      "Loss after mini-batch    81: 0.748\n",
      "Loss after mini-batch    91: 0.096\n",
      "Loss after mini-batch   101: 0.327\n",
      "Loss after mini-batch   111: 0.163\n",
      "Loss after mini-batch   121: 1.677\n",
      "Loss after mini-batch   131: 0.173\n",
      "Loss after mini-batch   141: 3.535\n",
      "Loss after mini-batch   151: 0.174\n",
      "Loss after mini-batch   161: 0.026\n",
      "Loss after mini-batch   171: 1.712\n",
      "Loss after mini-batch   181: 0.013\n",
      "Loss after mini-batch   191: 15.115\n",
      "Loss after mini-batch   201: 27.393\n",
      "Loss after mini-batch   211: 8.009\n",
      "Loss after mini-batch   221: 2.631\n",
      "Loss after mini-batch   231: 1.383\n",
      "Loss after mini-batch   241: 0.372\n",
      "Loss after mini-batch   251: 3.937\n",
      "Loss after mini-batch   261: 2.141\n",
      "Loss after mini-batch   271: 0.625\n",
      "Loss after mini-batch   281: 0.235\n",
      "Loss after mini-batch   291: 0.283\n",
      "Loss after mini-batch   301: 12.919\n",
      "Loss after mini-batch   311: 1.872\n",
      "Loss after mini-batch   321: 0.157\n",
      "Loss after mini-batch   331: 0.501\n",
      "Loss after mini-batch   341: 3.887\n",
      "Loss after mini-batch   351: 2.299\n",
      "Loss after mini-batch   361: 0.856\n",
      "Loss after mini-batch   371: 1.126\n",
      "Training Loss: 2.987 \t\t Validation Loss:4.762\n",
      "Starting epoch 77\n",
      "Loss after mini-batch     1: 0.105\n",
      "Loss after mini-batch    11: 11.296\n",
      "Loss after mini-batch    21: 0.310\n",
      "Loss after mini-batch    31: 14.694\n",
      "Loss after mini-batch    41: 7.558\n",
      "Loss after mini-batch    51: 2.981\n",
      "Loss after mini-batch    61: 0.318\n",
      "Loss after mini-batch    71: 2.258\n",
      "Loss after mini-batch    81: 1.869\n",
      "Loss after mini-batch    91: 1.115\n",
      "Loss after mini-batch   101: 0.107\n",
      "Loss after mini-batch   111: 3.072\n",
      "Loss after mini-batch   121: 5.832\n",
      "Loss after mini-batch   131: 0.144\n",
      "Loss after mini-batch   141: 0.163\n",
      "Loss after mini-batch   151: 2.939\n",
      "Loss after mini-batch   161: 42.714\n",
      "Loss after mini-batch   171: 1.914\n",
      "Loss after mini-batch   181: 0.133\n",
      "Loss after mini-batch   191: 17.832\n",
      "Loss after mini-batch   201: 2.793\n",
      "Loss after mini-batch   211: 1.349\n",
      "Loss after mini-batch   221: 7.292\n",
      "Loss after mini-batch   231: 0.556\n",
      "Loss after mini-batch   241: 0.954\n",
      "Loss after mini-batch   251: 0.128\n",
      "Loss after mini-batch   261: 2.505\n",
      "Loss after mini-batch   271: 0.018\n",
      "Loss after mini-batch   281: 0.909\n",
      "Loss after mini-batch   291: 0.905\n",
      "Loss after mini-batch   301: 0.330\n",
      "Loss after mini-batch   311: 6.040\n",
      "Loss after mini-batch   321: 23.450\n",
      "Loss after mini-batch   331: 4.909\n",
      "Loss after mini-batch   341: 24.557\n",
      "Loss after mini-batch   351: 0.776\n",
      "Loss after mini-batch   361: 4.768\n",
      "Loss after mini-batch   371: 25.107\n",
      "Training Loss: 2.762 \t\t Validation Loss:6.879\n",
      "Starting epoch 78\n",
      "Loss after mini-batch     1: 0.184\n",
      "Loss after mini-batch    11: 1.303\n",
      "Loss after mini-batch    21: 2.372\n",
      "Loss after mini-batch    31: 0.290\n",
      "Loss after mini-batch    41: 0.443\n",
      "Loss after mini-batch    51: 25.220\n",
      "Loss after mini-batch    61: 0.082\n",
      "Loss after mini-batch    71: 0.260\n",
      "Loss after mini-batch    81: 2.829\n",
      "Loss after mini-batch    91: 0.840\n",
      "Loss after mini-batch   101: 4.030\n",
      "Loss after mini-batch   111: 0.156\n",
      "Loss after mini-batch   121: 4.145\n",
      "Loss after mini-batch   131: 22.014\n",
      "Loss after mini-batch   141: 0.670\n",
      "Loss after mini-batch   151: 1.488\n",
      "Loss after mini-batch   161: 0.826\n",
      "Loss after mini-batch   171: 2.505\n",
      "Loss after mini-batch   181: 2.916\n",
      "Loss after mini-batch   191: 0.041\n",
      "Loss after mini-batch   201: 0.315\n",
      "Loss after mini-batch   211: 4.166\n",
      "Loss after mini-batch   221: 0.606\n",
      "Loss after mini-batch   231: 0.189\n",
      "Loss after mini-batch   241: 0.063\n",
      "Loss after mini-batch   251: 0.155\n",
      "Loss after mini-batch   261: 1.113\n",
      "Loss after mini-batch   271: 1.622\n",
      "Loss after mini-batch   281: 0.242\n",
      "Loss after mini-batch   291: 0.846\n",
      "Loss after mini-batch   301: 4.451\n",
      "Loss after mini-batch   311: 0.912\n",
      "Loss after mini-batch   321: 0.058\n",
      "Loss after mini-batch   331: 3.434\n",
      "Loss after mini-batch   341: 0.309\n",
      "Loss after mini-batch   351: 1.513\n",
      "Loss after mini-batch   361: 0.361\n",
      "Loss after mini-batch   371: 0.755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.418 \t\t Validation Loss:7.893\n",
      "Starting epoch 79\n",
      "Loss after mini-batch     1: 3.430\n",
      "Loss after mini-batch    11: 4.230\n",
      "Loss after mini-batch    21: 0.273\n",
      "Loss after mini-batch    31: 0.045\n",
      "Loss after mini-batch    41: 4.005\n",
      "Loss after mini-batch    51: 0.056\n",
      "Loss after mini-batch    61: 0.427\n",
      "Loss after mini-batch    71: 3.087\n",
      "Loss after mini-batch    81: 32.291\n",
      "Loss after mini-batch    91: 0.129\n",
      "Loss after mini-batch   101: 0.056\n",
      "Loss after mini-batch   111: 2.698\n",
      "Loss after mini-batch   121: 0.079\n",
      "Loss after mini-batch   131: 6.231\n",
      "Loss after mini-batch   141: 9.935\n",
      "Loss after mini-batch   151: 0.151\n",
      "Loss after mini-batch   161: 6.139\n",
      "Loss after mini-batch   171: 13.921\n",
      "Loss after mini-batch   181: 0.136\n",
      "Loss after mini-batch   191: 8.057\n",
      "Loss after mini-batch   201: 16.061\n",
      "Loss after mini-batch   211: 1.363\n",
      "Loss after mini-batch   221: 1.841\n",
      "Loss after mini-batch   231: 0.650\n",
      "Loss after mini-batch   241: 4.555\n",
      "Loss after mini-batch   251: 0.024\n",
      "Loss after mini-batch   261: 0.167\n",
      "Loss after mini-batch   271: 0.504\n",
      "Loss after mini-batch   281: 0.676\n",
      "Loss after mini-batch   291: 0.143\n",
      "Loss after mini-batch   301: 0.031\n",
      "Loss after mini-batch   311: 0.209\n",
      "Loss after mini-batch   321: 0.217\n",
      "Loss after mini-batch   331: 0.223\n",
      "Loss after mini-batch   341: 0.137\n",
      "Loss after mini-batch   351: 0.274\n",
      "Loss after mini-batch   361: 5.321\n",
      "Loss after mini-batch   371: 0.319\n",
      "Training Loss: 0.263 \t\t Validation Loss:14.098\n",
      "Starting epoch 80\n",
      "Loss after mini-batch     1: 11.925\n",
      "Loss after mini-batch    11: 4.528\n",
      "Loss after mini-batch    21: 1.216\n",
      "Loss after mini-batch    31: 0.233\n",
      "Loss after mini-batch    41: 2.261\n",
      "Loss after mini-batch    51: 0.073\n",
      "Loss after mini-batch    61: 1.203\n",
      "Loss after mini-batch    71: 1.941\n",
      "Loss after mini-batch    81: 1.515\n",
      "Loss after mini-batch    91: 3.810\n",
      "Loss after mini-batch   101: 13.636\n",
      "Loss after mini-batch   111: 3.059\n",
      "Loss after mini-batch   121: 0.221\n",
      "Loss after mini-batch   131: 1.084\n",
      "Loss after mini-batch   141: 1.340\n",
      "Loss after mini-batch   151: 0.208\n",
      "Loss after mini-batch   161: 0.672\n",
      "Loss after mini-batch   171: 1.423\n",
      "Loss after mini-batch   181: 0.955\n",
      "Loss after mini-batch   191: 8.532\n",
      "Loss after mini-batch   201: 5.562\n",
      "Loss after mini-batch   211: 0.094\n",
      "Loss after mini-batch   221: 0.214\n",
      "Loss after mini-batch   231: 4.371\n",
      "Loss after mini-batch   241: 3.756\n",
      "Loss after mini-batch   251: 0.092\n",
      "Loss after mini-batch   261: 2.515\n",
      "Loss after mini-batch   271: 0.277\n",
      "Loss after mini-batch   281: 3.028\n",
      "Loss after mini-batch   291: 14.858\n",
      "Loss after mini-batch   301: 0.049\n",
      "Loss after mini-batch   311: 0.637\n",
      "Loss after mini-batch   321: 0.200\n",
      "Loss after mini-batch   331: 0.698\n",
      "Loss after mini-batch   341: 0.530\n",
      "Loss after mini-batch   351: 0.035\n",
      "Loss after mini-batch   361: 1.732\n",
      "Loss after mini-batch   371: 21.047\n",
      "Training Loss: 0.729 \t\t Validation Loss:1.126\n",
      "Starting epoch 81\n",
      "Loss after mini-batch     1: 2.863\n",
      "Loss after mini-batch    11: 2.784\n",
      "Loss after mini-batch    21: 0.075\n",
      "Loss after mini-batch    31: 3.639\n",
      "Loss after mini-batch    41: 1.032\n",
      "Loss after mini-batch    51: 42.363\n",
      "Loss after mini-batch    61: 7.328\n",
      "Loss after mini-batch    71: 0.028\n",
      "Loss after mini-batch    81: 0.944\n",
      "Loss after mini-batch    91: 0.072\n",
      "Loss after mini-batch   101: 3.266\n",
      "Loss after mini-batch   111: 0.075\n",
      "Loss after mini-batch   121: 0.401\n",
      "Loss after mini-batch   131: 0.278\n",
      "Loss after mini-batch   141: 0.754\n",
      "Loss after mini-batch   151: 0.182\n",
      "Loss after mini-batch   161: 9.248\n",
      "Loss after mini-batch   171: 1.272\n",
      "Loss after mini-batch   181: 0.117\n",
      "Loss after mini-batch   191: 1.551\n",
      "Loss after mini-batch   201: 0.249\n",
      "Loss after mini-batch   211: 12.909\n",
      "Loss after mini-batch   221: 1.297\n",
      "Loss after mini-batch   231: 1.502\n",
      "Loss after mini-batch   241: 2.221\n",
      "Loss after mini-batch   251: 3.195\n",
      "Loss after mini-batch   261: 1.137\n",
      "Loss after mini-batch   271: 0.086\n",
      "Loss after mini-batch   281: 1.569\n",
      "Loss after mini-batch   291: 3.027\n",
      "Loss after mini-batch   301: 3.089\n",
      "Loss after mini-batch   311: 4.452\n",
      "Loss after mini-batch   321: 3.194\n",
      "Loss after mini-batch   331: 0.043\n",
      "Loss after mini-batch   341: 0.259\n",
      "Loss after mini-batch   351: 4.580\n",
      "Loss after mini-batch   361: 9.868\n",
      "Loss after mini-batch   371: 0.184\n",
      "Training Loss: 1.282 \t\t Validation Loss:1.846\n",
      "Starting epoch 82\n",
      "Loss after mini-batch     1: 1.302\n",
      "Loss after mini-batch    11: 0.178\n",
      "Loss after mini-batch    21: 1.894\n",
      "Loss after mini-batch    31: 0.460\n",
      "Loss after mini-batch    41: 0.042\n",
      "Loss after mini-batch    51: 0.065\n",
      "Loss after mini-batch    61: 0.218\n",
      "Loss after mini-batch    71: 0.046\n",
      "Loss after mini-batch    81: 2.366\n",
      "Loss after mini-batch    91: 9.044\n",
      "Loss after mini-batch   101: 2.360\n",
      "Loss after mini-batch   111: 0.419\n",
      "Loss after mini-batch   121: 0.124\n",
      "Loss after mini-batch   131: 0.055\n",
      "Loss after mini-batch   141: 2.723\n",
      "Loss after mini-batch   151: 0.077\n",
      "Loss after mini-batch   161: 0.255\n",
      "Loss after mini-batch   171: 31.538\n",
      "Loss after mini-batch   181: 0.309\n",
      "Loss after mini-batch   191: 0.840\n",
      "Loss after mini-batch   201: 0.060\n",
      "Loss after mini-batch   211: 0.237\n",
      "Loss after mini-batch   221: 0.037\n",
      "Loss after mini-batch   231: 0.230\n",
      "Loss after mini-batch   241: 0.987\n",
      "Loss after mini-batch   251: 7.874\n",
      "Loss after mini-batch   261: 0.072\n",
      "Loss after mini-batch   271: 0.054\n",
      "Loss after mini-batch   281: 2.744\n",
      "Loss after mini-batch   291: 0.239\n",
      "Loss after mini-batch   301: 0.731\n",
      "Loss after mini-batch   311: 13.740\n",
      "Loss after mini-batch   321: 4.778\n",
      "Loss after mini-batch   331: 1.343\n",
      "Loss after mini-batch   341: 8.021\n",
      "Loss after mini-batch   351: 0.139\n",
      "Loss after mini-batch   361: 1.261\n",
      "Loss after mini-batch   371: 0.166\n",
      "Training Loss: 0.526 \t\t Validation Loss:1.763\n",
      "Starting epoch 83\n",
      "Loss after mini-batch     1: 9.840\n",
      "Loss after mini-batch    11: 0.100\n",
      "Loss after mini-batch    21: 0.109\n",
      "Loss after mini-batch    31: 4.596\n",
      "Loss after mini-batch    41: 0.051\n",
      "Loss after mini-batch    51: 3.446\n",
      "Loss after mini-batch    61: 2.532\n",
      "Loss after mini-batch    71: 11.009\n",
      "Loss after mini-batch    81: 3.603\n",
      "Loss after mini-batch    91: 0.515\n",
      "Loss after mini-batch   101: 0.126\n",
      "Loss after mini-batch   111: 0.487\n",
      "Loss after mini-batch   121: 0.351\n",
      "Loss after mini-batch   131: 3.260\n",
      "Loss after mini-batch   141: 2.520\n",
      "Loss after mini-batch   151: 0.142\n",
      "Loss after mini-batch   161: 0.140\n",
      "Loss after mini-batch   171: 2.188\n",
      "Loss after mini-batch   181: 1.859\n",
      "Loss after mini-batch   191: 2.406\n",
      "Loss after mini-batch   201: 6.128\n",
      "Loss after mini-batch   211: 19.455\n",
      "Loss after mini-batch   221: 2.946\n",
      "Loss after mini-batch   231: 0.974\n",
      "Loss after mini-batch   241: 18.868\n",
      "Loss after mini-batch   251: 0.095\n",
      "Loss after mini-batch   261: 2.043\n",
      "Loss after mini-batch   271: 0.185\n",
      "Loss after mini-batch   281: 1.132\n",
      "Loss after mini-batch   291: 0.073\n",
      "Loss after mini-batch   301: 0.297\n",
      "Loss after mini-batch   311: 1.070\n",
      "Loss after mini-batch   321: 2.996\n",
      "Loss after mini-batch   331: 6.803\n",
      "Loss after mini-batch   341: 1.097\n",
      "Loss after mini-batch   351: 1.826\n",
      "Loss after mini-batch   361: 0.161\n",
      "Loss after mini-batch   371: 5.725\n",
      "Training Loss: 6.107 \t\t Validation Loss:25.266\n",
      "Starting epoch 84\n",
      "Loss after mini-batch     1: 0.256\n",
      "Loss after mini-batch    11: 42.002\n",
      "Loss after mini-batch    21: 1.681\n",
      "Loss after mini-batch    31: 1.759\n",
      "Loss after mini-batch    41: 0.054\n",
      "Loss after mini-batch    51: 0.373\n",
      "Loss after mini-batch    61: 1.404\n",
      "Loss after mini-batch    71: 0.451\n",
      "Loss after mini-batch    81: 0.054\n",
      "Loss after mini-batch    91: 0.117\n",
      "Loss after mini-batch   101: 0.407\n",
      "Loss after mini-batch   111: 1.731\n",
      "Loss after mini-batch   121: 0.094\n",
      "Loss after mini-batch   131: 1.431\n",
      "Loss after mini-batch   141: 0.243\n",
      "Loss after mini-batch   151: 0.022\n",
      "Loss after mini-batch   161: 0.586\n",
      "Loss after mini-batch   171: 7.320\n",
      "Loss after mini-batch   181: 5.569\n",
      "Loss after mini-batch   191: 0.009\n",
      "Loss after mini-batch   201: 12.299\n",
      "Loss after mini-batch   211: 0.732\n",
      "Loss after mini-batch   221: 1.840\n",
      "Loss after mini-batch   231: 5.545\n",
      "Loss after mini-batch   241: 3.872\n",
      "Loss after mini-batch   251: 0.278\n",
      "Loss after mini-batch   261: 4.838\n",
      "Loss after mini-batch   271: 4.169\n",
      "Loss after mini-batch   281: 6.740\n",
      "Loss after mini-batch   291: 0.859\n",
      "Loss after mini-batch   301: 2.623\n",
      "Loss after mini-batch   311: 5.095\n",
      "Loss after mini-batch   321: 2.103\n",
      "Loss after mini-batch   331: 6.119\n",
      "Loss after mini-batch   341: 0.481\n",
      "Loss after mini-batch   351: 0.279\n",
      "Loss after mini-batch   361: 0.823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   371: 9.852\n",
      "Training Loss: 24.856 \t\t Validation Loss:24.909\n",
      "Starting epoch 85\n",
      "Loss after mini-batch     1: 25.244\n",
      "Loss after mini-batch    11: 0.461\n",
      "Loss after mini-batch    21: 0.044\n",
      "Loss after mini-batch    31: 13.940\n",
      "Loss after mini-batch    41: 3.736\n",
      "Loss after mini-batch    51: 0.840\n",
      "Loss after mini-batch    61: 1.763\n",
      "Loss after mini-batch    71: 2.592\n",
      "Loss after mini-batch    81: 7.871\n",
      "Loss after mini-batch    91: 0.189\n",
      "Loss after mini-batch   101: 0.146\n",
      "Loss after mini-batch   111: 5.551\n",
      "Loss after mini-batch   121: 2.052\n",
      "Loss after mini-batch   131: 11.228\n",
      "Loss after mini-batch   141: 4.084\n",
      "Loss after mini-batch   151: 0.203\n",
      "Loss after mini-batch   161: 1.266\n",
      "Loss after mini-batch   171: 0.169\n",
      "Loss after mini-batch   181: 1.224\n",
      "Loss after mini-batch   191: 12.673\n",
      "Loss after mini-batch   201: 0.114\n",
      "Loss after mini-batch   211: 0.163\n",
      "Loss after mini-batch   221: 0.322\n",
      "Loss after mini-batch   231: 19.193\n",
      "Loss after mini-batch   241: 10.353\n",
      "Loss after mini-batch   251: 0.248\n",
      "Loss after mini-batch   261: 8.172\n",
      "Loss after mini-batch   271: 0.693\n",
      "Loss after mini-batch   281: 11.498\n",
      "Loss after mini-batch   291: 0.234\n",
      "Loss after mini-batch   301: 0.297\n",
      "Loss after mini-batch   311: 5.555\n",
      "Loss after mini-batch   321: 0.844\n",
      "Loss after mini-batch   331: 4.454\n",
      "Loss after mini-batch   341: 0.127\n",
      "Loss after mini-batch   351: 0.064\n",
      "Loss after mini-batch   361: 11.375\n",
      "Loss after mini-batch   371: 0.542\n",
      "Training Loss: 0.146 \t\t Validation Loss:12.089\n",
      "Starting epoch 86\n",
      "Loss after mini-batch     1: 0.372\n",
      "Loss after mini-batch    11: 3.082\n",
      "Loss after mini-batch    21: 1.844\n",
      "Loss after mini-batch    31: 0.968\n",
      "Loss after mini-batch    41: 0.052\n",
      "Loss after mini-batch    51: 6.175\n",
      "Loss after mini-batch    61: 3.259\n",
      "Loss after mini-batch    71: 0.938\n",
      "Loss after mini-batch    81: 0.179\n",
      "Loss after mini-batch    91: 23.624\n",
      "Loss after mini-batch   101: 0.852\n",
      "Loss after mini-batch   111: 2.252\n",
      "Loss after mini-batch   121: 5.065\n",
      "Loss after mini-batch   131: 8.397\n",
      "Loss after mini-batch   141: 1.292\n",
      "Loss after mini-batch   151: 0.057\n",
      "Loss after mini-batch   161: 2.250\n",
      "Loss after mini-batch   171: 0.765\n",
      "Loss after mini-batch   181: 0.678\n",
      "Loss after mini-batch   191: 0.396\n",
      "Loss after mini-batch   201: 0.060\n",
      "Loss after mini-batch   211: 0.433\n",
      "Loss after mini-batch   221: 3.691\n",
      "Loss after mini-batch   231: 8.190\n",
      "Loss after mini-batch   241: 2.147\n",
      "Loss after mini-batch   251: 23.547\n",
      "Loss after mini-batch   261: 8.868\n",
      "Loss after mini-batch   271: 3.273\n",
      "Loss after mini-batch   281: 1.075\n",
      "Loss after mini-batch   291: 0.128\n",
      "Loss after mini-batch   301: 5.011\n",
      "Loss after mini-batch   311: 3.082\n",
      "Loss after mini-batch   321: 0.424\n",
      "Loss after mini-batch   331: 0.789\n",
      "Loss after mini-batch   341: 0.458\n",
      "Loss after mini-batch   351: 28.137\n",
      "Loss after mini-batch   361: 0.236\n",
      "Loss after mini-batch   371: 0.232\n",
      "Training Loss: 1.308 \t\t Validation Loss:5.767\n",
      "Starting epoch 87\n",
      "Loss after mini-batch     1: 0.905\n",
      "Loss after mini-batch    11: 0.209\n",
      "Loss after mini-batch    21: 3.076\n",
      "Loss after mini-batch    31: 0.110\n",
      "Loss after mini-batch    41: 2.542\n",
      "Loss after mini-batch    51: 0.518\n",
      "Loss after mini-batch    61: 6.366\n",
      "Loss after mini-batch    71: 0.708\n",
      "Loss after mini-batch    81: 4.225\n",
      "Loss after mini-batch    91: 2.367\n",
      "Loss after mini-batch   101: 0.352\n",
      "Loss after mini-batch   111: 0.629\n",
      "Loss after mini-batch   121: 0.353\n",
      "Loss after mini-batch   131: 14.542\n",
      "Loss after mini-batch   141: 0.041\n",
      "Loss after mini-batch   151: 1.418\n",
      "Loss after mini-batch   161: 0.122\n",
      "Loss after mini-batch   171: 4.529\n",
      "Loss after mini-batch   181: 3.091\n",
      "Loss after mini-batch   191: 0.532\n",
      "Loss after mini-batch   201: 0.975\n",
      "Loss after mini-batch   211: 2.067\n",
      "Loss after mini-batch   221: 0.302\n",
      "Loss after mini-batch   231: 0.356\n",
      "Loss after mini-batch   241: 0.597\n",
      "Loss after mini-batch   251: 0.277\n",
      "Loss after mini-batch   261: 0.565\n",
      "Loss after mini-batch   271: 3.750\n",
      "Loss after mini-batch   281: 0.355\n",
      "Loss after mini-batch   291: 1.160\n",
      "Loss after mini-batch   301: 0.535\n",
      "Loss after mini-batch   311: 2.448\n",
      "Loss after mini-batch   321: 0.182\n",
      "Loss after mini-batch   331: 4.210\n",
      "Loss after mini-batch   341: 7.224\n",
      "Loss after mini-batch   351: 0.321\n",
      "Loss after mini-batch   361: 0.670\n",
      "Loss after mini-batch   371: 0.018\n",
      "Training Loss: 0.093 \t\t Validation Loss:0.416\n",
      "Starting epoch 88\n",
      "Loss after mini-batch     1: 4.137\n",
      "Loss after mini-batch    11: 0.990\n",
      "Loss after mini-batch    21: 0.195\n",
      "Loss after mini-batch    31: 0.026\n",
      "Loss after mini-batch    41: 2.240\n",
      "Loss after mini-batch    51: 32.440\n",
      "Loss after mini-batch    61: 2.440\n",
      "Loss after mini-batch    71: 2.876\n",
      "Loss after mini-batch    81: 1.350\n",
      "Loss after mini-batch    91: 0.036\n",
      "Loss after mini-batch   101: 1.779\n",
      "Loss after mini-batch   111: 0.374\n",
      "Loss after mini-batch   121: 0.796\n",
      "Loss after mini-batch   131: 0.093\n",
      "Loss after mini-batch   141: 1.390\n",
      "Loss after mini-batch   151: 14.385\n",
      "Loss after mini-batch   161: 1.433\n",
      "Loss after mini-batch   171: 1.590\n",
      "Loss after mini-batch   181: 0.144\n",
      "Loss after mini-batch   191: 0.063\n",
      "Loss after mini-batch   201: 4.213\n",
      "Loss after mini-batch   211: 1.709\n",
      "Loss after mini-batch   221: 0.408\n",
      "Loss after mini-batch   231: 6.622\n",
      "Loss after mini-batch   241: 0.812\n",
      "Loss after mini-batch   251: 1.103\n",
      "Loss after mini-batch   261: 0.420\n",
      "Loss after mini-batch   271: 0.039\n",
      "Loss after mini-batch   281: 0.034\n",
      "Loss after mini-batch   291: 0.490\n",
      "Loss after mini-batch   301: 0.142\n",
      "Loss after mini-batch   311: 3.023\n",
      "Loss after mini-batch   321: 0.704\n",
      "Loss after mini-batch   331: 7.262\n",
      "Loss after mini-batch   341: 4.368\n",
      "Loss after mini-batch   351: 0.264\n",
      "Loss after mini-batch   361: 0.211\n",
      "Loss after mini-batch   371: 0.124\n",
      "Training Loss: 0.148 \t\t Validation Loss:3.353\n",
      "Starting epoch 89\n",
      "Loss after mini-batch     1: 0.337\n",
      "Loss after mini-batch    11: 1.945\n",
      "Loss after mini-batch    21: 6.604\n",
      "Loss after mini-batch    31: 41.267\n",
      "Loss after mini-batch    41: 0.320\n",
      "Loss after mini-batch    51: 2.141\n",
      "Loss after mini-batch    61: 0.094\n",
      "Loss after mini-batch    71: 3.274\n",
      "Loss after mini-batch    81: 2.907\n",
      "Loss after mini-batch    91: 5.161\n",
      "Loss after mini-batch   101: 0.252\n",
      "Loss after mini-batch   111: 0.244\n",
      "Loss after mini-batch   121: 0.556\n",
      "Loss after mini-batch   131: 0.143\n",
      "Loss after mini-batch   141: 0.554\n",
      "Loss after mini-batch   151: 0.084\n",
      "Loss after mini-batch   161: 0.185\n",
      "Loss after mini-batch   171: 6.369\n",
      "Loss after mini-batch   181: 0.349\n",
      "Loss after mini-batch   191: 2.501\n",
      "Loss after mini-batch   201: 11.118\n",
      "Loss after mini-batch   211: 1.448\n",
      "Loss after mini-batch   221: 25.613\n",
      "Loss after mini-batch   231: 0.303\n",
      "Loss after mini-batch   241: 3.996\n",
      "Loss after mini-batch   251: 0.778\n",
      "Loss after mini-batch   261: 1.837\n",
      "Loss after mini-batch   271: 0.216\n",
      "Loss after mini-batch   281: 0.175\n",
      "Loss after mini-batch   291: 1.130\n",
      "Loss after mini-batch   301: 0.169\n",
      "Loss after mini-batch   311: 0.227\n",
      "Loss after mini-batch   321: 0.518\n",
      "Loss after mini-batch   331: 0.654\n",
      "Loss after mini-batch   341: 24.766\n",
      "Loss after mini-batch   351: 0.821\n",
      "Loss after mini-batch   361: 1.974\n",
      "Loss after mini-batch   371: 0.113\n",
      "Training Loss: 0.428 \t\t Validation Loss:0.667\n",
      "Starting epoch 90\n",
      "Loss after mini-batch     1: 0.225\n",
      "Loss after mini-batch    11: 5.198\n",
      "Loss after mini-batch    21: 21.458\n",
      "Loss after mini-batch    31: 0.362\n",
      "Loss after mini-batch    41: 0.198\n",
      "Loss after mini-batch    51: 0.134\n",
      "Loss after mini-batch    61: 3.280\n",
      "Loss after mini-batch    71: 9.970\n",
      "Loss after mini-batch    81: 0.124\n",
      "Loss after mini-batch    91: 4.508\n",
      "Loss after mini-batch   101: 0.061\n",
      "Loss after mini-batch   111: 0.079\n",
      "Loss after mini-batch   121: 6.429\n",
      "Loss after mini-batch   131: 11.036\n",
      "Loss after mini-batch   141: 0.116\n",
      "Loss after mini-batch   151: 1.419\n",
      "Loss after mini-batch   161: 3.241\n",
      "Loss after mini-batch   171: 0.135\n",
      "Loss after mini-batch   181: 0.636\n",
      "Loss after mini-batch   191: 1.930\n",
      "Loss after mini-batch   201: 0.234\n",
      "Loss after mini-batch   211: 0.777\n",
      "Loss after mini-batch   221: 0.189\n",
      "Loss after mini-batch   231: 2.695\n",
      "Loss after mini-batch   241: 1.373\n",
      "Loss after mini-batch   251: 0.170\n",
      "Loss after mini-batch   261: 0.087\n",
      "Loss after mini-batch   271: 0.170\n",
      "Loss after mini-batch   281: 0.098\n",
      "Loss after mini-batch   291: 0.141\n",
      "Loss after mini-batch   301: 1.601\n",
      "Loss after mini-batch   311: 0.553\n",
      "Loss after mini-batch   321: 0.157\n",
      "Loss after mini-batch   331: 2.490\n",
      "Loss after mini-batch   341: 1.246\n",
      "Loss after mini-batch   351: 4.391\n",
      "Loss after mini-batch   361: 1.213\n",
      "Loss after mini-batch   371: 3.477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.525 \t\t Validation Loss:0.792\n",
      "Starting epoch 91\n",
      "Loss after mini-batch     1: 6.033\n",
      "Loss after mini-batch    11: 0.043\n",
      "Loss after mini-batch    21: 1.908\n",
      "Loss after mini-batch    31: 0.117\n",
      "Loss after mini-batch    41: 0.449\n",
      "Loss after mini-batch    51: 0.084\n",
      "Loss after mini-batch    61: 0.034\n",
      "Loss after mini-batch    71: 2.725\n",
      "Loss after mini-batch    81: 0.725\n",
      "Loss after mini-batch    91: 0.124\n",
      "Loss after mini-batch   101: 2.813\n",
      "Loss after mini-batch   111: 3.502\n",
      "Loss after mini-batch   121: 0.193\n",
      "Loss after mini-batch   131: 0.139\n",
      "Loss after mini-batch   141: 23.209\n",
      "Loss after mini-batch   151: 3.945\n",
      "Loss after mini-batch   161: 0.281\n",
      "Loss after mini-batch   171: 1.524\n",
      "Loss after mini-batch   181: 6.195\n",
      "Loss after mini-batch   191: 0.084\n",
      "Loss after mini-batch   201: 0.192\n",
      "Loss after mini-batch   211: 7.298\n",
      "Loss after mini-batch   221: 0.461\n",
      "Loss after mini-batch   231: 0.318\n",
      "Loss after mini-batch   241: 0.298\n",
      "Loss after mini-batch   251: 15.275\n",
      "Loss after mini-batch   261: 17.216\n",
      "Loss after mini-batch   271: 1.811\n",
      "Loss after mini-batch   281: 1.819\n",
      "Loss after mini-batch   291: 2.282\n",
      "Loss after mini-batch   301: 1.496\n",
      "Loss after mini-batch   311: 1.069\n",
      "Loss after mini-batch   321: 0.308\n",
      "Loss after mini-batch   331: 2.360\n",
      "Loss after mini-batch   341: 2.684\n",
      "Loss after mini-batch   351: 0.192\n",
      "Loss after mini-batch   361: 0.097\n",
      "Loss after mini-batch   371: 0.044\n",
      "Training Loss: 0.167 \t\t Validation Loss:0.212\n",
      "Starting epoch 92\n",
      "Loss after mini-batch     1: 0.064\n",
      "Loss after mini-batch    11: 1.362\n",
      "Loss after mini-batch    21: 3.856\n",
      "Loss after mini-batch    31: 3.019\n",
      "Loss after mini-batch    41: 3.235\n",
      "Loss after mini-batch    51: 5.280\n",
      "Loss after mini-batch    61: 9.648\n",
      "Loss after mini-batch    71: 0.468\n",
      "Loss after mini-batch    81: 0.094\n",
      "Loss after mini-batch    91: 0.370\n",
      "Loss after mini-batch   101: 1.586\n",
      "Loss after mini-batch   111: 0.022\n",
      "Loss after mini-batch   121: 0.829\n",
      "Loss after mini-batch   131: 41.985\n",
      "Loss after mini-batch   141: 0.510\n",
      "Loss after mini-batch   151: 2.414\n",
      "Loss after mini-batch   161: 2.010\n",
      "Loss after mini-batch   171: 0.216\n",
      "Loss after mini-batch   181: 1.685\n",
      "Loss after mini-batch   191: 0.415\n",
      "Loss after mini-batch   201: 0.531\n",
      "Loss after mini-batch   211: 0.091\n",
      "Loss after mini-batch   221: 0.227\n",
      "Loss after mini-batch   231: 0.220\n",
      "Loss after mini-batch   241: 0.632\n",
      "Loss after mini-batch   251: 4.396\n",
      "Loss after mini-batch   261: 4.026\n",
      "Loss after mini-batch   271: 0.145\n",
      "Loss after mini-batch   281: 1.357\n",
      "Loss after mini-batch   291: 1.207\n",
      "Loss after mini-batch   301: 2.445\n",
      "Loss after mini-batch   311: 1.474\n",
      "Loss after mini-batch   321: 5.185\n",
      "Loss after mini-batch   331: 1.426\n",
      "Loss after mini-batch   341: 1.253\n",
      "Loss after mini-batch   351: 0.455\n",
      "Loss after mini-batch   361: 0.086\n",
      "Loss after mini-batch   371: 0.653\n",
      "Training Loss: 0.290 \t\t Validation Loss:9.231\n",
      "Starting epoch 93\n",
      "Loss after mini-batch     1: 0.840\n",
      "Loss after mini-batch    11: 0.089\n",
      "Loss after mini-batch    21: 0.966\n",
      "Loss after mini-batch    31: 0.331\n",
      "Loss after mini-batch    41: 0.112\n",
      "Loss after mini-batch    51: 6.562\n",
      "Loss after mini-batch    61: 0.809\n",
      "Loss after mini-batch    71: 1.263\n",
      "Loss after mini-batch    81: 0.296\n",
      "Loss after mini-batch    91: 1.645\n",
      "Loss after mini-batch   101: 1.138\n",
      "Loss after mini-batch   111: 0.023\n",
      "Loss after mini-batch   121: 3.532\n",
      "Loss after mini-batch   131: 6.222\n",
      "Loss after mini-batch   141: 23.617\n",
      "Loss after mini-batch   151: 3.850\n",
      "Loss after mini-batch   161: 0.116\n",
      "Loss after mini-batch   171: 3.327\n",
      "Loss after mini-batch   181: 0.062\n",
      "Loss after mini-batch   191: 0.053\n",
      "Loss after mini-batch   201: 12.438\n",
      "Loss after mini-batch   211: 0.664\n",
      "Loss after mini-batch   221: 0.265\n",
      "Loss after mini-batch   231: 14.004\n",
      "Loss after mini-batch   241: 0.535\n",
      "Loss after mini-batch   251: 0.508\n",
      "Loss after mini-batch   261: 2.416\n",
      "Loss after mini-batch   271: 0.280\n",
      "Loss after mini-batch   281: 15.744\n",
      "Loss after mini-batch   291: 3.285\n",
      "Loss after mini-batch   301: 6.255\n",
      "Loss after mini-batch   311: 1.250\n",
      "Loss after mini-batch   321: 0.211\n",
      "Loss after mini-batch   331: 0.431\n",
      "Loss after mini-batch   341: 0.521\n",
      "Loss after mini-batch   351: 0.132\n",
      "Loss after mini-batch   361: 0.765\n",
      "Loss after mini-batch   371: 3.163\n",
      "Training Loss: 0.502 \t\t Validation Loss:11.372\n",
      "Starting epoch 94\n",
      "Loss after mini-batch     1: 2.591\n",
      "Loss after mini-batch    11: 2.448\n",
      "Loss after mini-batch    21: 0.188\n",
      "Loss after mini-batch    31: 0.761\n",
      "Loss after mini-batch    41: 3.856\n",
      "Loss after mini-batch    51: 0.277\n",
      "Loss after mini-batch    61: 1.538\n",
      "Loss after mini-batch    71: 2.841\n",
      "Loss after mini-batch    81: 0.078\n",
      "Loss after mini-batch    91: 7.596\n",
      "Loss after mini-batch   101: 0.299\n",
      "Loss after mini-batch   111: 13.936\n",
      "Loss after mini-batch   121: 0.881\n",
      "Loss after mini-batch   131: 0.085\n",
      "Loss after mini-batch   141: 4.708\n",
      "Loss after mini-batch   151: 1.198\n",
      "Loss after mini-batch   161: 2.398\n",
      "Loss after mini-batch   171: 3.779\n",
      "Loss after mini-batch   181: 4.802\n",
      "Loss after mini-batch   191: 11.140\n",
      "Loss after mini-batch   201: 0.305\n",
      "Loss after mini-batch   211: 0.471\n",
      "Loss after mini-batch   221: 0.827\n",
      "Loss after mini-batch   231: 1.041\n",
      "Loss after mini-batch   241: 0.120\n",
      "Loss after mini-batch   251: 0.487\n",
      "Loss after mini-batch   261: 11.088\n",
      "Loss after mini-batch   271: 1.072\n",
      "Loss after mini-batch   281: 0.259\n",
      "Loss after mini-batch   291: 0.339\n",
      "Loss after mini-batch   301: 0.112\n",
      "Loss after mini-batch   311: 11.433\n",
      "Loss after mini-batch   321: 0.178\n",
      "Loss after mini-batch   331: 1.234\n",
      "Loss after mini-batch   341: 6.521\n",
      "Loss after mini-batch   351: 0.078\n",
      "Loss after mini-batch   361: 0.077\n",
      "Loss after mini-batch   371: 0.864\n",
      "Training Loss: 0.022 \t\t Validation Loss:0.049\n",
      "Starting epoch 95\n",
      "Loss after mini-batch     1: 0.214\n",
      "Loss after mini-batch    11: 0.676\n",
      "Loss after mini-batch    21: 1.304\n",
      "Loss after mini-batch    31: 0.543\n",
      "Loss after mini-batch    41: 2.470\n",
      "Loss after mini-batch    51: 0.313\n",
      "Loss after mini-batch    61: 1.599\n",
      "Loss after mini-batch    71: 0.379\n",
      "Loss after mini-batch    81: 0.944\n",
      "Loss after mini-batch    91: 2.060\n",
      "Loss after mini-batch   101: 0.145\n",
      "Loss after mini-batch   111: 0.134\n",
      "Loss after mini-batch   121: 3.322\n",
      "Loss after mini-batch   131: 5.957\n",
      "Loss after mini-batch   141: 0.301\n",
      "Loss after mini-batch   151: 2.572\n",
      "Loss after mini-batch   161: 0.360\n",
      "Loss after mini-batch   171: 0.881\n",
      "Loss after mini-batch   181: 0.385\n",
      "Loss after mini-batch   191: 0.450\n",
      "Loss after mini-batch   201: 0.147\n",
      "Loss after mini-batch   211: 2.374\n",
      "Loss after mini-batch   221: 1.078\n",
      "Loss after mini-batch   231: 2.353\n",
      "Loss after mini-batch   241: 2.767\n",
      "Loss after mini-batch   251: 0.189\n",
      "Loss after mini-batch   261: 0.151\n",
      "Loss after mini-batch   271: 0.696\n",
      "Loss after mini-batch   281: 5.877\n",
      "Loss after mini-batch   291: 3.013\n",
      "Loss after mini-batch   301: 8.497\n",
      "Loss after mini-batch   311: 0.094\n",
      "Loss after mini-batch   321: 0.249\n",
      "Loss after mini-batch   331: 1.441\n",
      "Loss after mini-batch   341: 0.161\n",
      "Loss after mini-batch   351: 10.513\n",
      "Loss after mini-batch   361: 4.125\n",
      "Loss after mini-batch   371: 7.957\n",
      "Training Loss: 0.205 \t\t Validation Loss:1.428\n",
      "Starting epoch 96\n",
      "Loss after mini-batch     1: 0.445\n",
      "Loss after mini-batch    11: 0.723\n",
      "Loss after mini-batch    21: 0.626\n",
      "Loss after mini-batch    31: 4.798\n",
      "Loss after mini-batch    41: 0.026\n",
      "Loss after mini-batch    51: 0.199\n",
      "Loss after mini-batch    61: 0.015\n",
      "Loss after mini-batch    71: 2.015\n",
      "Loss after mini-batch    81: 0.100\n",
      "Loss after mini-batch    91: 3.552\n",
      "Loss after mini-batch   101: 1.324\n",
      "Loss after mini-batch   111: 0.033\n",
      "Loss after mini-batch   121: 0.207\n",
      "Loss after mini-batch   131: 9.225\n",
      "Loss after mini-batch   141: 8.972\n",
      "Loss after mini-batch   151: 7.791\n",
      "Loss after mini-batch   161: 0.195\n",
      "Loss after mini-batch   171: 3.180\n",
      "Loss after mini-batch   181: 0.019\n",
      "Loss after mini-batch   191: 8.784\n",
      "Loss after mini-batch   201: 0.195\n",
      "Loss after mini-batch   211: 3.306\n",
      "Loss after mini-batch   221: 0.982\n",
      "Loss after mini-batch   231: 1.686\n",
      "Loss after mini-batch   241: 6.205\n",
      "Loss after mini-batch   251: 2.320\n",
      "Loss after mini-batch   261: 1.180\n",
      "Loss after mini-batch   271: 0.794\n",
      "Loss after mini-batch   281: 0.053\n",
      "Loss after mini-batch   291: 14.778\n",
      "Loss after mini-batch   301: 0.051\n",
      "Loss after mini-batch   311: 6.765\n",
      "Loss after mini-batch   321: 7.686\n",
      "Loss after mini-batch   331: 0.438\n",
      "Loss after mini-batch   341: 0.116\n",
      "Loss after mini-batch   351: 19.589\n",
      "Loss after mini-batch   361: 2.084\n",
      "Loss after mini-batch   371: 1.039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 3.778 \t\t Validation Loss:4.210\n",
      "Starting epoch 97\n",
      "Loss after mini-batch     1: 0.408\n",
      "Loss after mini-batch    11: 6.915\n",
      "Loss after mini-batch    21: 1.191\n",
      "Loss after mini-batch    31: 0.668\n",
      "Loss after mini-batch    41: 0.468\n",
      "Loss after mini-batch    51: 0.383\n",
      "Loss after mini-batch    61: 1.704\n",
      "Loss after mini-batch    71: 0.252\n",
      "Loss after mini-batch    81: 0.473\n",
      "Loss after mini-batch    91: 8.417\n",
      "Loss after mini-batch   101: 5.020\n",
      "Loss after mini-batch   111: 0.057\n",
      "Loss after mini-batch   121: 6.679\n",
      "Loss after mini-batch   131: 1.110\n",
      "Loss after mini-batch   141: 1.236\n",
      "Loss after mini-batch   151: 0.158\n",
      "Loss after mini-batch   161: 0.635\n",
      "Loss after mini-batch   171: 0.053\n",
      "Loss after mini-batch   181: 2.197\n",
      "Loss after mini-batch   191: 0.046\n",
      "Loss after mini-batch   201: 1.967\n",
      "Loss after mini-batch   211: 0.064\n",
      "Loss after mini-batch   221: 3.465\n",
      "Loss after mini-batch   231: 1.395\n",
      "Loss after mini-batch   241: 2.092\n",
      "Loss after mini-batch   251: 0.147\n",
      "Loss after mini-batch   261: 0.164\n",
      "Loss after mini-batch   271: 0.182\n",
      "Loss after mini-batch   281: 0.586\n",
      "Loss after mini-batch   291: 0.605\n",
      "Loss after mini-batch   301: 0.435\n",
      "Loss after mini-batch   311: 0.108\n",
      "Loss after mini-batch   321: 0.392\n",
      "Loss after mini-batch   331: 4.969\n",
      "Loss after mini-batch   341: 0.029\n",
      "Loss after mini-batch   351: 0.319\n",
      "Loss after mini-batch   361: 2.064\n",
      "Loss after mini-batch   371: 3.255\n",
      "Training Loss: 0.988 \t\t Validation Loss:2.258\n",
      "Starting epoch 98\n",
      "Loss after mini-batch     1: 0.678\n",
      "Loss after mini-batch    11: 2.328\n",
      "Loss after mini-batch    21: 0.445\n",
      "Loss after mini-batch    31: 0.143\n",
      "Loss after mini-batch    41: 1.412\n",
      "Loss after mini-batch    51: 1.023\n",
      "Loss after mini-batch    61: 3.173\n",
      "Loss after mini-batch    71: 19.272\n",
      "Loss after mini-batch    81: 0.119\n",
      "Loss after mini-batch    91: 0.566\n",
      "Loss after mini-batch   101: 0.074\n",
      "Loss after mini-batch   111: 0.324\n",
      "Loss after mini-batch   121: 2.958\n",
      "Loss after mini-batch   131: 15.626\n",
      "Loss after mini-batch   141: 0.436\n",
      "Loss after mini-batch   151: 0.135\n",
      "Loss after mini-batch   161: 0.328\n",
      "Loss after mini-batch   171: 0.445\n",
      "Loss after mini-batch   181: 4.210\n",
      "Loss after mini-batch   191: 3.275\n",
      "Loss after mini-batch   201: 6.115\n",
      "Loss after mini-batch   211: 0.408\n",
      "Loss after mini-batch   221: 3.973\n",
      "Loss after mini-batch   231: 3.803\n",
      "Loss after mini-batch   241: 0.284\n",
      "Loss after mini-batch   251: 0.202\n",
      "Loss after mini-batch   261: 3.616\n",
      "Loss after mini-batch   271: 3.379\n",
      "Loss after mini-batch   281: 1.772\n",
      "Loss after mini-batch   291: 12.036\n",
      "Loss after mini-batch   301: 0.164\n",
      "Loss after mini-batch   311: 0.300\n",
      "Loss after mini-batch   321: 0.211\n",
      "Loss after mini-batch   331: 0.505\n",
      "Loss after mini-batch   341: 0.694\n",
      "Loss after mini-batch   351: 0.951\n",
      "Loss after mini-batch   361: 0.261\n",
      "Loss after mini-batch   371: 40.003\n",
      "Training Loss: 0.258 \t\t Validation Loss:0.414\n",
      "Starting epoch 99\n",
      "Loss after mini-batch     1: 0.243\n",
      "Loss after mini-batch    11: 4.532\n",
      "Loss after mini-batch    21: 0.153\n",
      "Loss after mini-batch    31: 17.975\n",
      "Loss after mini-batch    41: 0.126\n",
      "Loss after mini-batch    51: 0.059\n",
      "Loss after mini-batch    61: 0.197\n",
      "Loss after mini-batch    71: 0.150\n",
      "Loss after mini-batch    81: 0.220\n",
      "Loss after mini-batch    91: 0.062\n",
      "Loss after mini-batch   101: 0.086\n",
      "Loss after mini-batch   111: 5.701\n",
      "Loss after mini-batch   121: 0.427\n",
      "Loss after mini-batch   131: 2.789\n",
      "Loss after mini-batch   141: 0.340\n",
      "Loss after mini-batch   151: 0.265\n",
      "Loss after mini-batch   161: 0.334\n",
      "Loss after mini-batch   171: 1.737\n",
      "Loss after mini-batch   181: 4.195\n",
      "Loss after mini-batch   191: 0.168\n",
      "Loss after mini-batch   201: 0.055\n",
      "Loss after mini-batch   211: 2.499\n",
      "Loss after mini-batch   221: 0.715\n",
      "Loss after mini-batch   231: 3.162\n",
      "Loss after mini-batch   241: 5.077\n",
      "Loss after mini-batch   251: 0.331\n",
      "Loss after mini-batch   261: 0.408\n",
      "Loss after mini-batch   271: 0.327\n",
      "Loss after mini-batch   281: 1.158\n",
      "Loss after mini-batch   291: 3.365\n",
      "Loss after mini-batch   301: 22.748\n",
      "Loss after mini-batch   311: 2.282\n",
      "Loss after mini-batch   321: 1.857\n",
      "Loss after mini-batch   331: 0.685\n",
      "Loss after mini-batch   341: 2.346\n",
      "Loss after mini-batch   351: 0.259\n",
      "Loss after mini-batch   361: 0.787\n",
      "Loss after mini-batch   371: 23.330\n",
      "Training Loss: 0.480 \t\t Validation Loss:1.880\n",
      "Starting epoch 100\n",
      "Loss after mini-batch     1: 0.443\n",
      "Loss after mini-batch    11: 0.177\n",
      "Loss after mini-batch    21: 0.370\n",
      "Loss after mini-batch    31: 4.357\n",
      "Loss after mini-batch    41: 0.300\n",
      "Loss after mini-batch    51: 2.424\n",
      "Loss after mini-batch    61: 2.177\n",
      "Loss after mini-batch    71: 0.190\n",
      "Loss after mini-batch    81: 6.994\n",
      "Loss after mini-batch    91: 2.068\n",
      "Loss after mini-batch   101: 2.807\n",
      "Loss after mini-batch   111: 0.109\n",
      "Loss after mini-batch   121: 0.278\n",
      "Loss after mini-batch   131: 0.064\n",
      "Loss after mini-batch   141: 7.214\n",
      "Loss after mini-batch   151: 0.045\n",
      "Loss after mini-batch   161: 0.733\n",
      "Loss after mini-batch   171: 1.054\n",
      "Loss after mini-batch   181: 9.585\n",
      "Loss after mini-batch   191: 2.764\n",
      "Loss after mini-batch   201: 4.331\n",
      "Loss after mini-batch   211: 3.665\n",
      "Loss after mini-batch   221: 1.832\n",
      "Loss after mini-batch   231: 3.207\n",
      "Loss after mini-batch   241: 1.235\n",
      "Loss after mini-batch   251: 0.291\n",
      "Loss after mini-batch   261: 2.578\n",
      "Loss after mini-batch   271: 10.231\n",
      "Loss after mini-batch   281: 0.836\n",
      "Loss after mini-batch   291: 0.168\n",
      "Loss after mini-batch   301: 0.631\n",
      "Loss after mini-batch   311: 0.343\n",
      "Loss after mini-batch   321: 1.678\n",
      "Loss after mini-batch   331: 0.426\n",
      "Loss after mini-batch   341: 5.081\n",
      "Loss after mini-batch   351: 0.823\n",
      "Loss after mini-batch   361: 1.232\n",
      "Loss after mini-batch   371: 0.165\n",
      "Training Loss: 0.593 \t\t Validation Loss:0.686\n",
      "Starting epoch 101\n",
      "Loss after mini-batch     1: 1.449\n",
      "Loss after mini-batch    11: 0.983\n",
      "Loss after mini-batch    21: 0.122\n",
      "Loss after mini-batch    31: 0.995\n",
      "Loss after mini-batch    41: 0.258\n",
      "Loss after mini-batch    51: 3.953\n",
      "Loss after mini-batch    61: 1.130\n",
      "Loss after mini-batch    71: 2.464\n",
      "Loss after mini-batch    81: 5.140\n",
      "Loss after mini-batch    91: 0.474\n",
      "Loss after mini-batch   101: 3.784\n",
      "Loss after mini-batch   111: 1.514\n",
      "Loss after mini-batch   121: 16.632\n",
      "Loss after mini-batch   131: 3.001\n",
      "Loss after mini-batch   141: 0.178\n",
      "Loss after mini-batch   151: 3.708\n",
      "Loss after mini-batch   161: 1.548\n",
      "Loss after mini-batch   171: 0.139\n",
      "Loss after mini-batch   181: 0.672\n",
      "Loss after mini-batch   191: 0.304\n",
      "Loss after mini-batch   201: 0.299\n",
      "Loss after mini-batch   211: 2.781\n",
      "Loss after mini-batch   221: 2.902\n",
      "Loss after mini-batch   231: 0.276\n",
      "Loss after mini-batch   241: 0.668\n",
      "Loss after mini-batch   251: 10.628\n",
      "Loss after mini-batch   261: 0.298\n",
      "Loss after mini-batch   271: 2.272\n",
      "Loss after mini-batch   281: 1.730\n",
      "Loss after mini-batch   291: 2.876\n",
      "Loss after mini-batch   301: 0.285\n",
      "Loss after mini-batch   311: 2.212\n",
      "Loss after mini-batch   321: 2.184\n",
      "Loss after mini-batch   331: 0.308\n",
      "Loss after mini-batch   341: 1.116\n",
      "Loss after mini-batch   351: 0.090\n",
      "Loss after mini-batch   361: 0.078\n",
      "Loss after mini-batch   371: 4.149\n",
      "Training Loss: 0.380 \t\t Validation Loss:0.807\n",
      "Starting epoch 102\n",
      "Loss after mini-batch     1: 1.907\n",
      "Loss after mini-batch    11: 2.766\n",
      "Loss after mini-batch    21: 0.161\n",
      "Loss after mini-batch    31: 0.376\n",
      "Loss after mini-batch    41: 0.796\n",
      "Loss after mini-batch    51: 0.294\n",
      "Loss after mini-batch    61: 3.538\n",
      "Loss after mini-batch    71: 0.087\n",
      "Loss after mini-batch    81: 0.163\n",
      "Loss after mini-batch    91: 3.018\n",
      "Loss after mini-batch   101: 0.068\n",
      "Loss after mini-batch   111: 3.119\n",
      "Loss after mini-batch   121: 40.511\n",
      "Loss after mini-batch   131: 6.251\n",
      "Loss after mini-batch   141: 0.306\n",
      "Loss after mini-batch   151: 0.218\n",
      "Loss after mini-batch   161: 13.195\n",
      "Loss after mini-batch   171: 3.826\n",
      "Loss after mini-batch   181: 0.202\n",
      "Loss after mini-batch   191: 4.060\n",
      "Loss after mini-batch   201: 0.475\n",
      "Loss after mini-batch   211: 3.043\n",
      "Loss after mini-batch   221: 14.094\n",
      "Loss after mini-batch   231: 2.290\n",
      "Loss after mini-batch   241: 8.830\n",
      "Loss after mini-batch   251: 0.932\n",
      "Loss after mini-batch   261: 5.914\n",
      "Loss after mini-batch   271: 0.420\n",
      "Loss after mini-batch   281: 0.232\n",
      "Loss after mini-batch   291: 0.065\n",
      "Loss after mini-batch   301: 0.716\n",
      "Loss after mini-batch   311: 2.591\n",
      "Loss after mini-batch   321: 21.762\n",
      "Loss after mini-batch   331: 0.587\n",
      "Loss after mini-batch   341: 0.918\n",
      "Loss after mini-batch   351: 0.064\n",
      "Loss after mini-batch   361: 0.624\n",
      "Loss after mini-batch   371: 1.052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 11.127 \t\t Validation Loss:12.743\n",
      "Starting epoch 103\n",
      "Loss after mini-batch     1: 0.085\n",
      "Loss after mini-batch    11: 0.686\n",
      "Loss after mini-batch    21: 6.594\n",
      "Loss after mini-batch    31: 0.703\n",
      "Loss after mini-batch    41: 0.310\n",
      "Loss after mini-batch    51: 0.220\n",
      "Loss after mini-batch    61: 3.120\n",
      "Loss after mini-batch    71: 2.469\n",
      "Loss after mini-batch    81: 5.333\n",
      "Loss after mini-batch    91: 0.087\n",
      "Loss after mini-batch   101: 13.412\n",
      "Loss after mini-batch   111: 4.109\n",
      "Loss after mini-batch   121: 7.395\n",
      "Loss after mini-batch   131: 0.255\n",
      "Loss after mini-batch   141: 0.281\n",
      "Loss after mini-batch   151: 2.341\n",
      "Loss after mini-batch   161: 0.414\n",
      "Loss after mini-batch   171: 0.167\n",
      "Loss after mini-batch   181: 3.108\n",
      "Loss after mini-batch   191: 2.133\n",
      "Loss after mini-batch   201: 1.460\n",
      "Loss after mini-batch   211: 0.487\n",
      "Loss after mini-batch   221: 3.464\n",
      "Loss after mini-batch   231: 0.485\n",
      "Loss after mini-batch   241: 1.835\n",
      "Loss after mini-batch   251: 0.679\n",
      "Loss after mini-batch   261: 0.485\n",
      "Loss after mini-batch   271: 0.901\n",
      "Loss after mini-batch   281: 0.117\n",
      "Loss after mini-batch   291: 1.306\n",
      "Loss after mini-batch   301: 1.571\n",
      "Loss after mini-batch   311: 0.338\n",
      "Loss after mini-batch   321: 4.168\n",
      "Loss after mini-batch   331: 0.197\n",
      "Loss after mini-batch   341: 10.332\n",
      "Loss after mini-batch   351: 1.561\n",
      "Loss after mini-batch   361: 0.320\n",
      "Loss after mini-batch   371: 0.236\n",
      "Training Loss: 0.187 \t\t Validation Loss:0.920\n",
      "Starting epoch 104\n",
      "Loss after mini-batch     1: 0.139\n",
      "Loss after mini-batch    11: 4.555\n",
      "Loss after mini-batch    21: 0.653\n",
      "Loss after mini-batch    31: 6.065\n",
      "Loss after mini-batch    41: 2.977\n",
      "Loss after mini-batch    51: 0.056\n",
      "Loss after mini-batch    61: 2.602\n",
      "Loss after mini-batch    71: 0.579\n",
      "Loss after mini-batch    81: 0.646\n",
      "Loss after mini-batch    91: 0.753\n",
      "Loss after mini-batch   101: 0.391\n",
      "Loss after mini-batch   111: 0.247\n",
      "Loss after mini-batch   121: 0.147\n",
      "Loss after mini-batch   131: 0.037\n",
      "Loss after mini-batch   141: 0.210\n",
      "Loss after mini-batch   151: 2.857\n",
      "Loss after mini-batch   161: 7.566\n",
      "Loss after mini-batch   171: 2.737\n",
      "Loss after mini-batch   181: 1.383\n",
      "Loss after mini-batch   191: 4.449\n",
      "Loss after mini-batch   201: 0.124\n",
      "Loss after mini-batch   211: 0.107\n",
      "Loss after mini-batch   221: 0.286\n",
      "Loss after mini-batch   231: 0.051\n",
      "Loss after mini-batch   241: 0.726\n",
      "Loss after mini-batch   251: 0.116\n",
      "Loss after mini-batch   261: 7.033\n",
      "Loss after mini-batch   271: 15.020\n",
      "Loss after mini-batch   281: 2.039\n",
      "Loss after mini-batch   291: 1.153\n",
      "Loss after mini-batch   301: 2.788\n",
      "Loss after mini-batch   311: 3.093\n",
      "Loss after mini-batch   321: 0.146\n",
      "Loss after mini-batch   331: 0.184\n",
      "Loss after mini-batch   341: 1.929\n",
      "Loss after mini-batch   351: 0.671\n",
      "Loss after mini-batch   361: 22.172\n",
      "Loss after mini-batch   371: 0.368\n",
      "Training Loss: 0.249 \t\t Validation Loss:1.990\n",
      "Starting epoch 105\n",
      "Loss after mini-batch     1: 0.286\n",
      "Loss after mini-batch    11: 5.481\n",
      "Loss after mini-batch    21: 17.020\n",
      "Loss after mini-batch    31: 0.406\n",
      "Loss after mini-batch    41: 0.420\n",
      "Loss after mini-batch    51: 0.214\n",
      "Loss after mini-batch    61: 1.935\n",
      "Loss after mini-batch    71: 0.086\n",
      "Loss after mini-batch    81: 0.047\n",
      "Loss after mini-batch    91: 0.159\n",
      "Loss after mini-batch   101: 0.392\n",
      "Loss after mini-batch   111: 14.969\n",
      "Loss after mini-batch   121: 0.200\n",
      "Loss after mini-batch   131: 0.258\n",
      "Loss after mini-batch   141: 0.072\n",
      "Loss after mini-batch   151: 0.460\n",
      "Loss after mini-batch   161: 8.809\n",
      "Loss after mini-batch   171: 0.120\n",
      "Loss after mini-batch   181: 0.163\n",
      "Loss after mini-batch   191: 1.914\n",
      "Loss after mini-batch   201: 0.078\n",
      "Loss after mini-batch   211: 2.549\n",
      "Loss after mini-batch   221: 0.671\n",
      "Loss after mini-batch   231: 0.898\n",
      "Loss after mini-batch   241: 0.594\n",
      "Loss after mini-batch   251: 12.399\n",
      "Loss after mini-batch   261: 3.748\n",
      "Loss after mini-batch   271: 0.824\n",
      "Loss after mini-batch   281: 0.272\n",
      "Loss after mini-batch   291: 0.395\n",
      "Loss after mini-batch   301: 0.328\n",
      "Loss after mini-batch   311: 0.503\n",
      "Loss after mini-batch   321: 1.720\n",
      "Loss after mini-batch   331: 0.307\n",
      "Loss after mini-batch   341: 0.488\n",
      "Loss after mini-batch   351: 0.074\n",
      "Loss after mini-batch   361: 0.276\n",
      "Loss after mini-batch   371: 0.493\n",
      "Training Loss: 0.421 \t\t Validation Loss:9.048\n",
      "Starting epoch 106\n",
      "Loss after mini-batch     1: 0.405\n",
      "Loss after mini-batch    11: 0.171\n",
      "Loss after mini-batch    21: 0.271\n",
      "Loss after mini-batch    31: 1.815\n",
      "Loss after mini-batch    41: 1.684\n",
      "Loss after mini-batch    51: 0.338\n",
      "Loss after mini-batch    61: 0.185\n",
      "Loss after mini-batch    71: 0.073\n",
      "Loss after mini-batch    81: 0.811\n",
      "Loss after mini-batch    91: 0.208\n",
      "Loss after mini-batch   101: 2.316\n",
      "Loss after mini-batch   111: 2.791\n",
      "Loss after mini-batch   121: 0.721\n",
      "Loss after mini-batch   131: 2.335\n",
      "Loss after mini-batch   141: 5.519\n",
      "Loss after mini-batch   151: 0.752\n",
      "Loss after mini-batch   161: 0.180\n",
      "Loss after mini-batch   171: 38.868\n",
      "Loss after mini-batch   181: 0.164\n",
      "Loss after mini-batch   191: 0.300\n",
      "Loss after mini-batch   201: 0.137\n",
      "Loss after mini-batch   211: 0.498\n",
      "Loss after mini-batch   221: 4.732\n",
      "Loss after mini-batch   231: 0.155\n",
      "Loss after mini-batch   241: 0.399\n",
      "Loss after mini-batch   251: 3.924\n",
      "Loss after mini-batch   261: 2.328\n",
      "Loss after mini-batch   271: 0.672\n",
      "Loss after mini-batch   281: 0.091\n",
      "Loss after mini-batch   291: 0.704\n",
      "Loss after mini-batch   301: 4.994\n",
      "Loss after mini-batch   311: 1.279\n",
      "Loss after mini-batch   321: 0.094\n",
      "Loss after mini-batch   331: 5.773\n",
      "Loss after mini-batch   341: 5.328\n",
      "Loss after mini-batch   351: 0.630\n",
      "Loss after mini-batch   361: 1.427\n",
      "Loss after mini-batch   371: 9.799\n",
      "Training Loss: 0.108 \t\t Validation Loss:0.356\n",
      "Starting epoch 107\n",
      "Loss after mini-batch     1: 0.579\n",
      "Loss after mini-batch    11: 1.567\n",
      "Loss after mini-batch    21: 1.113\n",
      "Loss after mini-batch    31: 2.413\n",
      "Loss after mini-batch    41: 1.805\n",
      "Loss after mini-batch    51: 0.406\n",
      "Loss after mini-batch    61: 0.189\n",
      "Loss after mini-batch    71: 6.581\n",
      "Loss after mini-batch    81: 9.684\n",
      "Loss after mini-batch    91: 0.180\n",
      "Loss after mini-batch   101: 2.276\n",
      "Loss after mini-batch   111: 0.541\n",
      "Loss after mini-batch   121: 1.566\n",
      "Loss after mini-batch   131: 0.219\n",
      "Loss after mini-batch   141: 2.002\n",
      "Loss after mini-batch   151: 4.681\n",
      "Loss after mini-batch   161: 0.810\n",
      "Loss after mini-batch   171: 2.089\n",
      "Loss after mini-batch   181: 2.605\n",
      "Loss after mini-batch   191: 0.320\n",
      "Loss after mini-batch   201: 1.991\n",
      "Loss after mini-batch   211: 0.072\n",
      "Loss after mini-batch   221: 1.516\n",
      "Loss after mini-batch   231: 4.620\n",
      "Loss after mini-batch   241: 0.158\n",
      "Loss after mini-batch   251: 13.022\n",
      "Loss after mini-batch   261: 0.258\n",
      "Loss after mini-batch   271: 1.207\n",
      "Loss after mini-batch   281: 1.411\n",
      "Loss after mini-batch   291: 0.432\n",
      "Loss after mini-batch   301: 1.066\n",
      "Loss after mini-batch   311: 0.275\n",
      "Loss after mini-batch   321: 0.152\n",
      "Loss after mini-batch   331: 0.294\n",
      "Loss after mini-batch   341: 0.378\n",
      "Loss after mini-batch   351: 0.567\n",
      "Loss after mini-batch   361: 0.648\n",
      "Loss after mini-batch   371: 3.096\n",
      "Training Loss: 0.430 \t\t Validation Loss:3.631\n",
      "Starting epoch 108\n",
      "Loss after mini-batch     1: 0.233\n",
      "Loss after mini-batch    11: 0.046\n",
      "Loss after mini-batch    21: 6.869\n",
      "Loss after mini-batch    31: 1.360\n",
      "Loss after mini-batch    41: 0.281\n",
      "Loss after mini-batch    51: 1.040\n",
      "Loss after mini-batch    61: 0.010\n",
      "Loss after mini-batch    71: 0.126\n",
      "Loss after mini-batch    81: 1.067\n",
      "Loss after mini-batch    91: 0.071\n",
      "Loss after mini-batch   101: 0.964\n",
      "Loss after mini-batch   111: 0.505\n",
      "Loss after mini-batch   121: 0.269\n",
      "Loss after mini-batch   131: 0.111\n",
      "Loss after mini-batch   141: 0.380\n",
      "Loss after mini-batch   151: 0.055\n",
      "Loss after mini-batch   161: 2.752\n",
      "Loss after mini-batch   171: 0.369\n",
      "Loss after mini-batch   181: 0.178\n",
      "Loss after mini-batch   191: 0.562\n",
      "Loss after mini-batch   201: 1.944\n",
      "Loss after mini-batch   211: 0.186\n",
      "Loss after mini-batch   221: 0.731\n",
      "Loss after mini-batch   231: 1.665\n",
      "Loss after mini-batch   241: 2.828\n",
      "Loss after mini-batch   251: 15.089\n",
      "Loss after mini-batch   261: 0.101\n",
      "Loss after mini-batch   271: 0.362\n",
      "Loss after mini-batch   281: 0.341\n",
      "Loss after mini-batch   291: 12.460\n",
      "Loss after mini-batch   301: 1.404\n",
      "Loss after mini-batch   311: 2.681\n",
      "Loss after mini-batch   321: 0.061\n",
      "Loss after mini-batch   331: 3.398\n",
      "Loss after mini-batch   341: 1.131\n",
      "Loss after mini-batch   351: 0.245\n",
      "Loss after mini-batch   361: 0.130\n",
      "Loss after mini-batch   371: 22.629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 11.191 \t\t Validation Loss:12.974\n",
      "Starting epoch 109\n",
      "Loss after mini-batch     1: 0.222\n",
      "Loss after mini-batch    11: 10.264\n",
      "Loss after mini-batch    21: 1.752\n",
      "Loss after mini-batch    31: 2.375\n",
      "Loss after mini-batch    41: 7.414\n",
      "Loss after mini-batch    51: 0.578\n",
      "Loss after mini-batch    61: 0.318\n",
      "Loss after mini-batch    71: 1.181\n",
      "Loss after mini-batch    81: 1.039\n",
      "Loss after mini-batch    91: 0.454\n",
      "Loss after mini-batch   101: 0.144\n",
      "Loss after mini-batch   111: 0.222\n",
      "Loss after mini-batch   121: 0.314\n",
      "Loss after mini-batch   131: 0.196\n",
      "Loss after mini-batch   141: 0.200\n",
      "Loss after mini-batch   151: 0.215\n",
      "Loss after mini-batch   161: 0.029\n",
      "Loss after mini-batch   171: 1.828\n",
      "Loss after mini-batch   181: 0.176\n",
      "Loss after mini-batch   191: 0.444\n",
      "Loss after mini-batch   201: 0.514\n",
      "Loss after mini-batch   211: 0.120\n",
      "Loss after mini-batch   221: 0.387\n",
      "Loss after mini-batch   231: 1.399\n",
      "Loss after mini-batch   241: 0.274\n",
      "Loss after mini-batch   251: 0.040\n",
      "Loss after mini-batch   261: 0.440\n",
      "Loss after mini-batch   271: 3.436\n",
      "Loss after mini-batch   281: 11.842\n",
      "Loss after mini-batch   291: 1.315\n",
      "Loss after mini-batch   301: 0.777\n",
      "Loss after mini-batch   311: 0.659\n",
      "Loss after mini-batch   321: 0.301\n",
      "Loss after mini-batch   331: 0.119\n",
      "Loss after mini-batch   341: 2.045\n",
      "Loss after mini-batch   351: 6.889\n",
      "Loss after mini-batch   361: 2.627\n",
      "Loss after mini-batch   371: 3.207\n",
      "Training Loss: 0.645 \t\t Validation Loss:3.361\n",
      "Starting epoch 110\n",
      "Loss after mini-batch     1: 3.195\n",
      "Loss after mini-batch    11: 0.040\n",
      "Loss after mini-batch    21: 2.108\n",
      "Loss after mini-batch    31: 0.710\n",
      "Loss after mini-batch    41: 0.551\n",
      "Loss after mini-batch    51: 1.053\n",
      "Loss after mini-batch    61: 1.571\n",
      "Loss after mini-batch    71: 2.878\n",
      "Loss after mini-batch    81: 0.681\n",
      "Loss after mini-batch    91: 0.452\n",
      "Loss after mini-batch   101: 1.408\n",
      "Loss after mini-batch   111: 0.023\n",
      "Loss after mini-batch   121: 0.378\n",
      "Loss after mini-batch   131: 0.097\n",
      "Loss after mini-batch   141: 0.157\n",
      "Loss after mini-batch   151: 2.111\n",
      "Loss after mini-batch   161: 0.776\n",
      "Loss after mini-batch   171: 4.671\n",
      "Loss after mini-batch   181: 0.631\n",
      "Loss after mini-batch   191: 3.632\n",
      "Loss after mini-batch   201: 0.252\n",
      "Loss after mini-batch   211: 0.937\n",
      "Loss after mini-batch   221: 0.614\n",
      "Loss after mini-batch   231: 0.143\n",
      "Loss after mini-batch   241: 0.825\n",
      "Loss after mini-batch   251: 0.205\n",
      "Loss after mini-batch   261: 1.158\n",
      "Loss after mini-batch   271: 0.112\n",
      "Loss after mini-batch   281: 2.729\n",
      "Loss after mini-batch   291: 3.146\n",
      "Loss after mini-batch   301: 14.988\n",
      "Loss after mini-batch   311: 1.536\n",
      "Loss after mini-batch   321: 0.179\n",
      "Loss after mini-batch   331: 1.049\n",
      "Loss after mini-batch   341: 0.250\n",
      "Loss after mini-batch   351: 1.151\n",
      "Loss after mini-batch   361: 1.093\n",
      "Loss after mini-batch   371: 0.502\n",
      "Training Loss: 11.301 \t\t Validation Loss:11.680\n",
      "Starting epoch 111\n",
      "Loss after mini-batch     1: 6.159\n",
      "Loss after mini-batch    11: 0.375\n",
      "Loss after mini-batch    21: 0.185\n",
      "Loss after mini-batch    31: 2.546\n",
      "Loss after mini-batch    41: 0.110\n",
      "Loss after mini-batch    51: 1.850\n",
      "Loss after mini-batch    61: 4.984\n",
      "Loss after mini-batch    71: 0.188\n",
      "Loss after mini-batch    81: 1.148\n",
      "Loss after mini-batch    91: 3.568\n",
      "Loss after mini-batch   101: 0.313\n",
      "Loss after mini-batch   111: 0.867\n",
      "Loss after mini-batch   121: 0.040\n",
      "Loss after mini-batch   131: 0.058\n",
      "Loss after mini-batch   141: 6.940\n",
      "Loss after mini-batch   151: 3.246\n",
      "Loss after mini-batch   161: 22.197\n",
      "Loss after mini-batch   171: 20.859\n",
      "Loss after mini-batch   181: 0.792\n",
      "Loss after mini-batch   191: 0.263\n",
      "Loss after mini-batch   201: 0.178\n",
      "Loss after mini-batch   211: 0.676\n",
      "Loss after mini-batch   221: 15.955\n",
      "Loss after mini-batch   231: 0.116\n",
      "Loss after mini-batch   241: 0.205\n",
      "Loss after mini-batch   251: 0.100\n",
      "Loss after mini-batch   261: 1.380\n",
      "Loss after mini-batch   271: 0.464\n",
      "Loss after mini-batch   281: 1.986\n",
      "Loss after mini-batch   291: 0.986\n",
      "Loss after mini-batch   301: 3.461\n",
      "Loss after mini-batch   311: 0.344\n",
      "Loss after mini-batch   321: 0.308\n",
      "Loss after mini-batch   331: 0.661\n",
      "Loss after mini-batch   341: 0.190\n",
      "Loss after mini-batch   351: 0.051\n",
      "Loss after mini-batch   361: 3.935\n",
      "Loss after mini-batch   371: 0.163\n",
      "Training Loss: 0.528 \t\t Validation Loss:3.170\n",
      "Starting epoch 112\n",
      "Loss after mini-batch     1: 4.750\n",
      "Loss after mini-batch    11: 1.840\n",
      "Loss after mini-batch    21: 0.758\n",
      "Loss after mini-batch    31: 3.197\n",
      "Loss after mini-batch    41: 0.411\n",
      "Loss after mini-batch    51: 0.214\n",
      "Loss after mini-batch    61: 4.480\n",
      "Loss after mini-batch    71: 0.158\n",
      "Loss after mini-batch    81: 0.212\n",
      "Loss after mini-batch    91: 1.432\n",
      "Loss after mini-batch   101: 0.519\n",
      "Loss after mini-batch   111: 1.920\n",
      "Loss after mini-batch   121: 0.179\n",
      "Loss after mini-batch   131: 8.653\n",
      "Loss after mini-batch   141: 0.248\n",
      "Loss after mini-batch   151: 0.206\n",
      "Loss after mini-batch   161: 0.152\n",
      "Loss after mini-batch   171: 0.098\n",
      "Loss after mini-batch   181: 1.402\n",
      "Loss after mini-batch   191: 0.275\n",
      "Loss after mini-batch   201: 0.145\n",
      "Loss after mini-batch   211: 3.800\n",
      "Loss after mini-batch   221: 0.402\n",
      "Loss after mini-batch   231: 0.591\n",
      "Loss after mini-batch   241: 7.549\n",
      "Loss after mini-batch   251: 2.495\n",
      "Loss after mini-batch   261: 0.467\n",
      "Loss after mini-batch   271: 3.366\n",
      "Loss after mini-batch   281: 0.415\n",
      "Loss after mini-batch   291: 5.014\n",
      "Loss after mini-batch   301: 2.819\n",
      "Loss after mini-batch   311: 38.021\n",
      "Loss after mini-batch   321: 0.184\n",
      "Loss after mini-batch   331: 0.080\n",
      "Loss after mini-batch   341: 0.308\n",
      "Loss after mini-batch   351: 0.124\n",
      "Loss after mini-batch   361: 1.042\n",
      "Loss after mini-batch   371: 0.061\n",
      "Training Loss: 7.996 \t\t Validation Loss:8.639\n",
      "Starting epoch 113\n",
      "Loss after mini-batch     1: 0.453\n",
      "Loss after mini-batch    11: 1.777\n",
      "Loss after mini-batch    21: 8.758\n",
      "Loss after mini-batch    31: 0.359\n",
      "Loss after mini-batch    41: 1.823\n",
      "Loss after mini-batch    51: 0.678\n",
      "Loss after mini-batch    61: 0.829\n",
      "Loss after mini-batch    71: 2.095\n",
      "Loss after mini-batch    81: 2.498\n",
      "Loss after mini-batch    91: 0.055\n",
      "Loss after mini-batch   101: 0.394\n",
      "Loss after mini-batch   111: 1.781\n",
      "Loss after mini-batch   121: 0.323\n",
      "Loss after mini-batch   131: 0.190\n",
      "Loss after mini-batch   141: 3.744\n",
      "Loss after mini-batch   151: 12.420\n",
      "Loss after mini-batch   161: 0.133\n",
      "Loss after mini-batch   171: 0.544\n",
      "Loss after mini-batch   181: 8.560\n",
      "Loss after mini-batch   191: 0.330\n",
      "Loss after mini-batch   201: 1.852\n",
      "Loss after mini-batch   211: 0.258\n",
      "Loss after mini-batch   221: 4.063\n",
      "Loss after mini-batch   231: 0.976\n",
      "Loss after mini-batch   241: 0.129\n",
      "Loss after mini-batch   251: 4.318\n",
      "Loss after mini-batch   261: 0.801\n",
      "Loss after mini-batch   271: 0.077\n",
      "Loss after mini-batch   281: 1.994\n",
      "Loss after mini-batch   291: 2.651\n",
      "Loss after mini-batch   301: 0.078\n",
      "Loss after mini-batch   311: 2.753\n",
      "Loss after mini-batch   321: 0.186\n",
      "Loss after mini-batch   331: 0.106\n",
      "Loss after mini-batch   341: 3.532\n",
      "Loss after mini-batch   351: 0.567\n",
      "Loss after mini-batch   361: 4.027\n",
      "Loss after mini-batch   371: 0.025\n",
      "Training Loss: 0.587 \t\t Validation Loss:5.650\n",
      "Starting epoch 114\n",
      "Loss after mini-batch     1: 2.790\n",
      "Loss after mini-batch    11: 2.840\n",
      "Loss after mini-batch    21: 2.546\n",
      "Loss after mini-batch    31: 2.259\n",
      "Loss after mini-batch    41: 0.365\n",
      "Loss after mini-batch    51: 0.478\n",
      "Loss after mini-batch    61: 10.430\n",
      "Loss after mini-batch    71: 0.308\n",
      "Loss after mini-batch    81: 4.451\n",
      "Loss after mini-batch    91: 0.328\n",
      "Loss after mini-batch   101: 1.586\n",
      "Loss after mini-batch   111: 0.390\n",
      "Loss after mini-batch   121: 0.122\n",
      "Loss after mini-batch   131: 0.077\n",
      "Loss after mini-batch   141: 0.097\n",
      "Loss after mini-batch   151: 1.385\n",
      "Loss after mini-batch   161: 0.089\n",
      "Loss after mini-batch   171: 0.264\n",
      "Loss after mini-batch   181: 1.007\n",
      "Loss after mini-batch   191: 0.364\n",
      "Loss after mini-batch   201: 6.496\n",
      "Loss after mini-batch   211: 0.414\n",
      "Loss after mini-batch   221: 1.285\n",
      "Loss after mini-batch   231: 0.350\n",
      "Loss after mini-batch   241: 0.347\n",
      "Loss after mini-batch   251: 1.318\n",
      "Loss after mini-batch   261: 0.553\n",
      "Loss after mini-batch   271: 0.828\n",
      "Loss after mini-batch   281: 0.263\n",
      "Loss after mini-batch   291: 0.104\n",
      "Loss after mini-batch   301: 0.504\n",
      "Loss after mini-batch   311: 4.305\n",
      "Loss after mini-batch   321: 4.992\n",
      "Loss after mini-batch   331: 0.522\n",
      "Loss after mini-batch   341: 0.569\n",
      "Loss after mini-batch   351: 0.266\n",
      "Loss after mini-batch   361: 0.270\n",
      "Loss after mini-batch   371: 6.862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.176 \t\t Validation Loss:1.324\n",
      "Starting epoch 115\n",
      "Loss after mini-batch     1: 0.250\n",
      "Loss after mini-batch    11: 9.210\n",
      "Loss after mini-batch    21: 6.437\n",
      "Loss after mini-batch    31: 1.317\n",
      "Loss after mini-batch    41: 0.372\n",
      "Loss after mini-batch    51: 0.161\n",
      "Loss after mini-batch    61: 2.686\n",
      "Loss after mini-batch    71: 0.172\n",
      "Loss after mini-batch    81: 0.403\n",
      "Loss after mini-batch    91: 1.125\n",
      "Loss after mini-batch   101: 4.424\n",
      "Loss after mini-batch   111: 0.086\n",
      "Loss after mini-batch   121: 1.072\n",
      "Loss after mini-batch   131: 0.702\n",
      "Loss after mini-batch   141: 0.228\n",
      "Loss after mini-batch   151: 0.076\n",
      "Loss after mini-batch   161: 0.486\n",
      "Loss after mini-batch   171: 1.203\n",
      "Loss after mini-batch   181: 0.161\n",
      "Loss after mini-batch   191: 0.148\n",
      "Loss after mini-batch   201: 3.412\n",
      "Loss after mini-batch   211: 4.039\n",
      "Loss after mini-batch   221: 1.132\n",
      "Loss after mini-batch   231: 0.551\n",
      "Loss after mini-batch   241: 0.718\n",
      "Loss after mini-batch   251: 5.504\n",
      "Loss after mini-batch   261: 0.188\n",
      "Loss after mini-batch   271: 0.568\n",
      "Loss after mini-batch   281: 0.134\n",
      "Loss after mini-batch   291: 0.175\n",
      "Loss after mini-batch   301: 0.108\n",
      "Loss after mini-batch   311: 2.411\n",
      "Loss after mini-batch   321: 0.051\n",
      "Loss after mini-batch   331: 0.183\n",
      "Loss after mini-batch   341: 0.755\n",
      "Loss after mini-batch   351: 2.748\n",
      "Loss after mini-batch   361: 0.072\n",
      "Loss after mini-batch   371: 1.586\n",
      "Training Loss: 0.598 \t\t Validation Loss:0.806\n",
      "Starting epoch 116\n",
      "Loss after mini-batch     1: 21.109\n",
      "Loss after mini-batch    11: 0.260\n",
      "Loss after mini-batch    21: 1.064\n",
      "Loss after mini-batch    31: 0.202\n",
      "Loss after mini-batch    41: 2.403\n",
      "Loss after mini-batch    51: 0.331\n",
      "Loss after mini-batch    61: 1.052\n",
      "Loss after mini-batch    71: 0.139\n",
      "Loss after mini-batch    81: 0.259\n",
      "Loss after mini-batch    91: 10.382\n",
      "Loss after mini-batch   101: 0.602\n",
      "Loss after mini-batch   111: 0.118\n",
      "Loss after mini-batch   121: 0.796\n",
      "Loss after mini-batch   131: 0.409\n",
      "Loss after mini-batch   141: 3.193\n",
      "Loss after mini-batch   151: 1.497\n",
      "Loss after mini-batch   161: 0.227\n",
      "Loss after mini-batch   171: 3.986\n",
      "Loss after mini-batch   181: 7.453\n",
      "Loss after mini-batch   191: 2.318\n",
      "Loss after mini-batch   201: 1.751\n",
      "Loss after mini-batch   211: 0.106\n",
      "Loss after mini-batch   221: 1.974\n",
      "Loss after mini-batch   231: 7.664\n",
      "Loss after mini-batch   241: 0.437\n",
      "Loss after mini-batch   251: 2.007\n",
      "Loss after mini-batch   261: 5.007\n",
      "Loss after mini-batch   271: 2.877\n",
      "Loss after mini-batch   281: 0.098\n",
      "Loss after mini-batch   291: 0.106\n",
      "Loss after mini-batch   301: 10.619\n",
      "Loss after mini-batch   311: 0.649\n",
      "Loss after mini-batch   321: 0.147\n",
      "Loss after mini-batch   331: 1.402\n",
      "Loss after mini-batch   341: 0.902\n",
      "Loss after mini-batch   351: 0.478\n",
      "Loss after mini-batch   361: 0.212\n",
      "Loss after mini-batch   371: 0.250\n",
      "Training Loss: 0.112 \t\t Validation Loss:2.748\n",
      "Starting epoch 117\n",
      "Loss after mini-batch     1: 1.857\n",
      "Loss after mini-batch    11: 4.362\n",
      "Loss after mini-batch    21: 0.132\n",
      "Loss after mini-batch    31: 0.281\n",
      "Loss after mini-batch    41: 10.441\n",
      "Loss after mini-batch    51: 0.296\n",
      "Loss after mini-batch    61: 7.631\n",
      "Loss after mini-batch    71: 0.813\n",
      "Loss after mini-batch    81: 0.430\n",
      "Loss after mini-batch    91: 0.932\n",
      "Loss after mini-batch   101: 4.982\n",
      "Loss after mini-batch   111: 11.949\n",
      "Loss after mini-batch   121: 0.203\n",
      "Loss after mini-batch   131: 0.214\n",
      "Loss after mini-batch   141: 1.203\n",
      "Loss after mini-batch   151: 1.014\n",
      "Loss after mini-batch   161: 0.043\n",
      "Loss after mini-batch   171: 0.103\n",
      "Loss after mini-batch   181: 0.035\n",
      "Loss after mini-batch   191: 2.625\n",
      "Loss after mini-batch   201: 1.203\n",
      "Loss after mini-batch   211: 0.206\n",
      "Loss after mini-batch   221: 0.113\n",
      "Loss after mini-batch   231: 8.543\n",
      "Loss after mini-batch   241: 0.410\n",
      "Loss after mini-batch   251: 3.262\n",
      "Loss after mini-batch   261: 0.128\n",
      "Loss after mini-batch   271: 2.843\n",
      "Loss after mini-batch   281: 0.784\n",
      "Loss after mini-batch   291: 5.027\n",
      "Loss after mini-batch   301: 0.384\n",
      "Loss after mini-batch   311: 0.177\n",
      "Loss after mini-batch   321: 0.363\n",
      "Loss after mini-batch   331: 0.297\n",
      "Loss after mini-batch   341: 5.663\n",
      "Loss after mini-batch   351: 1.406\n",
      "Loss after mini-batch   361: 0.957\n",
      "Loss after mini-batch   371: 1.155\n",
      "Training Loss: 7.274 \t\t Validation Loss:8.194\n",
      "Starting epoch 118\n",
      "Loss after mini-batch     1: 0.330\n",
      "Loss after mini-batch    11: 0.519\n",
      "Loss after mini-batch    21: 0.026\n",
      "Loss after mini-batch    31: 0.090\n",
      "Loss after mini-batch    41: 0.587\n",
      "Loss after mini-batch    51: 0.631\n",
      "Loss after mini-batch    61: 5.630\n",
      "Loss after mini-batch    71: 5.114\n",
      "Loss after mini-batch    81: 0.194\n",
      "Loss after mini-batch    91: 0.221\n",
      "Loss after mini-batch   101: 0.908\n",
      "Loss after mini-batch   111: 0.252\n",
      "Loss after mini-batch   121: 0.507\n",
      "Loss after mini-batch   131: 4.164\n",
      "Loss after mini-batch   141: 2.349\n",
      "Loss after mini-batch   151: 0.134\n",
      "Loss after mini-batch   161: 0.226\n",
      "Loss after mini-batch   171: 1.210\n",
      "Loss after mini-batch   181: 0.277\n",
      "Loss after mini-batch   191: 0.121\n",
      "Loss after mini-batch   201: 0.154\n",
      "Loss after mini-batch   211: 0.359\n",
      "Loss after mini-batch   221: 3.081\n",
      "Loss after mini-batch   231: 1.680\n",
      "Loss after mini-batch   241: 1.052\n",
      "Loss after mini-batch   251: 0.189\n",
      "Loss after mini-batch   261: 0.090\n",
      "Loss after mini-batch   271: 0.249\n",
      "Loss after mini-batch   281: 3.861\n",
      "Loss after mini-batch   291: 0.475\n",
      "Loss after mini-batch   301: 0.162\n",
      "Loss after mini-batch   311: 1.339\n",
      "Loss after mini-batch   321: 0.778\n",
      "Loss after mini-batch   331: 8.959\n",
      "Loss after mini-batch   341: 2.652\n",
      "Loss after mini-batch   351: 1.816\n",
      "Loss after mini-batch   361: 0.276\n",
      "Loss after mini-batch   371: 0.069\n",
      "Training Loss: 0.362 \t\t Validation Loss:0.576\n",
      "Starting epoch 119\n",
      "Loss after mini-batch     1: 0.103\n",
      "Loss after mini-batch    11: 0.115\n",
      "Loss after mini-batch    21: 0.381\n",
      "Loss after mini-batch    31: 0.190\n",
      "Loss after mini-batch    41: 0.195\n",
      "Loss after mini-batch    51: 0.223\n",
      "Loss after mini-batch    61: 6.740\n",
      "Loss after mini-batch    71: 1.406\n",
      "Loss after mini-batch    81: 0.295\n",
      "Loss after mini-batch    91: 3.138\n",
      "Loss after mini-batch   101: 3.414\n",
      "Loss after mini-batch   111: 0.254\n",
      "Loss after mini-batch   121: 1.247\n",
      "Loss after mini-batch   131: 0.901\n",
      "Loss after mini-batch   141: 19.906\n",
      "Loss after mini-batch   151: 0.233\n",
      "Loss after mini-batch   161: 0.453\n",
      "Loss after mini-batch   171: 0.095\n",
      "Loss after mini-batch   181: 0.023\n",
      "Loss after mini-batch   191: 0.324\n",
      "Loss after mini-batch   201: 0.498\n",
      "Loss after mini-batch   211: 1.027\n",
      "Loss after mini-batch   221: 12.125\n",
      "Loss after mini-batch   231: 3.658\n",
      "Loss after mini-batch   241: 0.757\n",
      "Loss after mini-batch   251: 0.187\n",
      "Loss after mini-batch   261: 0.202\n",
      "Loss after mini-batch   271: 1.219\n",
      "Loss after mini-batch   281: 0.511\n",
      "Loss after mini-batch   291: 2.848\n",
      "Loss after mini-batch   301: 0.122\n",
      "Loss after mini-batch   311: 2.902\n",
      "Loss after mini-batch   321: 2.154\n",
      "Loss after mini-batch   331: 1.446\n",
      "Loss after mini-batch   341: 0.801\n",
      "Loss after mini-batch   351: 3.295\n",
      "Loss after mini-batch   361: 0.535\n",
      "Loss after mini-batch   371: 5.168\n",
      "Training Loss: 0.875 \t\t Validation Loss:1.249\n",
      "Starting epoch 120\n",
      "Loss after mini-batch     1: 4.937\n",
      "Loss after mini-batch    11: 0.128\n",
      "Loss after mini-batch    21: 2.986\n",
      "Loss after mini-batch    31: 1.331\n",
      "Loss after mini-batch    41: 0.052\n",
      "Loss after mini-batch    51: 2.568\n",
      "Loss after mini-batch    61: 1.701\n",
      "Loss after mini-batch    71: 5.882\n",
      "Loss after mini-batch    81: 0.360\n",
      "Loss after mini-batch    91: 0.096\n",
      "Loss after mini-batch   101: 0.211\n",
      "Loss after mini-batch   111: 0.765\n",
      "Loss after mini-batch   121: 3.191\n",
      "Loss after mini-batch   131: 3.846\n",
      "Loss after mini-batch   141: 0.177\n",
      "Loss after mini-batch   151: 1.448\n",
      "Loss after mini-batch   161: 2.615\n",
      "Loss after mini-batch   171: 0.810\n",
      "Loss after mini-batch   181: 1.049\n",
      "Loss after mini-batch   191: 0.877\n",
      "Loss after mini-batch   201: 1.232\n",
      "Loss after mini-batch   211: 0.263\n",
      "Loss after mini-batch   221: 2.423\n",
      "Loss after mini-batch   231: 1.593\n",
      "Loss after mini-batch   241: 6.386\n",
      "Loss after mini-batch   251: 0.126\n",
      "Loss after mini-batch   261: 0.092\n",
      "Loss after mini-batch   271: 0.212\n",
      "Loss after mini-batch   281: 0.464\n",
      "Loss after mini-batch   291: 0.151\n",
      "Loss after mini-batch   301: 0.912\n",
      "Loss after mini-batch   311: 0.142\n",
      "Loss after mini-batch   321: 2.326\n",
      "Loss after mini-batch   331: 0.150\n",
      "Loss after mini-batch   341: 0.555\n",
      "Loss after mini-batch   351: 0.114\n",
      "Loss after mini-batch   361: 1.684\n",
      "Loss after mini-batch   371: 0.382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.669 \t\t Validation Loss:2.044\n",
      "Starting epoch 121\n",
      "Loss after mini-batch     1: 1.130\n",
      "Loss after mini-batch    11: 0.079\n",
      "Loss after mini-batch    21: 1.030\n",
      "Loss after mini-batch    31: 0.666\n",
      "Loss after mini-batch    41: 2.597\n",
      "Loss after mini-batch    51: 3.747\n",
      "Loss after mini-batch    61: 0.441\n",
      "Loss after mini-batch    71: 0.526\n",
      "Loss after mini-batch    81: 0.318\n",
      "Loss after mini-batch    91: 1.117\n",
      "Loss after mini-batch   101: 2.965\n",
      "Loss after mini-batch   111: 2.148\n",
      "Loss after mini-batch   121: 5.868\n",
      "Loss after mini-batch   131: 0.133\n",
      "Loss after mini-batch   141: 0.408\n",
      "Loss after mini-batch   151: 0.234\n",
      "Loss after mini-batch   161: 0.307\n",
      "Loss after mini-batch   171: 0.290\n",
      "Loss after mini-batch   181: 0.365\n",
      "Loss after mini-batch   191: 1.005\n",
      "Loss after mini-batch   201: 5.897\n",
      "Loss after mini-batch   211: 0.279\n",
      "Loss after mini-batch   221: 0.174\n",
      "Loss after mini-batch   231: 2.782\n",
      "Loss after mini-batch   241: 1.631\n",
      "Loss after mini-batch   251: 0.462\n",
      "Loss after mini-batch   261: 1.994\n",
      "Loss after mini-batch   271: 0.057\n",
      "Loss after mini-batch   281: 0.286\n",
      "Loss after mini-batch   291: 0.036\n",
      "Loss after mini-batch   301: 0.956\n",
      "Loss after mini-batch   311: 5.480\n",
      "Loss after mini-batch   321: 2.615\n",
      "Loss after mini-batch   331: 0.237\n",
      "Loss after mini-batch   341: 0.086\n",
      "Loss after mini-batch   351: 1.160\n",
      "Loss after mini-batch   361: 0.756\n",
      "Loss after mini-batch   371: 0.436\n",
      "Training Loss: 1.278 \t\t Validation Loss:1.414\n",
      "Starting epoch 122\n",
      "Loss after mini-batch     1: 0.435\n",
      "Loss after mini-batch    11: 4.386\n",
      "Loss after mini-batch    21: 0.186\n",
      "Loss after mini-batch    31: 0.309\n",
      "Loss after mini-batch    41: 2.459\n",
      "Loss after mini-batch    51: 0.358\n",
      "Loss after mini-batch    61: 0.084\n",
      "Loss after mini-batch    71: 0.408\n",
      "Loss after mini-batch    81: 3.266\n",
      "Loss after mini-batch    91: 13.538\n",
      "Loss after mini-batch   101: 0.878\n",
      "Loss after mini-batch   111: 4.105\n",
      "Loss after mini-batch   121: 1.057\n",
      "Loss after mini-batch   131: 4.580\n",
      "Loss after mini-batch   141: 0.796\n",
      "Loss after mini-batch   151: 0.843\n",
      "Loss after mini-batch   161: 0.217\n",
      "Loss after mini-batch   171: 0.848\n",
      "Loss after mini-batch   181: 0.217\n",
      "Loss after mini-batch   191: 2.405\n",
      "Loss after mini-batch   201: 2.552\n",
      "Loss after mini-batch   211: 0.446\n",
      "Loss after mini-batch   221: 1.475\n",
      "Loss after mini-batch   231: 0.259\n",
      "Loss after mini-batch   241: 1.031\n",
      "Loss after mini-batch   251: 0.175\n",
      "Loss after mini-batch   261: 0.068\n",
      "Loss after mini-batch   271: 1.586\n",
      "Loss after mini-batch   281: 0.446\n",
      "Loss after mini-batch   291: 0.305\n",
      "Loss after mini-batch   301: 0.597\n",
      "Loss after mini-batch   311: 8.525\n",
      "Loss after mini-batch   321: 0.349\n",
      "Loss after mini-batch   331: 0.461\n",
      "Loss after mini-batch   341: 0.243\n",
      "Loss after mini-batch   351: 0.592\n",
      "Loss after mini-batch   361: 4.301\n",
      "Loss after mini-batch   371: 0.235\n",
      "Training Loss: 0.451 \t\t Validation Loss:0.579\n",
      "Starting epoch 123\n",
      "Loss after mini-batch     1: 0.866\n",
      "Loss after mini-batch    11: 0.502\n",
      "Loss after mini-batch    21: 0.385\n",
      "Loss after mini-batch    31: 5.695\n",
      "Loss after mini-batch    41: 1.004\n",
      "Loss after mini-batch    51: 0.587\n",
      "Loss after mini-batch    61: 2.208\n",
      "Loss after mini-batch    71: 0.521\n",
      "Loss after mini-batch    81: 2.733\n",
      "Loss after mini-batch    91: 8.529\n",
      "Loss after mini-batch   101: 3.347\n",
      "Loss after mini-batch   111: 1.026\n",
      "Loss after mini-batch   121: 0.962\n",
      "Loss after mini-batch   131: 0.104\n",
      "Loss after mini-batch   141: 0.442\n",
      "Loss after mini-batch   151: 0.958\n",
      "Loss after mini-batch   161: 0.567\n",
      "Loss after mini-batch   171: 2.274\n",
      "Loss after mini-batch   181: 0.114\n",
      "Loss after mini-batch   191: 0.148\n",
      "Loss after mini-batch   201: 2.583\n",
      "Loss after mini-batch   211: 6.159\n",
      "Loss after mini-batch   221: 1.709\n",
      "Loss after mini-batch   231: 36.603\n",
      "Loss after mini-batch   241: 0.232\n",
      "Loss after mini-batch   251: 0.797\n",
      "Loss after mini-batch   261: 0.174\n",
      "Loss after mini-batch   271: 3.158\n",
      "Loss after mini-batch   281: 19.436\n",
      "Loss after mini-batch   291: 0.295\n",
      "Loss after mini-batch   301: 0.318\n",
      "Loss after mini-batch   311: 0.058\n",
      "Loss after mini-batch   321: 0.140\n",
      "Loss after mini-batch   331: 0.095\n",
      "Loss after mini-batch   341: 0.125\n",
      "Loss after mini-batch   351: 6.477\n",
      "Loss after mini-batch   361: 5.662\n",
      "Loss after mini-batch   371: 0.334\n",
      "Training Loss: 11.529 \t\t Validation Loss:14.611\n",
      "Starting epoch 124\n",
      "Loss after mini-batch     1: 0.280\n",
      "Loss after mini-batch    11: 0.299\n",
      "Loss after mini-batch    21: 4.888\n",
      "Loss after mini-batch    31: 0.330\n",
      "Loss after mini-batch    41: 0.088\n",
      "Loss after mini-batch    51: 3.181\n",
      "Loss after mini-batch    61: 11.661\n",
      "Loss after mini-batch    71: 0.751\n",
      "Loss after mini-batch    81: 4.422\n",
      "Loss after mini-batch    91: 7.355\n",
      "Loss after mini-batch   101: 0.235\n",
      "Loss after mini-batch   111: 2.005\n",
      "Loss after mini-batch   121: 0.729\n",
      "Loss after mini-batch   131: 0.372\n",
      "Loss after mini-batch   141: 0.952\n",
      "Loss after mini-batch   151: 1.877\n",
      "Loss after mini-batch   161: 1.930\n",
      "Loss after mini-batch   171: 6.959\n",
      "Loss after mini-batch   181: 0.279\n",
      "Loss after mini-batch   191: 0.566\n",
      "Loss after mini-batch   201: 0.304\n",
      "Loss after mini-batch   211: 1.585\n",
      "Loss after mini-batch   221: 0.459\n",
      "Loss after mini-batch   231: 0.546\n",
      "Loss after mini-batch   241: 2.224\n",
      "Loss after mini-batch   251: 0.093\n",
      "Loss after mini-batch   261: 0.345\n",
      "Loss after mini-batch   271: 2.517\n",
      "Loss after mini-batch   281: 5.927\n",
      "Loss after mini-batch   291: 8.183\n",
      "Loss after mini-batch   301: 3.031\n",
      "Loss after mini-batch   311: 0.364\n",
      "Loss after mini-batch   321: 5.347\n",
      "Loss after mini-batch   331: 0.762\n",
      "Loss after mini-batch   341: 7.071\n",
      "Loss after mini-batch   351: 1.156\n",
      "Loss after mini-batch   361: 9.391\n",
      "Loss after mini-batch   371: 0.115\n",
      "Training Loss: 0.155 \t\t Validation Loss:1.673\n",
      "Starting epoch 125\n",
      "Loss after mini-batch     1: 2.628\n",
      "Loss after mini-batch    11: 0.424\n",
      "Loss after mini-batch    21: 1.875\n",
      "Loss after mini-batch    31: 2.345\n",
      "Loss after mini-batch    41: 0.825\n",
      "Loss after mini-batch    51: 2.039\n",
      "Loss after mini-batch    61: 2.530\n",
      "Loss after mini-batch    71: 2.458\n",
      "Loss after mini-batch    81: 0.080\n",
      "Loss after mini-batch    91: 2.287\n",
      "Loss after mini-batch   101: 0.922\n",
      "Loss after mini-batch   111: 0.774\n",
      "Loss after mini-batch   121: 0.257\n",
      "Loss after mini-batch   131: 0.039\n",
      "Loss after mini-batch   141: 0.194\n",
      "Loss after mini-batch   151: 0.034\n",
      "Loss after mini-batch   161: 2.541\n",
      "Loss after mini-batch   171: 0.241\n",
      "Loss after mini-batch   181: 3.525\n",
      "Loss after mini-batch   191: 7.409\n",
      "Loss after mini-batch   201: 1.325\n",
      "Loss after mini-batch   211: 0.566\n",
      "Loss after mini-batch   221: 6.317\n",
      "Loss after mini-batch   231: 1.360\n",
      "Loss after mini-batch   241: 0.485\n",
      "Loss after mini-batch   251: 4.205\n",
      "Loss after mini-batch   261: 0.085\n",
      "Loss after mini-batch   271: 1.273\n",
      "Loss after mini-batch   281: 0.805\n",
      "Loss after mini-batch   291: 0.075\n",
      "Loss after mini-batch   301: 0.192\n",
      "Loss after mini-batch   311: 1.248\n",
      "Loss after mini-batch   321: 1.010\n",
      "Loss after mini-batch   331: 0.529\n",
      "Loss after mini-batch   341: 0.106\n",
      "Loss after mini-batch   351: 0.282\n",
      "Loss after mini-batch   361: 0.617\n",
      "Loss after mini-batch   371: 0.321\n",
      "Training Loss: 0.146 \t\t Validation Loss:0.261\n",
      "Starting epoch 126\n",
      "Loss after mini-batch     1: 0.202\n",
      "Loss after mini-batch    11: 0.284\n",
      "Loss after mini-batch    21: 6.411\n",
      "Loss after mini-batch    31: 1.154\n",
      "Loss after mini-batch    41: 0.085\n",
      "Loss after mini-batch    51: 1.265\n",
      "Loss after mini-batch    61: 5.483\n",
      "Loss after mini-batch    71: 0.873\n",
      "Loss after mini-batch    81: 1.505\n",
      "Loss after mini-batch    91: 0.269\n",
      "Loss after mini-batch   101: 0.246\n",
      "Loss after mini-batch   111: 0.214\n",
      "Loss after mini-batch   121: 2.252\n",
      "Loss after mini-batch   131: 0.034\n",
      "Loss after mini-batch   141: 0.222\n",
      "Loss after mini-batch   151: 0.122\n",
      "Loss after mini-batch   161: 0.160\n",
      "Loss after mini-batch   171: 0.249\n",
      "Loss after mini-batch   181: 0.057\n",
      "Loss after mini-batch   191: 0.576\n",
      "Loss after mini-batch   201: 0.066\n",
      "Loss after mini-batch   211: 0.117\n",
      "Loss after mini-batch   221: 0.399\n",
      "Loss after mini-batch   231: 0.145\n",
      "Loss after mini-batch   241: 0.067\n",
      "Loss after mini-batch   251: 0.322\n",
      "Loss after mini-batch   261: 0.584\n",
      "Loss after mini-batch   271: 0.333\n",
      "Loss after mini-batch   281: 10.092\n",
      "Loss after mini-batch   291: 0.081\n",
      "Loss after mini-batch   301: 0.042\n",
      "Loss after mini-batch   311: 1.346\n",
      "Loss after mini-batch   321: 7.722\n",
      "Loss after mini-batch   331: 0.954\n",
      "Loss after mini-batch   341: 2.041\n",
      "Loss after mini-batch   351: 7.314\n",
      "Loss after mini-batch   361: 0.280\n",
      "Loss after mini-batch   371: 0.177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.088 \t\t Validation Loss:0.799\n",
      "Starting epoch 127\n",
      "Loss after mini-batch     1: 0.615\n",
      "Loss after mini-batch    11: 11.493\n",
      "Loss after mini-batch    21: 0.902\n",
      "Loss after mini-batch    31: 1.149\n",
      "Loss after mini-batch    41: 0.084\n",
      "Loss after mini-batch    51: 0.223\n",
      "Loss after mini-batch    61: 1.028\n",
      "Loss after mini-batch    71: 0.215\n",
      "Loss after mini-batch    81: 4.554\n",
      "Loss after mini-batch    91: 3.495\n",
      "Loss after mini-batch   101: 1.701\n",
      "Loss after mini-batch   111: 0.262\n",
      "Loss after mini-batch   121: 2.876\n",
      "Loss after mini-batch   131: 3.837\n",
      "Loss after mini-batch   141: 0.411\n",
      "Loss after mini-batch   151: 0.483\n",
      "Loss after mini-batch   161: 0.253\n",
      "Loss after mini-batch   171: 0.382\n",
      "Loss after mini-batch   181: 2.205\n",
      "Loss after mini-batch   191: 0.119\n",
      "Loss after mini-batch   201: 0.065\n",
      "Loss after mini-batch   211: 0.754\n",
      "Loss after mini-batch   221: 0.405\n",
      "Loss after mini-batch   231: 0.189\n",
      "Loss after mini-batch   241: 0.629\n",
      "Loss after mini-batch   251: 0.047\n",
      "Loss after mini-batch   261: 0.432\n",
      "Loss after mini-batch   271: 2.080\n",
      "Loss after mini-batch   281: 0.166\n",
      "Loss after mini-batch   291: 11.017\n",
      "Loss after mini-batch   301: 0.480\n",
      "Loss after mini-batch   311: 0.214\n",
      "Loss after mini-batch   321: 5.604\n",
      "Loss after mini-batch   331: 0.761\n",
      "Loss after mini-batch   341: 0.172\n",
      "Loss after mini-batch   351: 0.383\n",
      "Loss after mini-batch   361: 6.520\n",
      "Loss after mini-batch   371: 0.342\n",
      "Training Loss: 3.937 \t\t Validation Loss:5.322\n",
      "Starting epoch 128\n",
      "Loss after mini-batch     1: 0.504\n",
      "Loss after mini-batch    11: 0.205\n",
      "Loss after mini-batch    21: 1.006\n",
      "Loss after mini-batch    31: 1.584\n",
      "Loss after mini-batch    41: 1.584\n",
      "Loss after mini-batch    51: 0.975\n",
      "Loss after mini-batch    61: 1.663\n",
      "Loss after mini-batch    71: 1.127\n",
      "Loss after mini-batch    81: 1.145\n",
      "Loss after mini-batch    91: 3.624\n",
      "Loss after mini-batch   101: 0.260\n",
      "Loss after mini-batch   111: 0.501\n",
      "Loss after mini-batch   121: 0.160\n",
      "Loss after mini-batch   131: 0.163\n",
      "Loss after mini-batch   141: 0.169\n",
      "Loss after mini-batch   151: 0.064\n",
      "Loss after mini-batch   161: 2.133\n",
      "Loss after mini-batch   171: 0.326\n",
      "Loss after mini-batch   181: 0.417\n",
      "Loss after mini-batch   191: 0.082\n",
      "Loss after mini-batch   201: 0.560\n",
      "Loss after mini-batch   211: 0.148\n",
      "Loss after mini-batch   221: 0.737\n",
      "Loss after mini-batch   231: 0.046\n",
      "Loss after mini-batch   241: 0.188\n",
      "Loss after mini-batch   251: 0.053\n",
      "Loss after mini-batch   261: 0.150\n",
      "Loss after mini-batch   271: 11.684\n",
      "Loss after mini-batch   281: 0.526\n",
      "Loss after mini-batch   291: 1.312\n",
      "Loss after mini-batch   301: 1.026\n",
      "Loss after mini-batch   311: 0.107\n",
      "Loss after mini-batch   321: 3.740\n",
      "Loss after mini-batch   331: 2.056\n",
      "Loss after mini-batch   341: 0.464\n",
      "Loss after mini-batch   351: 5.830\n",
      "Loss after mini-batch   361: 0.498\n",
      "Loss after mini-batch   371: 0.109\n",
      "Training Loss: 0.161 \t\t Validation Loss:0.454\n",
      "Starting epoch 129\n",
      "Loss after mini-batch     1: 2.217\n",
      "Loss after mini-batch    11: 0.892\n",
      "Loss after mini-batch    21: 0.095\n",
      "Loss after mini-batch    31: 1.318\n",
      "Loss after mini-batch    41: 9.965\n",
      "Loss after mini-batch    51: 1.172\n",
      "Loss after mini-batch    61: 0.078\n",
      "Loss after mini-batch    71: 9.753\n",
      "Loss after mini-batch    81: 0.424\n",
      "Loss after mini-batch    91: 1.500\n",
      "Loss after mini-batch   101: 3.776\n",
      "Loss after mini-batch   111: 1.652\n",
      "Loss after mini-batch   121: 0.281\n",
      "Loss after mini-batch   131: 2.233\n",
      "Loss after mini-batch   141: 0.021\n",
      "Loss after mini-batch   151: 0.152\n",
      "Loss after mini-batch   161: 7.325\n",
      "Loss after mini-batch   171: 0.191\n",
      "Loss after mini-batch   181: 0.098\n",
      "Loss after mini-batch   191: 13.060\n",
      "Loss after mini-batch   201: 0.161\n",
      "Loss after mini-batch   211: 0.254\n",
      "Loss after mini-batch   221: 0.806\n",
      "Loss after mini-batch   231: 5.850\n",
      "Loss after mini-batch   241: 5.964\n",
      "Loss after mini-batch   251: 0.205\n",
      "Loss after mini-batch   261: 4.517\n",
      "Loss after mini-batch   271: 1.646\n",
      "Loss after mini-batch   281: 0.452\n",
      "Loss after mini-batch   291: 0.361\n",
      "Loss after mini-batch   301: 2.808\n",
      "Loss after mini-batch   311: 1.399\n",
      "Loss after mini-batch   321: 3.196\n",
      "Loss after mini-batch   331: 3.980\n",
      "Loss after mini-batch   341: 1.298\n",
      "Loss after mini-batch   351: 1.510\n",
      "Loss after mini-batch   361: 1.757\n",
      "Loss after mini-batch   371: 0.954\n",
      "Training Loss: 5.321 \t\t Validation Loss:5.486\n",
      "Starting epoch 130\n",
      "Loss after mini-batch     1: 0.217\n",
      "Loss after mini-batch    11: 3.812\n",
      "Loss after mini-batch    21: 5.927\n",
      "Loss after mini-batch    31: 0.929\n",
      "Loss after mini-batch    41: 2.707\n",
      "Loss after mini-batch    51: 11.130\n",
      "Loss after mini-batch    61: 0.362\n",
      "Loss after mini-batch    71: 0.157\n",
      "Loss after mini-batch    81: 0.059\n",
      "Loss after mini-batch    91: 4.058\n",
      "Loss after mini-batch   101: 0.640\n",
      "Loss after mini-batch   111: 0.047\n",
      "Loss after mini-batch   121: 0.865\n",
      "Loss after mini-batch   131: 4.421\n",
      "Loss after mini-batch   141: 0.971\n",
      "Loss after mini-batch   151: 5.916\n",
      "Loss after mini-batch   161: 0.145\n",
      "Loss after mini-batch   171: 0.340\n",
      "Loss after mini-batch   181: 2.198\n",
      "Loss after mini-batch   191: 2.742\n",
      "Loss after mini-batch   201: 3.214\n",
      "Loss after mini-batch   211: 4.836\n",
      "Loss after mini-batch   221: 1.433\n",
      "Loss after mini-batch   231: 0.710\n",
      "Loss after mini-batch   241: 0.999\n",
      "Loss after mini-batch   251: 0.084\n",
      "Loss after mini-batch   261: 0.340\n",
      "Loss after mini-batch   271: 0.091\n",
      "Loss after mini-batch   281: 0.291\n",
      "Loss after mini-batch   291: 0.281\n",
      "Loss after mini-batch   301: 0.526\n",
      "Loss after mini-batch   311: 0.102\n",
      "Loss after mini-batch   321: 0.761\n",
      "Loss after mini-batch   331: 0.083\n",
      "Loss after mini-batch   341: 0.783\n",
      "Loss after mini-batch   351: 3.213\n",
      "Loss after mini-batch   361: 0.397\n",
      "Loss after mini-batch   371: 0.764\n",
      "Training Loss: 2.021 \t\t Validation Loss:6.317\n",
      "Starting epoch 131\n",
      "Loss after mini-batch     1: 0.699\n",
      "Loss after mini-batch    11: 0.086\n",
      "Loss after mini-batch    21: 0.262\n",
      "Loss after mini-batch    31: 2.581\n",
      "Loss after mini-batch    41: 0.038\n",
      "Loss after mini-batch    51: 9.086\n",
      "Loss after mini-batch    61: 0.139\n",
      "Loss after mini-batch    71: 5.234\n",
      "Loss after mini-batch    81: 3.937\n",
      "Loss after mini-batch    91: 0.195\n",
      "Loss after mini-batch   101: 2.882\n",
      "Loss after mini-batch   111: 1.441\n",
      "Loss after mini-batch   121: 0.602\n",
      "Loss after mini-batch   131: 1.309\n",
      "Loss after mini-batch   141: 0.401\n",
      "Loss after mini-batch   151: 0.289\n",
      "Loss after mini-batch   161: 0.174\n",
      "Loss after mini-batch   171: 0.288\n",
      "Loss after mini-batch   181: 0.648\n",
      "Loss after mini-batch   191: 0.034\n",
      "Loss after mini-batch   201: 20.318\n",
      "Loss after mini-batch   211: 0.290\n",
      "Loss after mini-batch   221: 0.064\n",
      "Loss after mini-batch   231: 0.276\n",
      "Loss after mini-batch   241: 4.890\n",
      "Loss after mini-batch   251: 0.293\n",
      "Loss after mini-batch   261: 1.149\n",
      "Loss after mini-batch   271: 0.433\n",
      "Loss after mini-batch   281: 2.246\n",
      "Loss after mini-batch   291: 1.778\n",
      "Loss after mini-batch   301: 0.062\n",
      "Loss after mini-batch   311: 0.077\n",
      "Loss after mini-batch   321: 0.122\n",
      "Loss after mini-batch   331: 0.301\n",
      "Loss after mini-batch   341: 0.098\n",
      "Loss after mini-batch   351: 0.381\n",
      "Loss after mini-batch   361: 6.067\n",
      "Loss after mini-batch   371: 0.250\n",
      "Training Loss: 1.041 \t\t Validation Loss:3.407\n",
      "Starting epoch 132\n",
      "Loss after mini-batch     1: 10.659\n",
      "Loss after mini-batch    11: 9.577\n",
      "Loss after mini-batch    21: 0.261\n",
      "Loss after mini-batch    31: 0.115\n",
      "Loss after mini-batch    41: 1.223\n",
      "Loss after mini-batch    51: 1.364\n",
      "Loss after mini-batch    61: 2.984\n",
      "Loss after mini-batch    71: 0.345\n",
      "Loss after mini-batch    81: 2.749\n",
      "Loss after mini-batch    91: 6.288\n",
      "Loss after mini-batch   101: 1.196\n",
      "Loss after mini-batch   111: 0.120\n",
      "Loss after mini-batch   121: 0.308\n",
      "Loss after mini-batch   131: 0.070\n",
      "Loss after mini-batch   141: 2.058\n",
      "Loss after mini-batch   151: 0.080\n",
      "Loss after mini-batch   161: 7.408\n",
      "Loss after mini-batch   171: 4.997\n",
      "Loss after mini-batch   181: 1.382\n",
      "Loss after mini-batch   191: 0.294\n",
      "Loss after mini-batch   201: 0.683\n",
      "Loss after mini-batch   211: 0.064\n",
      "Loss after mini-batch   221: 1.139\n",
      "Loss after mini-batch   231: 0.372\n",
      "Loss after mini-batch   241: 0.795\n",
      "Loss after mini-batch   251: 0.185\n",
      "Loss after mini-batch   261: 3.236\n",
      "Loss after mini-batch   271: 0.397\n",
      "Loss after mini-batch   281: 0.471\n",
      "Loss after mini-batch   291: 0.099\n",
      "Loss after mini-batch   301: 0.091\n",
      "Loss after mini-batch   311: 0.156\n",
      "Loss after mini-batch   321: 0.077\n",
      "Loss after mini-batch   331: 0.245\n",
      "Loss after mini-batch   341: 7.097\n",
      "Loss after mini-batch   351: 18.681\n",
      "Loss after mini-batch   361: 5.967\n",
      "Loss after mini-batch   371: 0.967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.333 \t\t Validation Loss:7.090\n",
      "Starting epoch 133\n",
      "Loss after mini-batch     1: 0.046\n",
      "Loss after mini-batch    11: 0.378\n",
      "Loss after mini-batch    21: 0.487\n",
      "Loss after mini-batch    31: 1.681\n",
      "Loss after mini-batch    41: 2.522\n",
      "Loss after mini-batch    51: 1.190\n",
      "Loss after mini-batch    61: 0.491\n",
      "Loss after mini-batch    71: 0.546\n",
      "Loss after mini-batch    81: 2.250\n",
      "Loss after mini-batch    91: 4.651\n",
      "Loss after mini-batch   101: 0.766\n",
      "Loss after mini-batch   111: 0.167\n",
      "Loss after mini-batch   121: 2.174\n",
      "Loss after mini-batch   131: 0.329\n",
      "Loss after mini-batch   141: 0.038\n",
      "Loss after mini-batch   151: 0.388\n",
      "Loss after mini-batch   161: 0.613\n",
      "Loss after mini-batch   171: 2.181\n",
      "Loss after mini-batch   181: 0.271\n",
      "Loss after mini-batch   191: 0.195\n",
      "Loss after mini-batch   201: 1.690\n",
      "Loss after mini-batch   211: 5.566\n",
      "Loss after mini-batch   221: 0.434\n",
      "Loss after mini-batch   231: 0.810\n",
      "Loss after mini-batch   241: 10.749\n",
      "Loss after mini-batch   251: 0.188\n",
      "Loss after mini-batch   261: 0.267\n",
      "Loss after mini-batch   271: 4.256\n",
      "Loss after mini-batch   281: 0.548\n",
      "Loss after mini-batch   291: 0.407\n",
      "Loss after mini-batch   301: 7.602\n",
      "Loss after mini-batch   311: 0.158\n",
      "Loss after mini-batch   321: 5.064\n",
      "Loss after mini-batch   331: 0.077\n",
      "Loss after mini-batch   341: 0.861\n",
      "Loss after mini-batch   351: 0.362\n",
      "Loss after mini-batch   361: 20.182\n",
      "Loss after mini-batch   371: 0.171\n",
      "Training Loss: 0.513 \t\t Validation Loss:1.277\n",
      "Starting epoch 134\n",
      "Loss after mini-batch     1: 2.012\n",
      "Loss after mini-batch    11: 1.319\n",
      "Loss after mini-batch    21: 0.142\n",
      "Loss after mini-batch    31: 10.817\n",
      "Loss after mini-batch    41: 2.539\n",
      "Loss after mini-batch    51: 0.311\n",
      "Loss after mini-batch    61: 0.471\n",
      "Loss after mini-batch    71: 0.963\n",
      "Loss after mini-batch    81: 0.176\n",
      "Loss after mini-batch    91: 1.325\n",
      "Loss after mini-batch   101: 0.292\n",
      "Loss after mini-batch   111: 0.182\n",
      "Loss after mini-batch   121: 0.201\n",
      "Loss after mini-batch   131: 3.085\n",
      "Loss after mini-batch   141: 0.092\n",
      "Loss after mini-batch   151: 0.260\n",
      "Loss after mini-batch   161: 0.074\n",
      "Loss after mini-batch   171: 0.026\n",
      "Loss after mini-batch   181: 2.793\n",
      "Loss after mini-batch   191: 0.441\n",
      "Loss after mini-batch   201: 0.387\n",
      "Loss after mini-batch   211: 2.290\n",
      "Loss after mini-batch   221: 0.046\n",
      "Loss after mini-batch   231: 0.082\n",
      "Loss after mini-batch   241: 9.774\n",
      "Loss after mini-batch   251: 0.157\n",
      "Loss after mini-batch   261: 0.524\n",
      "Loss after mini-batch   271: 0.154\n",
      "Loss after mini-batch   281: 1.074\n",
      "Loss after mini-batch   291: 0.229\n",
      "Loss after mini-batch   301: 0.224\n",
      "Loss after mini-batch   311: 2.863\n",
      "Loss after mini-batch   321: 0.466\n",
      "Loss after mini-batch   331: 0.986\n",
      "Loss after mini-batch   341: 0.531\n",
      "Loss after mini-batch   351: 9.340\n",
      "Loss after mini-batch   361: 1.370\n",
      "Loss after mini-batch   371: 2.585\n",
      "Training Loss: 0.143 \t\t Validation Loss:0.226\n",
      "Starting epoch 135\n",
      "Loss after mini-batch     1: 0.205\n",
      "Loss after mini-batch    11: 0.115\n",
      "Loss after mini-batch    21: 7.801\n",
      "Loss after mini-batch    31: 0.088\n",
      "Loss after mini-batch    41: 0.538\n",
      "Loss after mini-batch    51: 1.654\n",
      "Loss after mini-batch    61: 0.197\n",
      "Loss after mini-batch    71: 1.839\n",
      "Loss after mini-batch    81: 0.475\n",
      "Loss after mini-batch    91: 1.045\n",
      "Loss after mini-batch   101: 0.620\n",
      "Loss after mini-batch   111: 0.274\n",
      "Loss after mini-batch   121: 0.242\n",
      "Loss after mini-batch   131: 0.120\n",
      "Loss after mini-batch   141: 1.187\n",
      "Loss after mini-batch   151: 1.537\n",
      "Loss after mini-batch   161: 3.388\n",
      "Loss after mini-batch   171: 1.809\n",
      "Loss after mini-batch   181: 0.848\n",
      "Loss after mini-batch   191: 0.964\n",
      "Loss after mini-batch   201: 1.490\n",
      "Loss after mini-batch   211: 0.459\n",
      "Loss after mini-batch   221: 0.167\n",
      "Loss after mini-batch   231: 1.179\n",
      "Loss after mini-batch   241: 1.961\n",
      "Loss after mini-batch   251: 0.212\n",
      "Loss after mini-batch   261: 2.556\n",
      "Loss after mini-batch   271: 0.999\n",
      "Loss after mini-batch   281: 0.425\n",
      "Loss after mini-batch   291: 0.580\n",
      "Loss after mini-batch   301: 0.091\n",
      "Loss after mini-batch   311: 0.053\n",
      "Loss after mini-batch   321: 0.719\n",
      "Loss after mini-batch   331: 0.579\n",
      "Loss after mini-batch   341: 0.102\n",
      "Loss after mini-batch   351: 2.593\n",
      "Loss after mini-batch   361: 2.866\n",
      "Loss after mini-batch   371: 0.719\n",
      "Training Loss: 2.818 \t\t Validation Loss:5.128\n",
      "Starting epoch 136\n",
      "Loss after mini-batch     1: 0.158\n",
      "Loss after mini-batch    11: 0.973\n",
      "Loss after mini-batch    21: 2.744\n",
      "Loss after mini-batch    31: 3.034\n",
      "Loss after mini-batch    41: 0.046\n",
      "Loss after mini-batch    51: 0.993\n",
      "Loss after mini-batch    61: 0.444\n",
      "Loss after mini-batch    71: 0.407\n",
      "Loss after mini-batch    81: 10.548\n",
      "Loss after mini-batch    91: 8.358\n",
      "Loss after mini-batch   101: 4.985\n",
      "Loss after mini-batch   111: 0.274\n",
      "Loss after mini-batch   121: 4.277\n",
      "Loss after mini-batch   131: 0.391\n",
      "Loss after mini-batch   141: 0.285\n",
      "Loss after mini-batch   151: 0.511\n",
      "Loss after mini-batch   161: 6.663\n",
      "Loss after mini-batch   171: 0.095\n",
      "Loss after mini-batch   181: 0.326\n",
      "Loss after mini-batch   191: 0.709\n",
      "Loss after mini-batch   201: 1.491\n",
      "Loss after mini-batch   211: 0.705\n",
      "Loss after mini-batch   221: 0.456\n",
      "Loss after mini-batch   231: 0.478\n",
      "Loss after mini-batch   241: 0.544\n",
      "Loss after mini-batch   251: 0.765\n",
      "Loss after mini-batch   261: 1.012\n",
      "Loss after mini-batch   271: 1.690\n",
      "Loss after mini-batch   281: 0.184\n",
      "Loss after mini-batch   291: 1.785\n",
      "Loss after mini-batch   301: 0.632\n",
      "Loss after mini-batch   311: 7.174\n",
      "Loss after mini-batch   321: 0.330\n",
      "Loss after mini-batch   331: 0.401\n",
      "Loss after mini-batch   341: 0.124\n",
      "Loss after mini-batch   351: 3.451\n",
      "Loss after mini-batch   361: 0.078\n",
      "Loss after mini-batch   371: 1.362\n",
      "Training Loss: 0.032 \t\t Validation Loss:5.464\n",
      "Starting epoch 137\n",
      "Loss after mini-batch     1: 6.472\n",
      "Loss after mini-batch    11: 0.196\n",
      "Loss after mini-batch    21: 9.034\n",
      "Loss after mini-batch    31: 1.859\n",
      "Loss after mini-batch    41: 0.433\n",
      "Loss after mini-batch    51: 0.102\n",
      "Loss after mini-batch    61: 0.240\n",
      "Loss after mini-batch    71: 1.373\n",
      "Loss after mini-batch    81: 2.311\n",
      "Loss after mini-batch    91: 2.150\n",
      "Loss after mini-batch   101: 0.347\n",
      "Loss after mini-batch   111: 0.322\n",
      "Loss after mini-batch   121: 3.447\n",
      "Loss after mini-batch   131: 2.096\n",
      "Loss after mini-batch   141: 0.249\n",
      "Loss after mini-batch   151: 1.381\n",
      "Loss after mini-batch   161: 0.470\n",
      "Loss after mini-batch   171: 7.089\n",
      "Loss after mini-batch   181: 0.228\n",
      "Loss after mini-batch   191: 4.821\n",
      "Loss after mini-batch   201: 0.953\n",
      "Loss after mini-batch   211: 2.645\n",
      "Loss after mini-batch   221: 0.367\n",
      "Loss after mini-batch   231: 0.352\n",
      "Loss after mini-batch   241: 0.154\n",
      "Loss after mini-batch   251: 1.278\n",
      "Loss after mini-batch   261: 0.452\n",
      "Loss after mini-batch   271: 0.015\n",
      "Loss after mini-batch   281: 0.875\n",
      "Loss after mini-batch   291: 1.196\n",
      "Loss after mini-batch   301: 3.557\n",
      "Loss after mini-batch   311: 0.171\n",
      "Loss after mini-batch   321: 0.377\n",
      "Loss after mini-batch   331: 0.931\n",
      "Loss after mini-batch   341: 2.740\n",
      "Loss after mini-batch   351: 0.277\n",
      "Loss after mini-batch   361: 2.327\n",
      "Loss after mini-batch   371: 0.281\n",
      "Training Loss: 0.429 \t\t Validation Loss:5.574\n",
      "Starting epoch 138\n",
      "Loss after mini-batch     1: 0.201\n",
      "Loss after mini-batch    11: 0.817\n",
      "Loss after mini-batch    21: 1.284\n",
      "Loss after mini-batch    31: 2.461\n",
      "Loss after mini-batch    41: 0.155\n",
      "Loss after mini-batch    51: 0.256\n",
      "Loss after mini-batch    61: 1.569\n",
      "Loss after mini-batch    71: 1.019\n",
      "Loss after mini-batch    81: 18.835\n",
      "Loss after mini-batch    91: 2.215\n",
      "Loss after mini-batch   101: 0.322\n",
      "Loss after mini-batch   111: 1.918\n",
      "Loss after mini-batch   121: 0.399\n",
      "Loss after mini-batch   131: 0.100\n",
      "Loss after mini-batch   141: 0.832\n",
      "Loss after mini-batch   151: 2.091\n",
      "Loss after mini-batch   161: 0.108\n",
      "Loss after mini-batch   171: 0.153\n",
      "Loss after mini-batch   181: 0.756\n",
      "Loss after mini-batch   191: 2.890\n",
      "Loss after mini-batch   201: 7.124\n",
      "Loss after mini-batch   211: 0.648\n",
      "Loss after mini-batch   221: 1.537\n",
      "Loss after mini-batch   231: 1.277\n",
      "Loss after mini-batch   241: 0.165\n",
      "Loss after mini-batch   251: 3.592\n",
      "Loss after mini-batch   261: 0.850\n",
      "Loss after mini-batch   271: 2.797\n",
      "Loss after mini-batch   281: 0.065\n",
      "Loss after mini-batch   291: 3.442\n",
      "Loss after mini-batch   301: 5.929\n",
      "Loss after mini-batch   311: 0.351\n",
      "Loss after mini-batch   321: 1.353\n",
      "Loss after mini-batch   331: 1.017\n",
      "Loss after mini-batch   341: 0.031\n",
      "Loss after mini-batch   351: 4.781\n",
      "Loss after mini-batch   361: 0.223\n",
      "Loss after mini-batch   371: 2.020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 7.353 \t\t Validation Loss:7.890\n",
      "Starting epoch 139\n",
      "Loss after mini-batch     1: 0.162\n",
      "Loss after mini-batch    11: 0.473\n",
      "Loss after mini-batch    21: 2.310\n",
      "Loss after mini-batch    31: 3.236\n",
      "Loss after mini-batch    41: 0.117\n",
      "Loss after mini-batch    51: 0.633\n",
      "Loss after mini-batch    61: 0.116\n",
      "Loss after mini-batch    71: 0.450\n",
      "Loss after mini-batch    81: 0.214\n",
      "Loss after mini-batch    91: 4.706\n",
      "Loss after mini-batch   101: 2.165\n",
      "Loss after mini-batch   111: 1.925\n",
      "Loss after mini-batch   121: 2.794\n",
      "Loss after mini-batch   131: 0.562\n",
      "Loss after mini-batch   141: 1.450\n",
      "Loss after mini-batch   151: 9.734\n",
      "Loss after mini-batch   161: 1.685\n",
      "Loss after mini-batch   171: 22.819\n",
      "Loss after mini-batch   181: 0.740\n",
      "Loss after mini-batch   191: 0.947\n",
      "Loss after mini-batch   201: 1.353\n",
      "Loss after mini-batch   211: 1.658\n",
      "Loss after mini-batch   221: 0.034\n",
      "Loss after mini-batch   231: 1.412\n",
      "Loss after mini-batch   241: 0.257\n",
      "Loss after mini-batch   251: 0.967\n",
      "Loss after mini-batch   261: 1.270\n",
      "Loss after mini-batch   271: 7.940\n",
      "Loss after mini-batch   281: 0.449\n",
      "Loss after mini-batch   291: 3.948\n",
      "Loss after mini-batch   301: 4.414\n",
      "Loss after mini-batch   311: 1.207\n",
      "Loss after mini-batch   321: 1.305\n",
      "Loss after mini-batch   331: 0.089\n",
      "Loss after mini-batch   341: 0.246\n",
      "Loss after mini-batch   351: 0.318\n",
      "Loss after mini-batch   361: 7.307\n",
      "Loss after mini-batch   371: 0.153\n",
      "Training Loss: 6.629 \t\t Validation Loss:12.584\n",
      "Starting epoch 140\n",
      "Loss after mini-batch     1: 37.833\n",
      "Loss after mini-batch    11: 1.238\n",
      "Loss after mini-batch    21: 0.699\n",
      "Loss after mini-batch    31: 1.707\n",
      "Loss after mini-batch    41: 0.094\n",
      "Loss after mini-batch    51: 7.055\n",
      "Loss after mini-batch    61: 0.200\n",
      "Loss after mini-batch    71: 1.364\n",
      "Loss after mini-batch    81: 0.389\n",
      "Loss after mini-batch    91: 8.473\n",
      "Loss after mini-batch   101: 0.475\n",
      "Loss after mini-batch   111: 2.877\n",
      "Loss after mini-batch   121: 6.666\n",
      "Loss after mini-batch   131: 0.363\n",
      "Loss after mini-batch   141: 2.870\n",
      "Loss after mini-batch   151: 1.034\n",
      "Loss after mini-batch   161: 5.260\n",
      "Loss after mini-batch   171: 0.195\n",
      "Loss after mini-batch   181: 0.174\n",
      "Loss after mini-batch   191: 0.048\n",
      "Loss after mini-batch   201: 7.661\n",
      "Loss after mini-batch   211: 1.094\n",
      "Loss after mini-batch   221: 0.108\n",
      "Loss after mini-batch   231: 5.460\n",
      "Loss after mini-batch   241: 0.859\n",
      "Loss after mini-batch   251: 0.742\n",
      "Loss after mini-batch   261: 2.847\n",
      "Loss after mini-batch   271: 0.102\n",
      "Loss after mini-batch   281: 0.475\n",
      "Loss after mini-batch   291: 1.198\n",
      "Loss after mini-batch   301: 2.689\n",
      "Loss after mini-batch   311: 1.209\n",
      "Loss after mini-batch   321: 1.668\n",
      "Loss after mini-batch   331: 0.283\n",
      "Loss after mini-batch   341: 5.289\n",
      "Loss after mini-batch   351: 1.803\n",
      "Loss after mini-batch   361: 0.786\n",
      "Loss after mini-batch   371: 0.323\n",
      "Training Loss: 0.183 \t\t Validation Loss:0.238\n",
      "Starting epoch 141\n",
      "Loss after mini-batch     1: 0.084\n",
      "Loss after mini-batch    11: 2.666\n",
      "Loss after mini-batch    21: 0.111\n",
      "Loss after mini-batch    31: 0.112\n",
      "Loss after mini-batch    41: 0.324\n",
      "Loss after mini-batch    51: 3.930\n",
      "Loss after mini-batch    61: 1.390\n",
      "Loss after mini-batch    71: 1.791\n",
      "Loss after mini-batch    81: 0.763\n",
      "Loss after mini-batch    91: 18.177\n",
      "Loss after mini-batch   101: 0.337\n",
      "Loss after mini-batch   111: 0.095\n",
      "Loss after mini-batch   121: 5.328\n",
      "Loss after mini-batch   131: 19.611\n",
      "Loss after mini-batch   141: 0.018\n",
      "Loss after mini-batch   151: 0.020\n",
      "Loss after mini-batch   161: 2.065\n",
      "Loss after mini-batch   171: 0.353\n",
      "Loss after mini-batch   181: 0.355\n",
      "Loss after mini-batch   191: 0.330\n",
      "Loss after mini-batch   201: 1.676\n",
      "Loss after mini-batch   211: 0.845\n",
      "Loss after mini-batch   221: 0.131\n",
      "Loss after mini-batch   231: 0.076\n",
      "Loss after mini-batch   241: 0.258\n",
      "Loss after mini-batch   251: 1.262\n",
      "Loss after mini-batch   261: 0.150\n",
      "Loss after mini-batch   271: 1.798\n",
      "Loss after mini-batch   281: 0.265\n",
      "Loss after mini-batch   291: 0.082\n",
      "Loss after mini-batch   301: 1.060\n",
      "Loss after mini-batch   311: 0.369\n",
      "Loss after mini-batch   321: 1.158\n",
      "Loss after mini-batch   331: 0.049\n",
      "Loss after mini-batch   341: 1.649\n",
      "Loss after mini-batch   351: 4.450\n",
      "Loss after mini-batch   361: 5.248\n",
      "Loss after mini-batch   371: 1.797\n",
      "Training Loss: 0.348 \t\t Validation Loss:1.708\n",
      "Starting epoch 142\n",
      "Loss after mini-batch     1: 0.673\n",
      "Loss after mini-batch    11: 0.276\n",
      "Loss after mini-batch    21: 0.102\n",
      "Loss after mini-batch    31: 0.013\n",
      "Loss after mini-batch    41: 0.807\n",
      "Loss after mini-batch    51: 0.856\n",
      "Loss after mini-batch    61: 20.516\n",
      "Loss after mini-batch    71: 1.687\n",
      "Loss after mini-batch    81: 0.183\n",
      "Loss after mini-batch    91: 8.559\n",
      "Loss after mini-batch   101: 0.416\n",
      "Loss after mini-batch   111: 5.244\n",
      "Loss after mini-batch   121: 1.172\n",
      "Loss after mini-batch   131: 0.070\n",
      "Loss after mini-batch   141: 0.782\n",
      "Loss after mini-batch   151: 0.554\n",
      "Loss after mini-batch   161: 0.582\n",
      "Loss after mini-batch   171: 7.507\n",
      "Loss after mini-batch   181: 23.058\n",
      "Loss after mini-batch   191: 1.723\n",
      "Loss after mini-batch   201: 0.082\n",
      "Loss after mini-batch   211: 0.205\n",
      "Loss after mini-batch   221: 0.516\n",
      "Loss after mini-batch   231: 0.177\n",
      "Loss after mini-batch   241: 0.502\n",
      "Loss after mini-batch   251: 5.241\n",
      "Loss after mini-batch   261: 11.635\n",
      "Loss after mini-batch   271: 0.140\n",
      "Loss after mini-batch   281: 0.302\n",
      "Loss after mini-batch   291: 0.274\n",
      "Loss after mini-batch   301: 0.027\n",
      "Loss after mini-batch   311: 0.056\n",
      "Loss after mini-batch   321: 1.779\n",
      "Loss after mini-batch   331: 0.263\n",
      "Loss after mini-batch   341: 0.543\n",
      "Loss after mini-batch   351: 1.247\n",
      "Loss after mini-batch   361: 0.669\n",
      "Loss after mini-batch   371: 0.211\n",
      "Training Loss: 0.370 \t\t Validation Loss:1.051\n",
      "Starting epoch 143\n",
      "Loss after mini-batch     1: 1.683\n",
      "Loss after mini-batch    11: 1.576\n",
      "Loss after mini-batch    21: 0.123\n",
      "Loss after mini-batch    31: 0.476\n",
      "Loss after mini-batch    41: 0.008\n",
      "Loss after mini-batch    51: 4.458\n",
      "Loss after mini-batch    61: 0.114\n",
      "Loss after mini-batch    71: 0.954\n",
      "Loss after mini-batch    81: 0.038\n",
      "Loss after mini-batch    91: 5.938\n",
      "Loss after mini-batch   101: 0.653\n",
      "Loss after mini-batch   111: 0.783\n",
      "Loss after mini-batch   121: 1.133\n",
      "Loss after mini-batch   131: 0.060\n",
      "Loss after mini-batch   141: 0.452\n",
      "Loss after mini-batch   151: 0.211\n",
      "Loss after mini-batch   161: 2.189\n",
      "Loss after mini-batch   171: 0.225\n",
      "Loss after mini-batch   181: 1.966\n",
      "Loss after mini-batch   191: 0.741\n",
      "Loss after mini-batch   201: 0.451\n",
      "Loss after mini-batch   211: 5.334\n",
      "Loss after mini-batch   221: 1.401\n",
      "Loss after mini-batch   231: 0.136\n",
      "Loss after mini-batch   241: 7.942\n",
      "Loss after mini-batch   251: 0.500\n",
      "Loss after mini-batch   261: 5.591\n",
      "Loss after mini-batch   271: 10.513\n",
      "Loss after mini-batch   281: 0.496\n",
      "Loss after mini-batch   291: 2.945\n",
      "Loss after mini-batch   301: 1.403\n",
      "Loss after mini-batch   311: 3.693\n",
      "Loss after mini-batch   321: 1.259\n",
      "Loss after mini-batch   331: 3.519\n",
      "Loss after mini-batch   341: 0.398\n",
      "Loss after mini-batch   351: 2.931\n",
      "Loss after mini-batch   361: 0.076\n",
      "Loss after mini-batch   371: 0.054\n",
      "Training Loss: 0.109 \t\t Validation Loss:1.087\n",
      "Starting epoch 144\n",
      "Loss after mini-batch     1: 0.470\n",
      "Loss after mini-batch    11: 0.252\n",
      "Loss after mini-batch    21: 0.347\n",
      "Loss after mini-batch    31: 0.090\n",
      "Loss after mini-batch    41: 0.193\n",
      "Loss after mini-batch    51: 5.214\n",
      "Loss after mini-batch    61: 0.587\n",
      "Loss after mini-batch    71: 0.197\n",
      "Loss after mini-batch    81: 0.307\n",
      "Loss after mini-batch    91: 3.534\n",
      "Loss after mini-batch   101: 0.827\n",
      "Loss after mini-batch   111: 0.576\n",
      "Loss after mini-batch   121: 0.055\n",
      "Loss after mini-batch   131: 0.727\n",
      "Loss after mini-batch   141: 1.108\n",
      "Loss after mini-batch   151: 0.055\n",
      "Loss after mini-batch   161: 0.165\n",
      "Loss after mini-batch   171: 0.251\n",
      "Loss after mini-batch   181: 0.042\n",
      "Loss after mini-batch   191: 0.269\n",
      "Loss after mini-batch   201: 1.434\n",
      "Loss after mini-batch   211: 0.481\n",
      "Loss after mini-batch   221: 1.385\n",
      "Loss after mini-batch   231: 0.620\n",
      "Loss after mini-batch   241: 0.122\n",
      "Loss after mini-batch   251: 8.731\n",
      "Loss after mini-batch   261: 5.634\n",
      "Loss after mini-batch   271: 0.181\n",
      "Loss after mini-batch   281: 5.460\n",
      "Loss after mini-batch   291: 0.871\n",
      "Loss after mini-batch   301: 1.244\n",
      "Loss after mini-batch   311: 0.204\n",
      "Loss after mini-batch   321: 0.238\n",
      "Loss after mini-batch   331: 0.339\n",
      "Loss after mini-batch   341: 0.277\n",
      "Loss after mini-batch   351: 33.943\n",
      "Loss after mini-batch   361: 0.531\n",
      "Loss after mini-batch   371: 0.867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.486 \t\t Validation Loss:0.617\n",
      "Starting epoch 145\n",
      "Loss after mini-batch     1: 4.639\n",
      "Loss after mini-batch    11: 0.688\n",
      "Loss after mini-batch    21: 0.381\n",
      "Loss after mini-batch    31: 0.425\n",
      "Loss after mini-batch    41: 10.028\n",
      "Loss after mini-batch    51: 0.050\n",
      "Loss after mini-batch    61: 0.018\n",
      "Loss after mini-batch    71: 4.558\n",
      "Loss after mini-batch    81: 0.644\n",
      "Loss after mini-batch    91: 0.169\n",
      "Loss after mini-batch   101: 0.188\n",
      "Loss after mini-batch   111: 1.382\n",
      "Loss after mini-batch   121: 0.007\n",
      "Loss after mini-batch   131: 0.671\n",
      "Loss after mini-batch   141: 1.953\n",
      "Loss after mini-batch   151: 4.828\n",
      "Loss after mini-batch   161: 0.339\n",
      "Loss after mini-batch   171: 1.106\n",
      "Loss after mini-batch   181: 0.187\n",
      "Loss after mini-batch   191: 0.050\n",
      "Loss after mini-batch   201: 0.801\n",
      "Loss after mini-batch   211: 1.569\n",
      "Loss after mini-batch   221: 0.501\n",
      "Loss after mini-batch   231: 2.238\n",
      "Loss after mini-batch   241: 0.209\n",
      "Loss after mini-batch   251: 0.314\n",
      "Loss after mini-batch   261: 0.178\n",
      "Loss after mini-batch   271: 0.166\n",
      "Loss after mini-batch   281: 1.332\n",
      "Loss after mini-batch   291: 0.909\n",
      "Loss after mini-batch   301: 0.608\n",
      "Loss after mini-batch   311: 6.233\n",
      "Loss after mini-batch   321: 1.490\n",
      "Loss after mini-batch   331: 0.308\n",
      "Loss after mini-batch   341: 0.067\n",
      "Loss after mini-batch   351: 0.668\n",
      "Loss after mini-batch   361: 1.019\n",
      "Loss after mini-batch   371: 4.168\n",
      "Training Loss: 4.387 \t\t Validation Loss:7.978\n",
      "Starting epoch 146\n",
      "Loss after mini-batch     1: 0.326\n",
      "Loss after mini-batch    11: 0.167\n",
      "Loss after mini-batch    21: 0.095\n",
      "Loss after mini-batch    31: 2.733\n",
      "Loss after mini-batch    41: 1.236\n",
      "Loss after mini-batch    51: 2.697\n",
      "Loss after mini-batch    61: 1.748\n",
      "Loss after mini-batch    71: 2.266\n",
      "Loss after mini-batch    81: 5.991\n",
      "Loss after mini-batch    91: 1.738\n",
      "Loss after mini-batch   101: 1.376\n",
      "Loss after mini-batch   111: 0.024\n",
      "Loss after mini-batch   121: 1.129\n",
      "Loss after mini-batch   131: 0.449\n",
      "Loss after mini-batch   141: 0.115\n",
      "Loss after mini-batch   151: 6.224\n",
      "Loss after mini-batch   161: 0.030\n",
      "Loss after mini-batch   171: 0.028\n",
      "Loss after mini-batch   181: 0.117\n",
      "Loss after mini-batch   191: 1.414\n",
      "Loss after mini-batch   201: 1.187\n",
      "Loss after mini-batch   211: 1.644\n",
      "Loss after mini-batch   221: 0.017\n",
      "Loss after mini-batch   231: 0.176\n",
      "Loss after mini-batch   241: 0.681\n",
      "Loss after mini-batch   251: 1.202\n",
      "Loss after mini-batch   261: 0.113\n",
      "Loss after mini-batch   271: 0.527\n",
      "Loss after mini-batch   281: 0.561\n",
      "Loss after mini-batch   291: 0.069\n",
      "Loss after mini-batch   301: 0.606\n",
      "Loss after mini-batch   311: 3.510\n",
      "Loss after mini-batch   321: 0.905\n",
      "Loss after mini-batch   331: 0.049\n",
      "Loss after mini-batch   341: 1.263\n",
      "Loss after mini-batch   351: 2.165\n",
      "Loss after mini-batch   361: 0.447\n",
      "Loss after mini-batch   371: 0.251\n",
      "Training Loss: 0.259 \t\t Validation Loss:4.447\n",
      "Starting epoch 147\n",
      "Loss after mini-batch     1: 1.069\n",
      "Loss after mini-batch    11: 9.810\n",
      "Loss after mini-batch    21: 1.381\n",
      "Loss after mini-batch    31: 7.003\n",
      "Loss after mini-batch    41: 6.103\n",
      "Loss after mini-batch    51: 0.249\n",
      "Loss after mini-batch    61: 5.042\n",
      "Loss after mini-batch    71: 0.110\n",
      "Loss after mini-batch    81: 1.310\n",
      "Loss after mini-batch    91: 0.476\n",
      "Loss after mini-batch   101: 0.316\n",
      "Loss after mini-batch   111: 2.778\n",
      "Loss after mini-batch   121: 1.130\n",
      "Loss after mini-batch   131: 2.646\n",
      "Loss after mini-batch   141: 0.197\n",
      "Loss after mini-batch   151: 0.877\n",
      "Loss after mini-batch   161: 0.142\n",
      "Loss after mini-batch   171: 9.393\n",
      "Loss after mini-batch   181: 1.495\n",
      "Loss after mini-batch   191: 0.477\n",
      "Loss after mini-batch   201: 0.926\n",
      "Loss after mini-batch   211: 0.273\n",
      "Loss after mini-batch   221: 0.251\n",
      "Loss after mini-batch   231: 0.163\n",
      "Loss after mini-batch   241: 0.088\n",
      "Loss after mini-batch   251: 5.704\n",
      "Loss after mini-batch   261: 0.063\n",
      "Loss after mini-batch   271: 0.478\n",
      "Loss after mini-batch   281: 2.389\n",
      "Loss after mini-batch   291: 0.141\n",
      "Loss after mini-batch   301: 0.348\n",
      "Loss after mini-batch   311: 0.172\n",
      "Loss after mini-batch   321: 4.170\n",
      "Loss after mini-batch   331: 1.380\n",
      "Loss after mini-batch   341: 8.258\n",
      "Loss after mini-batch   351: 0.819\n",
      "Loss after mini-batch   361: 2.425\n",
      "Loss after mini-batch   371: 0.144\n",
      "Training Loss: 0.560 \t\t Validation Loss:1.376\n",
      "Starting epoch 148\n",
      "Loss after mini-batch     1: 7.790\n",
      "Loss after mini-batch    11: 0.457\n",
      "Loss after mini-batch    21: 1.151\n",
      "Loss after mini-batch    31: 5.383\n",
      "Loss after mini-batch    41: 0.060\n",
      "Loss after mini-batch    51: 0.082\n",
      "Loss after mini-batch    61: 9.981\n",
      "Loss after mini-batch    71: 0.123\n",
      "Loss after mini-batch    81: 0.596\n",
      "Loss after mini-batch    91: 7.066\n",
      "Loss after mini-batch   101: 2.022\n",
      "Loss after mini-batch   111: 0.605\n",
      "Loss after mini-batch   121: 0.215\n",
      "Loss after mini-batch   131: 7.003\n",
      "Loss after mini-batch   141: 2.396\n",
      "Loss after mini-batch   151: 0.903\n",
      "Loss after mini-batch   161: 1.157\n",
      "Loss after mini-batch   171: 0.211\n",
      "Loss after mini-batch   181: 5.832\n",
      "Loss after mini-batch   191: 0.747\n",
      "Loss after mini-batch   201: 0.189\n",
      "Loss after mini-batch   211: 1.518\n",
      "Loss after mini-batch   221: 0.299\n",
      "Loss after mini-batch   231: 0.081\n",
      "Loss after mini-batch   241: 4.382\n",
      "Loss after mini-batch   251: 0.309\n",
      "Loss after mini-batch   261: 7.023\n",
      "Loss after mini-batch   271: 1.029\n",
      "Loss after mini-batch   281: 2.526\n",
      "Loss after mini-batch   291: 0.312\n",
      "Loss after mini-batch   301: 0.071\n",
      "Loss after mini-batch   311: 2.116\n",
      "Loss after mini-batch   321: 0.098\n",
      "Loss after mini-batch   331: 0.703\n",
      "Loss after mini-batch   341: 0.462\n",
      "Loss after mini-batch   351: 0.183\n",
      "Loss after mini-batch   361: 0.005\n",
      "Loss after mini-batch   371: 0.319\n",
      "Training Loss: 3.662 \t\t Validation Loss:4.009\n",
      "Starting epoch 149\n",
      "Loss after mini-batch     1: 0.135\n",
      "Loss after mini-batch    11: 0.321\n",
      "Loss after mini-batch    21: 2.362\n",
      "Loss after mini-batch    31: 17.310\n",
      "Loss after mini-batch    41: 0.152\n",
      "Loss after mini-batch    51: 0.767\n",
      "Loss after mini-batch    61: 0.186\n",
      "Loss after mini-batch    71: 1.333\n",
      "Loss after mini-batch    81: 10.414\n",
      "Loss after mini-batch    91: 0.256\n",
      "Loss after mini-batch   101: 1.702\n",
      "Loss after mini-batch   111: 0.175\n",
      "Loss after mini-batch   121: 0.448\n",
      "Loss after mini-batch   131: 0.114\n",
      "Loss after mini-batch   141: 0.053\n",
      "Loss after mini-batch   151: 1.066\n",
      "Loss after mini-batch   161: 2.795\n",
      "Loss after mini-batch   171: 0.165\n",
      "Loss after mini-batch   181: 0.275\n",
      "Loss after mini-batch   191: 0.582\n",
      "Loss after mini-batch   201: 0.320\n",
      "Loss after mini-batch   211: 0.368\n",
      "Loss after mini-batch   221: 0.970\n",
      "Loss after mini-batch   231: 0.070\n",
      "Loss after mini-batch   241: 0.617\n",
      "Loss after mini-batch   251: 17.440\n",
      "Loss after mini-batch   261: 0.609\n",
      "Loss after mini-batch   271: 8.102\n",
      "Loss after mini-batch   281: 2.835\n",
      "Loss after mini-batch   291: 0.456\n",
      "Loss after mini-batch   301: 1.120\n",
      "Loss after mini-batch   311: 6.902\n",
      "Loss after mini-batch   321: 0.213\n",
      "Loss after mini-batch   331: 0.132\n",
      "Loss after mini-batch   341: 0.249\n",
      "Loss after mini-batch   351: 1.325\n",
      "Loss after mini-batch   361: 0.691\n",
      "Loss after mini-batch   371: 3.695\n",
      "Training Loss: 1.120 \t\t Validation Loss:1.537\n",
      "Starting epoch 150\n",
      "Loss after mini-batch     1: 0.635\n",
      "Loss after mini-batch    11: 1.103\n",
      "Loss after mini-batch    21: 0.189\n",
      "Loss after mini-batch    31: 0.923\n",
      "Loss after mini-batch    41: 0.378\n",
      "Loss after mini-batch    51: 0.701\n",
      "Loss after mini-batch    61: 0.410\n",
      "Loss after mini-batch    71: 0.941\n",
      "Loss after mini-batch    81: 1.210\n",
      "Loss after mini-batch    91: 0.615\n",
      "Loss after mini-batch   101: 0.332\n",
      "Loss after mini-batch   111: 0.244\n",
      "Loss after mini-batch   121: 34.353\n",
      "Loss after mini-batch   131: 0.646\n",
      "Loss after mini-batch   141: 3.542\n",
      "Loss after mini-batch   151: 0.761\n",
      "Loss after mini-batch   161: 0.037\n",
      "Loss after mini-batch   171: 0.088\n",
      "Loss after mini-batch   181: 2.540\n",
      "Loss after mini-batch   191: 1.215\n",
      "Loss after mini-batch   201: 0.206\n",
      "Loss after mini-batch   211: 0.070\n",
      "Loss after mini-batch   221: 0.331\n",
      "Loss after mini-batch   231: 0.089\n",
      "Loss after mini-batch   241: 2.318\n",
      "Loss after mini-batch   251: 0.696\n",
      "Loss after mini-batch   261: 0.782\n",
      "Loss after mini-batch   271: 0.067\n",
      "Loss after mini-batch   281: 0.509\n",
      "Loss after mini-batch   291: 0.299\n",
      "Loss after mini-batch   301: 0.104\n",
      "Loss after mini-batch   311: 0.771\n",
      "Loss after mini-batch   321: 0.442\n",
      "Loss after mini-batch   331: 5.870\n",
      "Loss after mini-batch   341: 0.131\n",
      "Loss after mini-batch   351: 3.348\n",
      "Loss after mini-batch   361: 0.938\n",
      "Loss after mini-batch   371: 0.447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 11.329 \t\t Validation Loss:13.795\n",
      "Starting epoch 151\n",
      "Loss after mini-batch     1: 2.548\n",
      "Loss after mini-batch    11: 0.298\n",
      "Loss after mini-batch    21: 0.245\n",
      "Loss after mini-batch    31: 4.834\n",
      "Loss after mini-batch    41: 0.190\n",
      "Loss after mini-batch    51: 1.009\n",
      "Loss after mini-batch    61: 0.685\n",
      "Loss after mini-batch    71: 0.108\n",
      "Loss after mini-batch    81: 0.308\n",
      "Loss after mini-batch    91: 0.497\n",
      "Loss after mini-batch   101: 0.081\n",
      "Loss after mini-batch   111: 7.856\n",
      "Loss after mini-batch   121: 0.670\n",
      "Loss after mini-batch   131: 2.650\n",
      "Loss after mini-batch   141: 0.279\n",
      "Loss after mini-batch   151: 0.412\n",
      "Loss after mini-batch   161: 17.535\n",
      "Loss after mini-batch   171: 0.330\n",
      "Loss after mini-batch   181: 3.435\n",
      "Loss after mini-batch   191: 1.939\n",
      "Loss after mini-batch   201: 0.231\n",
      "Loss after mini-batch   211: 0.400\n",
      "Loss after mini-batch   221: 0.832\n",
      "Loss after mini-batch   231: 0.711\n",
      "Loss after mini-batch   241: 0.905\n",
      "Loss after mini-batch   251: 7.482\n",
      "Loss after mini-batch   261: 1.328\n",
      "Loss after mini-batch   271: 0.576\n",
      "Loss after mini-batch   281: 2.120\n",
      "Loss after mini-batch   291: 0.757\n",
      "Loss after mini-batch   301: 0.217\n",
      "Loss after mini-batch   311: 2.726\n",
      "Loss after mini-batch   321: 0.211\n",
      "Loss after mini-batch   331: 0.116\n",
      "Loss after mini-batch   341: 0.130\n",
      "Loss after mini-batch   351: 0.398\n",
      "Loss after mini-batch   361: 2.349\n",
      "Loss after mini-batch   371: 0.132\n",
      "Training Loss: 2.653 \t\t Validation Loss:2.766\n",
      "Starting epoch 152\n",
      "Loss after mini-batch     1: 2.721\n",
      "Loss after mini-batch    11: 0.228\n",
      "Loss after mini-batch    21: 6.861\n",
      "Loss after mini-batch    31: 0.699\n",
      "Loss after mini-batch    41: 0.298\n",
      "Loss after mini-batch    51: 4.963\n",
      "Loss after mini-batch    61: 0.138\n",
      "Loss after mini-batch    71: 0.403\n",
      "Loss after mini-batch    81: 0.130\n",
      "Loss after mini-batch    91: 0.316\n",
      "Loss after mini-batch   101: 0.041\n",
      "Loss after mini-batch   111: 0.160\n",
      "Loss after mini-batch   121: 1.204\n",
      "Loss after mini-batch   131: 0.282\n",
      "Loss after mini-batch   141: 0.207\n",
      "Loss after mini-batch   151: 3.424\n",
      "Loss after mini-batch   161: 0.229\n",
      "Loss after mini-batch   171: 0.694\n",
      "Loss after mini-batch   181: 0.444\n",
      "Loss after mini-batch   191: 2.000\n",
      "Loss after mini-batch   201: 0.672\n",
      "Loss after mini-batch   211: 5.794\n",
      "Loss after mini-batch   221: 0.113\n",
      "Loss after mini-batch   231: 0.248\n",
      "Loss after mini-batch   241: 0.164\n",
      "Loss after mini-batch   251: 0.609\n",
      "Loss after mini-batch   261: 1.756\n",
      "Loss after mini-batch   271: 0.135\n",
      "Loss after mini-batch   281: 0.085\n",
      "Loss after mini-batch   291: 4.771\n",
      "Loss after mini-batch   301: 0.881\n",
      "Loss after mini-batch   311: 0.222\n",
      "Loss after mini-batch   321: 0.235\n",
      "Loss after mini-batch   331: 0.353\n",
      "Loss after mini-batch   341: 0.143\n",
      "Loss after mini-batch   351: 0.667\n",
      "Loss after mini-batch   361: 0.090\n",
      "Loss after mini-batch   371: 7.726\n",
      "Training Loss: 2.029 \t\t Validation Loss:6.330\n",
      "Starting epoch 153\n",
      "Loss after mini-batch     1: 0.199\n",
      "Loss after mini-batch    11: 1.704\n",
      "Loss after mini-batch    21: 1.284\n",
      "Loss after mini-batch    31: 1.321\n",
      "Loss after mini-batch    41: 0.362\n",
      "Loss after mini-batch    51: 0.371\n",
      "Loss after mini-batch    61: 1.361\n",
      "Loss after mini-batch    71: 0.900\n",
      "Loss after mini-batch    81: 0.201\n",
      "Loss after mini-batch    91: 0.341\n",
      "Loss after mini-batch   101: 0.618\n",
      "Loss after mini-batch   111: 4.597\n",
      "Loss after mini-batch   121: 2.724\n",
      "Loss after mini-batch   131: 15.657\n",
      "Loss after mini-batch   141: 2.533\n",
      "Loss after mini-batch   151: 3.282\n",
      "Loss after mini-batch   161: 18.734\n",
      "Loss after mini-batch   171: 0.017\n",
      "Loss after mini-batch   181: 0.665\n",
      "Loss after mini-batch   191: 0.867\n",
      "Loss after mini-batch   201: 2.569\n",
      "Loss after mini-batch   211: 7.202\n",
      "Loss after mini-batch   221: 0.140\n",
      "Loss after mini-batch   231: 0.763\n",
      "Loss after mini-batch   241: 2.734\n",
      "Loss after mini-batch   251: 0.171\n",
      "Loss after mini-batch   261: 0.032\n",
      "Loss after mini-batch   271: 0.242\n",
      "Loss after mini-batch   281: 0.187\n",
      "Loss after mini-batch   291: 0.020\n",
      "Loss after mini-batch   301: 0.490\n",
      "Loss after mini-batch   311: 0.235\n",
      "Loss after mini-batch   321: 40.381\n",
      "Loss after mini-batch   331: 1.205\n",
      "Loss after mini-batch   341: 3.468\n",
      "Loss after mini-batch   351: 0.213\n",
      "Loss after mini-batch   361: 0.429\n",
      "Loss after mini-batch   371: 0.058\n",
      "Training Loss: 2.316 \t\t Validation Loss:4.055\n",
      "Starting epoch 154\n",
      "Loss after mini-batch     1: 0.437\n",
      "Loss after mini-batch    11: 0.245\n",
      "Loss after mini-batch    21: 0.412\n",
      "Loss after mini-batch    31: 2.390\n",
      "Loss after mini-batch    41: 1.088\n",
      "Loss after mini-batch    51: 0.417\n",
      "Loss after mini-batch    61: 1.687\n",
      "Loss after mini-batch    71: 0.350\n",
      "Loss after mini-batch    81: 0.101\n",
      "Loss after mini-batch    91: 3.134\n",
      "Loss after mini-batch   101: 0.204\n",
      "Loss after mini-batch   111: 1.191\n",
      "Loss after mini-batch   121: 1.529\n",
      "Loss after mini-batch   131: 0.788\n",
      "Loss after mini-batch   141: 3.796\n",
      "Loss after mini-batch   151: 0.120\n",
      "Loss after mini-batch   161: 1.382\n",
      "Loss after mini-batch   171: 2.512\n",
      "Loss after mini-batch   181: 0.249\n",
      "Loss after mini-batch   191: 0.072\n",
      "Loss after mini-batch   201: 0.364\n",
      "Loss after mini-batch   211: 2.538\n",
      "Loss after mini-batch   221: 1.183\n",
      "Loss after mini-batch   231: 1.546\n",
      "Loss after mini-batch   241: 0.056\n",
      "Loss after mini-batch   251: 0.158\n",
      "Loss after mini-batch   261: 7.623\n",
      "Loss after mini-batch   271: 8.354\n",
      "Loss after mini-batch   281: 0.988\n",
      "Loss after mini-batch   291: 0.051\n",
      "Loss after mini-batch   301: 5.809\n",
      "Loss after mini-batch   311: 0.135\n",
      "Loss after mini-batch   321: 0.116\n",
      "Loss after mini-batch   331: 0.172\n",
      "Loss after mini-batch   341: 0.239\n",
      "Loss after mini-batch   351: 0.431\n",
      "Loss after mini-batch   361: 0.374\n",
      "Loss after mini-batch   371: 0.254\n",
      "Training Loss: 0.181 \t\t Validation Loss:0.501\n",
      "Starting epoch 155\n",
      "Loss after mini-batch     1: 0.069\n",
      "Loss after mini-batch    11: 1.460\n",
      "Loss after mini-batch    21: 0.467\n",
      "Loss after mini-batch    31: 9.548\n",
      "Loss after mini-batch    41: 0.052\n",
      "Loss after mini-batch    51: 0.196\n",
      "Loss after mini-batch    61: 0.040\n",
      "Loss after mini-batch    71: 5.001\n",
      "Loss after mini-batch    81: 0.274\n",
      "Loss after mini-batch    91: 1.855\n",
      "Loss after mini-batch   101: 0.794\n",
      "Loss after mini-batch   111: 0.839\n",
      "Loss after mini-batch   121: 0.278\n",
      "Loss after mini-batch   131: 2.254\n",
      "Loss after mini-batch   141: 0.303\n",
      "Loss after mini-batch   151: 0.112\n",
      "Loss after mini-batch   161: 0.970\n",
      "Loss after mini-batch   171: 0.404\n",
      "Loss after mini-batch   181: 2.990\n",
      "Loss after mini-batch   191: 7.305\n",
      "Loss after mini-batch   201: 1.319\n",
      "Loss after mini-batch   211: 1.684\n",
      "Loss after mini-batch   221: 0.022\n",
      "Loss after mini-batch   231: 0.731\n",
      "Loss after mini-batch   241: 0.601\n",
      "Loss after mini-batch   251: 2.280\n",
      "Loss after mini-batch   261: 2.207\n",
      "Loss after mini-batch   271: 0.199\n",
      "Loss after mini-batch   281: 0.201\n",
      "Loss after mini-batch   291: 0.057\n",
      "Loss after mini-batch   301: 0.725\n",
      "Loss after mini-batch   311: 1.299\n",
      "Loss after mini-batch   321: 0.548\n",
      "Loss after mini-batch   331: 2.053\n",
      "Loss after mini-batch   341: 0.547\n",
      "Loss after mini-batch   351: 0.995\n",
      "Loss after mini-batch   361: 1.250\n",
      "Loss after mini-batch   371: 0.126\n",
      "Training Loss: 0.765 \t\t Validation Loss:1.955\n",
      "Starting epoch 156\n",
      "Loss after mini-batch     1: 26.693\n",
      "Loss after mini-batch    11: 0.169\n",
      "Loss after mini-batch    21: 0.325\n",
      "Loss after mini-batch    31: 0.503\n",
      "Loss after mini-batch    41: 0.103\n",
      "Loss after mini-batch    51: 5.926\n",
      "Loss after mini-batch    61: 0.842\n",
      "Loss after mini-batch    71: 1.465\n",
      "Loss after mini-batch    81: 0.087\n",
      "Loss after mini-batch    91: 0.671\n",
      "Loss after mini-batch   101: 0.468\n",
      "Loss after mini-batch   111: 1.593\n",
      "Loss after mini-batch   121: 0.161\n",
      "Loss after mini-batch   131: 0.800\n",
      "Loss after mini-batch   141: 1.670\n",
      "Loss after mini-batch   151: 1.266\n",
      "Loss after mini-batch   161: 0.560\n",
      "Loss after mini-batch   171: 9.215\n",
      "Loss after mini-batch   181: 1.574\n",
      "Loss after mini-batch   191: 5.262\n",
      "Loss after mini-batch   201: 2.706\n",
      "Loss after mini-batch   211: 0.619\n",
      "Loss after mini-batch   221: 6.731\n",
      "Loss after mini-batch   231: 1.449\n",
      "Loss after mini-batch   241: 0.608\n",
      "Loss after mini-batch   251: 0.316\n",
      "Loss after mini-batch   261: 0.477\n",
      "Loss after mini-batch   271: 0.313\n",
      "Loss after mini-batch   281: 0.461\n",
      "Loss after mini-batch   291: 0.236\n",
      "Loss after mini-batch   301: 0.337\n",
      "Loss after mini-batch   311: 0.122\n",
      "Loss after mini-batch   321: 1.823\n",
      "Loss after mini-batch   331: 2.003\n",
      "Loss after mini-batch   341: 0.086\n",
      "Loss after mini-batch   351: 3.160\n",
      "Loss after mini-batch   361: 4.134\n",
      "Loss after mini-batch   371: 7.115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.948 \t\t Validation Loss:9.008\n",
      "Starting epoch 157\n",
      "Loss after mini-batch     1: 1.101\n",
      "Loss after mini-batch    11: 1.215\n",
      "Loss after mini-batch    21: 0.451\n",
      "Loss after mini-batch    31: 0.465\n",
      "Loss after mini-batch    41: 0.065\n",
      "Loss after mini-batch    51: 0.773\n",
      "Loss after mini-batch    61: 0.058\n",
      "Loss after mini-batch    71: 0.177\n",
      "Loss after mini-batch    81: 0.076\n",
      "Loss after mini-batch    91: 0.087\n",
      "Loss after mini-batch   101: 1.549\n",
      "Loss after mini-batch   111: 1.108\n",
      "Loss after mini-batch   121: 0.094\n",
      "Loss after mini-batch   131: 0.076\n",
      "Loss after mini-batch   141: 0.179\n",
      "Loss after mini-batch   151: 0.345\n",
      "Loss after mini-batch   161: 0.632\n",
      "Loss after mini-batch   171: 3.353\n",
      "Loss after mini-batch   181: 0.265\n",
      "Loss after mini-batch   191: 1.172\n",
      "Loss after mini-batch   201: 0.815\n",
      "Loss after mini-batch   211: 2.502\n",
      "Loss after mini-batch   221: 3.919\n",
      "Loss after mini-batch   231: 0.795\n",
      "Loss after mini-batch   241: 2.207\n",
      "Loss after mini-batch   251: 0.164\n",
      "Loss after mini-batch   261: 2.796\n",
      "Loss after mini-batch   271: 2.938\n",
      "Loss after mini-batch   281: 0.943\n",
      "Loss after mini-batch   291: 0.044\n",
      "Loss after mini-batch   301: 0.058\n",
      "Loss after mini-batch   311: 0.179\n",
      "Loss after mini-batch   321: 11.675\n",
      "Loss after mini-batch   331: 0.139\n",
      "Loss after mini-batch   341: 1.899\n",
      "Loss after mini-batch   351: 1.625\n",
      "Loss after mini-batch   361: 0.646\n",
      "Loss after mini-batch   371: 8.332\n",
      "Training Loss: 0.590 \t\t Validation Loss:0.693\n",
      "Starting epoch 158\n",
      "Loss after mini-batch     1: 0.263\n",
      "Loss after mini-batch    11: 0.180\n",
      "Loss after mini-batch    21: 1.011\n",
      "Loss after mini-batch    31: 0.270\n",
      "Loss after mini-batch    41: 2.486\n",
      "Loss after mini-batch    51: 0.008\n",
      "Loss after mini-batch    61: 1.035\n",
      "Loss after mini-batch    71: 0.257\n",
      "Loss after mini-batch    81: 0.794\n",
      "Loss after mini-batch    91: 0.111\n",
      "Loss after mini-batch   101: 0.038\n",
      "Loss after mini-batch   111: 0.673\n",
      "Loss after mini-batch   121: 2.245\n",
      "Loss after mini-batch   131: 0.873\n",
      "Loss after mini-batch   141: 0.254\n",
      "Loss after mini-batch   151: 0.197\n",
      "Loss after mini-batch   161: 0.783\n",
      "Loss after mini-batch   171: 0.208\n",
      "Loss after mini-batch   181: 0.120\n",
      "Loss after mini-batch   191: 0.073\n",
      "Loss after mini-batch   201: 3.005\n",
      "Loss after mini-batch   211: 0.110\n",
      "Loss after mini-batch   221: 0.128\n",
      "Loss after mini-batch   231: 0.643\n",
      "Loss after mini-batch   241: 1.739\n",
      "Loss after mini-batch   251: 0.279\n",
      "Loss after mini-batch   261: 0.539\n",
      "Loss after mini-batch   271: 5.649\n",
      "Loss after mini-batch   281: 8.092\n",
      "Loss after mini-batch   291: 0.300\n",
      "Loss after mini-batch   301: 2.640\n",
      "Loss after mini-batch   311: 1.072\n",
      "Loss after mini-batch   321: 2.974\n",
      "Loss after mini-batch   331: 20.730\n",
      "Loss after mini-batch   341: 0.390\n",
      "Loss after mini-batch   351: 0.791\n",
      "Loss after mini-batch   361: 4.260\n",
      "Loss after mini-batch   371: 0.777\n",
      "Training Loss: 0.032 \t\t Validation Loss:0.849\n",
      "Starting epoch 159\n",
      "Loss after mini-batch     1: 0.065\n",
      "Loss after mini-batch    11: 0.289\n",
      "Loss after mini-batch    21: 7.224\n",
      "Loss after mini-batch    31: 0.117\n",
      "Loss after mini-batch    41: 1.263\n",
      "Loss after mini-batch    51: 0.117\n",
      "Loss after mini-batch    61: 0.588\n",
      "Loss after mini-batch    71: 0.288\n",
      "Loss after mini-batch    81: 3.664\n",
      "Loss after mini-batch    91: 0.404\n",
      "Loss after mini-batch   101: 9.753\n",
      "Loss after mini-batch   111: 0.579\n",
      "Loss after mini-batch   121: 0.950\n",
      "Loss after mini-batch   131: 0.247\n",
      "Loss after mini-batch   141: 0.929\n",
      "Loss after mini-batch   151: 2.684\n",
      "Loss after mini-batch   161: 1.410\n",
      "Loss after mini-batch   171: 0.333\n",
      "Loss after mini-batch   181: 1.176\n",
      "Loss after mini-batch   191: 1.785\n",
      "Loss after mini-batch   201: 1.707\n",
      "Loss after mini-batch   211: 0.361\n",
      "Loss after mini-batch   221: 1.411\n",
      "Loss after mini-batch   231: 0.066\n",
      "Loss after mini-batch   241: 0.014\n",
      "Loss after mini-batch   251: 8.125\n",
      "Loss after mini-batch   261: 1.171\n",
      "Loss after mini-batch   271: 0.088\n",
      "Loss after mini-batch   281: 0.809\n",
      "Loss after mini-batch   291: 0.557\n",
      "Loss after mini-batch   301: 1.236\n",
      "Loss after mini-batch   311: 0.426\n",
      "Loss after mini-batch   321: 0.312\n",
      "Loss after mini-batch   331: 1.035\n",
      "Loss after mini-batch   341: 2.142\n",
      "Loss after mini-batch   351: 0.812\n",
      "Loss after mini-batch   361: 2.441\n",
      "Loss after mini-batch   371: 0.994\n",
      "Training Loss: 0.598 \t\t Validation Loss:0.685\n",
      "Starting epoch 160\n",
      "Loss after mini-batch     1: 0.004\n",
      "Loss after mini-batch    11: 0.362\n",
      "Loss after mini-batch    21: 0.383\n",
      "Loss after mini-batch    31: 0.044\n",
      "Loss after mini-batch    41: 0.692\n",
      "Loss after mini-batch    51: 0.028\n",
      "Loss after mini-batch    61: 0.799\n",
      "Loss after mini-batch    71: 2.546\n",
      "Loss after mini-batch    81: 7.080\n",
      "Loss after mini-batch    91: 2.456\n",
      "Loss after mini-batch   101: 0.798\n",
      "Loss after mini-batch   111: 0.434\n",
      "Loss after mini-batch   121: 3.571\n",
      "Loss after mini-batch   131: 0.907\n",
      "Loss after mini-batch   141: 2.302\n",
      "Loss after mini-batch   151: 0.205\n",
      "Loss after mini-batch   161: 5.913\n",
      "Loss after mini-batch   171: 1.634\n",
      "Loss after mini-batch   181: 4.743\n",
      "Loss after mini-batch   191: 0.607\n",
      "Loss after mini-batch   201: 1.774\n",
      "Loss after mini-batch   211: 2.644\n",
      "Loss after mini-batch   221: 0.776\n",
      "Loss after mini-batch   231: 0.898\n",
      "Loss after mini-batch   241: 1.728\n",
      "Loss after mini-batch   251: 0.236\n",
      "Loss after mini-batch   261: 0.025\n",
      "Loss after mini-batch   271: 0.645\n",
      "Loss after mini-batch   281: 0.345\n",
      "Loss after mini-batch   291: 5.941\n",
      "Loss after mini-batch   301: 0.062\n",
      "Loss after mini-batch   311: 2.691\n",
      "Loss after mini-batch   321: 0.117\n",
      "Loss after mini-batch   331: 1.318\n",
      "Loss after mini-batch   341: 0.810\n",
      "Loss after mini-batch   351: 0.173\n",
      "Loss after mini-batch   361: 0.545\n",
      "Loss after mini-batch   371: 1.166\n",
      "Training Loss: 3.365 \t\t Validation Loss:3.928\n",
      "Starting epoch 161\n",
      "Loss after mini-batch     1: 0.430\n",
      "Loss after mini-batch    11: 1.989\n",
      "Loss after mini-batch    21: 0.863\n",
      "Loss after mini-batch    31: 0.548\n",
      "Loss after mini-batch    41: 3.535\n",
      "Loss after mini-batch    51: 0.092\n",
      "Loss after mini-batch    61: 0.123\n",
      "Loss after mini-batch    71: 1.578\n",
      "Loss after mini-batch    81: 0.538\n",
      "Loss after mini-batch    91: 0.168\n",
      "Loss after mini-batch   101: 0.030\n",
      "Loss after mini-batch   111: 0.111\n",
      "Loss after mini-batch   121: 5.858\n",
      "Loss after mini-batch   131: 0.160\n",
      "Loss after mini-batch   141: 0.399\n",
      "Loss after mini-batch   151: 0.408\n",
      "Loss after mini-batch   161: 7.382\n",
      "Loss after mini-batch   171: 1.681\n",
      "Loss after mini-batch   181: 1.095\n",
      "Loss after mini-batch   191: 32.326\n",
      "Loss after mini-batch   201: 0.750\n",
      "Loss after mini-batch   211: 1.682\n",
      "Loss after mini-batch   221: 3.265\n",
      "Loss after mini-batch   231: 1.075\n",
      "Loss after mini-batch   241: 0.983\n",
      "Loss after mini-batch   251: 0.117\n",
      "Loss after mini-batch   261: 0.508\n",
      "Loss after mini-batch   271: 0.542\n",
      "Loss after mini-batch   281: 0.316\n",
      "Loss after mini-batch   291: 0.114\n",
      "Loss after mini-batch   301: 0.114\n",
      "Loss after mini-batch   311: 1.118\n",
      "Loss after mini-batch   321: 1.292\n",
      "Loss after mini-batch   331: 0.149\n",
      "Loss after mini-batch   341: 4.329\n",
      "Loss after mini-batch   351: 2.969\n",
      "Loss after mini-batch   361: 3.999\n",
      "Loss after mini-batch   371: 0.036\n",
      "Training Loss: 0.538 \t\t Validation Loss:2.529\n",
      "Starting epoch 162\n",
      "Loss after mini-batch     1: 0.203\n",
      "Loss after mini-batch    11: 0.390\n",
      "Loss after mini-batch    21: 1.280\n",
      "Loss after mini-batch    31: 0.184\n",
      "Loss after mini-batch    41: 0.413\n",
      "Loss after mini-batch    51: 0.586\n",
      "Loss after mini-batch    61: 0.155\n",
      "Loss after mini-batch    71: 5.841\n",
      "Loss after mini-batch    81: 1.070\n",
      "Loss after mini-batch    91: 9.947\n",
      "Loss after mini-batch   101: 0.189\n",
      "Loss after mini-batch   111: 0.575\n",
      "Loss after mini-batch   121: 0.784\n",
      "Loss after mini-batch   131: 0.284\n",
      "Loss after mini-batch   141: 0.144\n",
      "Loss after mini-batch   151: 5.752\n",
      "Loss after mini-batch   161: 1.019\n",
      "Loss after mini-batch   171: 2.210\n",
      "Loss after mini-batch   181: 0.243\n",
      "Loss after mini-batch   191: 2.983\n",
      "Loss after mini-batch   201: 1.807\n",
      "Loss after mini-batch   211: 1.433\n",
      "Loss after mini-batch   221: 6.445\n",
      "Loss after mini-batch   231: 1.757\n",
      "Loss after mini-batch   241: 1.641\n",
      "Loss after mini-batch   251: 0.150\n",
      "Loss after mini-batch   261: 0.791\n",
      "Loss after mini-batch   271: 0.341\n",
      "Loss after mini-batch   281: 0.132\n",
      "Loss after mini-batch   291: 4.789\n",
      "Loss after mini-batch   301: 4.819\n",
      "Loss after mini-batch   311: 0.211\n",
      "Loss after mini-batch   321: 0.846\n",
      "Loss after mini-batch   331: 8.155\n",
      "Loss after mini-batch   341: 0.669\n",
      "Loss after mini-batch   351: 1.512\n",
      "Loss after mini-batch   361: 5.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   371: 7.612\n",
      "Training Loss: 2.961 \t\t Validation Loss:3.287\n",
      "Starting epoch 163\n",
      "Loss after mini-batch     1: 0.310\n",
      "Loss after mini-batch    11: 1.547\n",
      "Loss after mini-batch    21: 0.908\n",
      "Loss after mini-batch    31: 0.937\n",
      "Loss after mini-batch    41: 0.488\n",
      "Loss after mini-batch    51: 1.202\n",
      "Loss after mini-batch    61: 0.150\n",
      "Loss after mini-batch    71: 0.148\n",
      "Loss after mini-batch    81: 1.740\n",
      "Loss after mini-batch    91: 0.551\n",
      "Loss after mini-batch   101: 0.337\n",
      "Loss after mini-batch   111: 1.089\n",
      "Loss after mini-batch   121: 0.203\n",
      "Loss after mini-batch   131: 3.774\n",
      "Loss after mini-batch   141: 1.276\n",
      "Loss after mini-batch   151: 3.454\n",
      "Loss after mini-batch   161: 0.221\n",
      "Loss after mini-batch   171: 0.641\n",
      "Loss after mini-batch   181: 1.814\n",
      "Loss after mini-batch   191: 0.418\n",
      "Loss after mini-batch   201: 0.671\n",
      "Loss after mini-batch   211: 0.094\n",
      "Loss after mini-batch   221: 3.452\n",
      "Loss after mini-batch   231: 3.075\n",
      "Loss after mini-batch   241: 0.508\n",
      "Loss after mini-batch   251: 0.065\n",
      "Loss after mini-batch   261: 0.133\n",
      "Loss after mini-batch   271: 0.685\n",
      "Loss after mini-batch   281: 3.279\n",
      "Loss after mini-batch   291: 0.247\n",
      "Loss after mini-batch   301: 7.354\n",
      "Loss after mini-batch   311: 2.435\n",
      "Loss after mini-batch   321: 5.656\n",
      "Loss after mini-batch   331: 0.028\n",
      "Loss after mini-batch   341: 1.236\n",
      "Loss after mini-batch   351: 6.601\n",
      "Loss after mini-batch   361: 0.372\n",
      "Loss after mini-batch   371: 0.715\n",
      "Training Loss: 0.017 \t\t Validation Loss:1.300\n",
      "Starting epoch 164\n",
      "Loss after mini-batch     1: 0.033\n",
      "Loss after mini-batch    11: 0.348\n",
      "Loss after mini-batch    21: 3.453\n",
      "Loss after mini-batch    31: 2.143\n",
      "Loss after mini-batch    41: 12.049\n",
      "Loss after mini-batch    51: 0.620\n",
      "Loss after mini-batch    61: 0.683\n",
      "Loss after mini-batch    71: 0.116\n",
      "Loss after mini-batch    81: 0.244\n",
      "Loss after mini-batch    91: 1.280\n",
      "Loss after mini-batch   101: 9.235\n",
      "Loss after mini-batch   111: 1.227\n",
      "Loss after mini-batch   121: 0.495\n",
      "Loss after mini-batch   131: 4.462\n",
      "Loss after mini-batch   141: 2.486\n",
      "Loss after mini-batch   151: 0.282\n",
      "Loss after mini-batch   161: 0.634\n",
      "Loss after mini-batch   171: 3.502\n",
      "Loss after mini-batch   181: 0.078\n",
      "Loss after mini-batch   191: 0.211\n",
      "Loss after mini-batch   201: 7.269\n",
      "Loss after mini-batch   211: 6.839\n",
      "Loss after mini-batch   221: 0.966\n",
      "Loss after mini-batch   231: 0.333\n",
      "Loss after mini-batch   241: 2.495\n",
      "Loss after mini-batch   251: 0.206\n",
      "Loss after mini-batch   261: 1.472\n",
      "Loss after mini-batch   271: 0.141\n",
      "Loss after mini-batch   281: 5.305\n",
      "Loss after mini-batch   291: 0.894\n",
      "Loss after mini-batch   301: 0.527\n",
      "Loss after mini-batch   311: 7.674\n",
      "Loss after mini-batch   321: 0.100\n",
      "Loss after mini-batch   331: 0.670\n",
      "Loss after mini-batch   341: 1.065\n",
      "Loss after mini-batch   351: 5.668\n",
      "Loss after mini-batch   361: 0.989\n",
      "Loss after mini-batch   371: 0.047\n",
      "Training Loss: 6.996 \t\t Validation Loss:7.544\n",
      "Starting epoch 165\n",
      "Loss after mini-batch     1: 0.176\n",
      "Loss after mini-batch    11: 5.091\n",
      "Loss after mini-batch    21: 0.901\n",
      "Loss after mini-batch    31: 1.902\n",
      "Loss after mini-batch    41: 2.281\n",
      "Loss after mini-batch    51: 0.447\n",
      "Loss after mini-batch    61: 0.949\n",
      "Loss after mini-batch    71: 2.280\n",
      "Loss after mini-batch    81: 0.328\n",
      "Loss after mini-batch    91: 11.031\n",
      "Loss after mini-batch   101: 0.127\n",
      "Loss after mini-batch   111: 0.820\n",
      "Loss after mini-batch   121: 8.129\n",
      "Loss after mini-batch   131: 0.288\n",
      "Loss after mini-batch   141: 0.192\n",
      "Loss after mini-batch   151: 1.728\n",
      "Loss after mini-batch   161: 1.364\n",
      "Loss after mini-batch   171: 4.144\n",
      "Loss after mini-batch   181: 0.090\n",
      "Loss after mini-batch   191: 0.401\n",
      "Loss after mini-batch   201: 0.095\n",
      "Loss after mini-batch   211: 3.803\n",
      "Loss after mini-batch   221: 0.463\n",
      "Loss after mini-batch   231: 7.856\n",
      "Loss after mini-batch   241: 0.675\n",
      "Loss after mini-batch   251: 0.887\n",
      "Loss after mini-batch   261: 0.092\n",
      "Loss after mini-batch   271: 1.839\n",
      "Loss after mini-batch   281: 5.839\n",
      "Loss after mini-batch   291: 0.584\n",
      "Loss after mini-batch   301: 0.085\n",
      "Loss after mini-batch   311: 0.114\n",
      "Loss after mini-batch   321: 1.869\n",
      "Loss after mini-batch   331: 0.116\n",
      "Loss after mini-batch   341: 0.069\n",
      "Loss after mini-batch   351: 4.718\n",
      "Loss after mini-batch   361: 1.588\n",
      "Loss after mini-batch   371: 0.180\n",
      "Training Loss: 0.603 \t\t Validation Loss:3.097\n",
      "Starting epoch 166\n",
      "Loss after mini-batch     1: 0.411\n",
      "Loss after mini-batch    11: 9.412\n",
      "Loss after mini-batch    21: 16.343\n",
      "Loss after mini-batch    31: 0.640\n",
      "Loss after mini-batch    41: 0.323\n",
      "Loss after mini-batch    51: 2.160\n",
      "Loss after mini-batch    61: 1.251\n",
      "Loss after mini-batch    71: 2.627\n",
      "Loss after mini-batch    81: 0.049\n",
      "Loss after mini-batch    91: 1.076\n",
      "Loss after mini-batch   101: 0.970\n",
      "Loss after mini-batch   111: 2.035\n",
      "Loss after mini-batch   121: 0.043\n",
      "Loss after mini-batch   131: 1.028\n",
      "Loss after mini-batch   141: 1.364\n",
      "Loss after mini-batch   151: 5.840\n",
      "Loss after mini-batch   161: 0.133\n",
      "Loss after mini-batch   171: 0.779\n",
      "Loss after mini-batch   181: 3.092\n",
      "Loss after mini-batch   191: 0.913\n",
      "Loss after mini-batch   201: 0.699\n",
      "Loss after mini-batch   211: 2.009\n",
      "Loss after mini-batch   221: 0.093\n",
      "Loss after mini-batch   231: 1.014\n",
      "Loss after mini-batch   241: 0.042\n",
      "Loss after mini-batch   251: 1.018\n",
      "Loss after mini-batch   261: 0.946\n",
      "Loss after mini-batch   271: 0.070\n",
      "Loss after mini-batch   281: 0.370\n",
      "Loss after mini-batch   291: 0.434\n",
      "Loss after mini-batch   301: 0.153\n",
      "Loss after mini-batch   311: 1.184\n",
      "Loss after mini-batch   321: 8.573\n",
      "Loss after mini-batch   331: 0.592\n",
      "Loss after mini-batch   341: 0.126\n",
      "Loss after mini-batch   351: 2.227\n",
      "Loss after mini-batch   361: 1.754\n",
      "Loss after mini-batch   371: 7.168\n",
      "Training Loss: 0.528 \t\t Validation Loss:4.189\n",
      "Starting epoch 167\n",
      "Loss after mini-batch     1: 5.846\n",
      "Loss after mini-batch    11: 0.207\n",
      "Loss after mini-batch    21: 1.845\n",
      "Loss after mini-batch    31: 0.017\n",
      "Loss after mini-batch    41: 0.043\n",
      "Loss after mini-batch    51: 0.329\n",
      "Loss after mini-batch    61: 1.155\n",
      "Loss after mini-batch    71: 0.572\n",
      "Loss after mini-batch    81: 4.509\n",
      "Loss after mini-batch    91: 8.080\n",
      "Loss after mini-batch   101: 0.950\n",
      "Loss after mini-batch   111: 1.504\n",
      "Loss after mini-batch   121: 0.112\n",
      "Loss after mini-batch   131: 0.282\n",
      "Loss after mini-batch   141: 0.774\n",
      "Loss after mini-batch   151: 1.830\n",
      "Loss after mini-batch   161: 1.348\n",
      "Loss after mini-batch   171: 3.521\n",
      "Loss after mini-batch   181: 6.374\n",
      "Loss after mini-batch   191: 1.770\n",
      "Loss after mini-batch   201: 1.751\n",
      "Loss after mini-batch   211: 1.743\n",
      "Loss after mini-batch   221: 3.124\n",
      "Loss after mini-batch   231: 0.423\n",
      "Loss after mini-batch   241: 0.184\n",
      "Loss after mini-batch   251: 2.481\n",
      "Loss after mini-batch   261: 0.875\n",
      "Loss after mini-batch   271: 2.220\n",
      "Loss after mini-batch   281: 1.517\n",
      "Loss after mini-batch   291: 1.621\n",
      "Loss after mini-batch   301: 0.156\n",
      "Loss after mini-batch   311: 0.121\n",
      "Loss after mini-batch   321: 5.709\n",
      "Loss after mini-batch   331: 0.032\n",
      "Loss after mini-batch   341: 0.637\n",
      "Loss after mini-batch   351: 2.534\n",
      "Loss after mini-batch   361: 0.284\n",
      "Loss after mini-batch   371: 15.740\n",
      "Training Loss: 0.148 \t\t Validation Loss:0.475\n",
      "Starting epoch 168\n",
      "Loss after mini-batch     1: 5.786\n",
      "Loss after mini-batch    11: 7.236\n",
      "Loss after mini-batch    21: 2.992\n",
      "Loss after mini-batch    31: 0.404\n",
      "Loss after mini-batch    41: 1.780\n",
      "Loss after mini-batch    51: 0.130\n",
      "Loss after mini-batch    61: 2.005\n",
      "Loss after mini-batch    71: 0.058\n",
      "Loss after mini-batch    81: 1.211\n",
      "Loss after mini-batch    91: 0.733\n",
      "Loss after mini-batch   101: 0.726\n",
      "Loss after mini-batch   111: 0.335\n",
      "Loss after mini-batch   121: 1.168\n",
      "Loss after mini-batch   131: 0.060\n",
      "Loss after mini-batch   141: 0.146\n",
      "Loss after mini-batch   151: 0.433\n",
      "Loss after mini-batch   161: 0.334\n",
      "Loss after mini-batch   171: 0.104\n",
      "Loss after mini-batch   181: 0.071\n",
      "Loss after mini-batch   191: 0.026\n",
      "Loss after mini-batch   201: 0.083\n",
      "Loss after mini-batch   211: 0.519\n",
      "Loss after mini-batch   221: 10.512\n",
      "Loss after mini-batch   231: 2.732\n",
      "Loss after mini-batch   241: 1.997\n",
      "Loss after mini-batch   251: 0.367\n",
      "Loss after mini-batch   261: 0.640\n",
      "Loss after mini-batch   271: 0.409\n",
      "Loss after mini-batch   281: 0.545\n",
      "Loss after mini-batch   291: 1.356\n",
      "Loss after mini-batch   301: 0.042\n",
      "Loss after mini-batch   311: 1.966\n",
      "Loss after mini-batch   321: 0.077\n",
      "Loss after mini-batch   331: 0.088\n",
      "Loss after mini-batch   341: 5.917\n",
      "Loss after mini-batch   351: 2.137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   361: 0.687\n",
      "Loss after mini-batch   371: 1.283\n",
      "Training Loss: 0.436 \t\t Validation Loss:1.200\n",
      "Starting epoch 169\n",
      "Loss after mini-batch     1: 0.246\n",
      "Loss after mini-batch    11: 4.947\n",
      "Loss after mini-batch    21: 0.514\n",
      "Loss after mini-batch    31: 0.035\n",
      "Loss after mini-batch    41: 1.137\n",
      "Loss after mini-batch    51: 0.131\n",
      "Loss after mini-batch    61: 0.161\n",
      "Loss after mini-batch    71: 0.673\n",
      "Loss after mini-batch    81: 0.137\n",
      "Loss after mini-batch    91: 0.310\n",
      "Loss after mini-batch   101: 0.207\n",
      "Loss after mini-batch   111: 1.401\n",
      "Loss after mini-batch   121: 0.852\n",
      "Loss after mini-batch   131: 0.474\n",
      "Loss after mini-batch   141: 0.125\n",
      "Loss after mini-batch   151: 1.945\n",
      "Loss after mini-batch   161: 7.796\n",
      "Loss after mini-batch   171: 4.254\n",
      "Loss after mini-batch   181: 0.359\n",
      "Loss after mini-batch   191: 0.176\n",
      "Loss after mini-batch   201: 0.469\n",
      "Loss after mini-batch   211: 3.118\n",
      "Loss after mini-batch   221: 4.167\n",
      "Loss after mini-batch   231: 0.296\n",
      "Loss after mini-batch   241: 0.400\n",
      "Loss after mini-batch   251: 0.556\n",
      "Loss after mini-batch   261: 0.252\n",
      "Loss after mini-batch   271: 10.737\n",
      "Loss after mini-batch   281: 1.058\n",
      "Loss after mini-batch   291: 0.588\n",
      "Loss after mini-batch   301: 2.628\n",
      "Loss after mini-batch   311: 2.294\n",
      "Loss after mini-batch   321: 0.056\n",
      "Loss after mini-batch   331: 0.240\n",
      "Loss after mini-batch   341: 0.575\n",
      "Loss after mini-batch   351: 0.276\n",
      "Loss after mini-batch   361: 0.123\n",
      "Loss after mini-batch   371: 1.443\n",
      "Training Loss: 2.424 \t\t Validation Loss:5.577\n",
      "Starting epoch 170\n",
      "Loss after mini-batch     1: 0.134\n",
      "Loss after mini-batch    11: 0.362\n",
      "Loss after mini-batch    21: 1.728\n",
      "Loss after mini-batch    31: 0.199\n",
      "Loss after mini-batch    41: 0.287\n",
      "Loss after mini-batch    51: 0.491\n",
      "Loss after mini-batch    61: 0.240\n",
      "Loss after mini-batch    71: 1.306\n",
      "Loss after mini-batch    81: 0.244\n",
      "Loss after mini-batch    91: 1.495\n",
      "Loss after mini-batch   101: 1.401\n",
      "Loss after mini-batch   111: 0.231\n",
      "Loss after mini-batch   121: 2.505\n",
      "Loss after mini-batch   131: 0.568\n",
      "Loss after mini-batch   141: 1.084\n",
      "Loss after mini-batch   151: 1.064\n",
      "Loss after mini-batch   161: 0.885\n",
      "Loss after mini-batch   171: 5.239\n",
      "Loss after mini-batch   181: 1.272\n",
      "Loss after mini-batch   191: 0.018\n",
      "Loss after mini-batch   201: 1.137\n",
      "Loss after mini-batch   211: 2.457\n",
      "Loss after mini-batch   221: 2.988\n",
      "Loss after mini-batch   231: 4.284\n",
      "Loss after mini-batch   241: 0.994\n",
      "Loss after mini-batch   251: 6.166\n",
      "Loss after mini-batch   261: 0.016\n",
      "Loss after mini-batch   271: 1.768\n",
      "Loss after mini-batch   281: 0.756\n",
      "Loss after mini-batch   291: 0.883\n",
      "Loss after mini-batch   301: 1.906\n",
      "Loss after mini-batch   311: 0.706\n",
      "Loss after mini-batch   321: 1.453\n",
      "Loss after mini-batch   331: 0.843\n",
      "Loss after mini-batch   341: 0.057\n",
      "Loss after mini-batch   351: 0.582\n",
      "Loss after mini-batch   361: 1.703\n",
      "Loss after mini-batch   371: 0.275\n",
      "Training Loss: 0.142 \t\t Validation Loss:0.393\n",
      "Starting epoch 171\n",
      "Loss after mini-batch     1: 3.354\n",
      "Loss after mini-batch    11: 1.146\n",
      "Loss after mini-batch    21: 17.799\n",
      "Loss after mini-batch    31: 1.813\n",
      "Loss after mini-batch    41: 0.164\n",
      "Loss after mini-batch    51: 1.362\n",
      "Loss after mini-batch    61: 16.631\n",
      "Loss after mini-batch    71: 3.296\n",
      "Loss after mini-batch    81: 0.032\n",
      "Loss after mini-batch    91: 0.318\n",
      "Loss after mini-batch   101: 7.149\n",
      "Loss after mini-batch   111: 4.164\n",
      "Loss after mini-batch   121: 0.368\n",
      "Loss after mini-batch   131: 0.418\n",
      "Loss after mini-batch   141: 0.102\n",
      "Loss after mini-batch   151: 0.149\n",
      "Loss after mini-batch   161: 6.413\n",
      "Loss after mini-batch   171: 0.302\n",
      "Loss after mini-batch   181: 0.371\n",
      "Loss after mini-batch   191: 2.729\n",
      "Loss after mini-batch   201: 1.681\n",
      "Loss after mini-batch   211: 6.720\n",
      "Loss after mini-batch   221: 15.792\n",
      "Loss after mini-batch   231: 2.242\n",
      "Loss after mini-batch   241: 1.019\n",
      "Loss after mini-batch   251: 1.171\n",
      "Loss after mini-batch   261: 1.225\n",
      "Loss after mini-batch   271: 0.128\n",
      "Loss after mini-batch   281: 0.170\n",
      "Loss after mini-batch   291: 0.044\n",
      "Loss after mini-batch   301: 0.700\n",
      "Loss after mini-batch   311: 0.961\n",
      "Loss after mini-batch   321: 0.158\n",
      "Loss after mini-batch   331: 0.134\n",
      "Loss after mini-batch   341: 10.156\n",
      "Loss after mini-batch   351: 2.646\n",
      "Loss after mini-batch   361: 1.968\n",
      "Loss after mini-batch   371: 5.223\n",
      "Training Loss: 0.073 \t\t Validation Loss:1.673\n",
      "Starting epoch 172\n",
      "Loss after mini-batch     1: 4.347\n",
      "Loss after mini-batch    11: 1.093\n",
      "Loss after mini-batch    21: 0.592\n",
      "Loss after mini-batch    31: 0.102\n",
      "Loss after mini-batch    41: 1.526\n",
      "Loss after mini-batch    51: 1.346\n",
      "Loss after mini-batch    61: 0.489\n",
      "Loss after mini-batch    71: 5.090\n",
      "Loss after mini-batch    81: 0.070\n",
      "Loss after mini-batch    91: 0.242\n",
      "Loss after mini-batch   101: 1.334\n",
      "Loss after mini-batch   111: 0.213\n",
      "Loss after mini-batch   121: 0.352\n",
      "Loss after mini-batch   131: 0.384\n",
      "Loss after mini-batch   141: 0.189\n",
      "Loss after mini-batch   151: 1.042\n",
      "Loss after mini-batch   161: 0.056\n",
      "Loss after mini-batch   171: 0.030\n",
      "Loss after mini-batch   181: 2.477\n",
      "Loss after mini-batch   191: 0.248\n",
      "Loss after mini-batch   201: 0.947\n",
      "Loss after mini-batch   211: 0.157\n",
      "Loss after mini-batch   221: 10.640\n",
      "Loss after mini-batch   231: 0.683\n",
      "Loss after mini-batch   241: 0.120\n",
      "Loss after mini-batch   251: 2.731\n",
      "Loss after mini-batch   261: 2.000\n",
      "Loss after mini-batch   271: 2.686\n",
      "Loss after mini-batch   281: 1.685\n",
      "Loss after mini-batch   291: 1.999\n",
      "Loss after mini-batch   301: 0.036\n",
      "Loss after mini-batch   311: 17.314\n",
      "Loss after mini-batch   321: 0.482\n",
      "Loss after mini-batch   331: 0.368\n",
      "Loss after mini-batch   341: 2.470\n",
      "Loss after mini-batch   351: 2.995\n",
      "Loss after mini-batch   361: 0.858\n",
      "Loss after mini-batch   371: 0.291\n",
      "Training Loss: 7.900 \t\t Validation Loss:9.199\n",
      "Starting epoch 173\n",
      "Loss after mini-batch     1: 0.218\n",
      "Loss after mini-batch    11: 7.131\n",
      "Loss after mini-batch    21: 0.138\n",
      "Loss after mini-batch    31: 0.919\n",
      "Loss after mini-batch    41: 0.429\n",
      "Loss after mini-batch    51: 1.405\n",
      "Loss after mini-batch    61: 0.447\n",
      "Loss after mini-batch    71: 0.154\n",
      "Loss after mini-batch    81: 1.579\n",
      "Loss after mini-batch    91: 2.053\n",
      "Loss after mini-batch   101: 0.410\n",
      "Loss after mini-batch   111: 0.310\n",
      "Loss after mini-batch   121: 1.622\n",
      "Loss after mini-batch   131: 2.483\n",
      "Loss after mini-batch   141: 1.170\n",
      "Loss after mini-batch   151: 0.183\n",
      "Loss after mini-batch   161: 1.000\n",
      "Loss after mini-batch   171: 0.177\n",
      "Loss after mini-batch   181: 2.293\n",
      "Loss after mini-batch   191: 0.424\n",
      "Loss after mini-batch   201: 0.254\n",
      "Loss after mini-batch   211: 2.791\n",
      "Loss after mini-batch   221: 30.978\n",
      "Loss after mini-batch   231: 0.014\n",
      "Loss after mini-batch   241: 0.086\n",
      "Loss after mini-batch   251: 0.239\n",
      "Loss after mini-batch   261: 1.739\n",
      "Loss after mini-batch   271: 1.531\n",
      "Loss after mini-batch   281: 1.430\n",
      "Loss after mini-batch   291: 2.629\n",
      "Loss after mini-batch   301: 0.344\n",
      "Loss after mini-batch   311: 0.300\n",
      "Loss after mini-batch   321: 2.173\n",
      "Loss after mini-batch   331: 3.630\n",
      "Loss after mini-batch   341: 0.786\n",
      "Loss after mini-batch   351: 0.136\n",
      "Loss after mini-batch   361: 0.046\n",
      "Loss after mini-batch   371: 1.484\n",
      "Training Loss: 8.626 \t\t Validation Loss:8.918\n",
      "Starting epoch 174\n",
      "Loss after mini-batch     1: 0.433\n",
      "Loss after mini-batch    11: 5.756\n",
      "Loss after mini-batch    21: 0.609\n",
      "Loss after mini-batch    31: 0.072\n",
      "Loss after mini-batch    41: 4.115\n",
      "Loss after mini-batch    51: 0.753\n",
      "Loss after mini-batch    61: 0.148\n",
      "Loss after mini-batch    71: 5.185\n",
      "Loss after mini-batch    81: 0.635\n",
      "Loss after mini-batch    91: 1.060\n",
      "Loss after mini-batch   101: 0.057\n",
      "Loss after mini-batch   111: 0.133\n",
      "Loss after mini-batch   121: 2.216\n",
      "Loss after mini-batch   131: 1.601\n",
      "Loss after mini-batch   141: 7.312\n",
      "Loss after mini-batch   151: 0.218\n",
      "Loss after mini-batch   161: 1.636\n",
      "Loss after mini-batch   171: 0.150\n",
      "Loss after mini-batch   181: 1.162\n",
      "Loss after mini-batch   191: 1.646\n",
      "Loss after mini-batch   201: 1.911\n",
      "Loss after mini-batch   211: 8.153\n",
      "Loss after mini-batch   221: 0.263\n",
      "Loss after mini-batch   231: 1.292\n",
      "Loss after mini-batch   241: 12.472\n",
      "Loss after mini-batch   251: 0.086\n",
      "Loss after mini-batch   261: 0.691\n",
      "Loss after mini-batch   271: 0.348\n",
      "Loss after mini-batch   281: 0.055\n",
      "Loss after mini-batch   291: 5.778\n",
      "Loss after mini-batch   301: 1.603\n",
      "Loss after mini-batch   311: 0.092\n",
      "Loss after mini-batch   321: 1.173\n",
      "Loss after mini-batch   331: 1.217\n",
      "Loss after mini-batch   341: 1.444\n",
      "Loss after mini-batch   351: 0.869\n",
      "Loss after mini-batch   361: 0.048\n",
      "Loss after mini-batch   371: 5.898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.898 \t\t Validation Loss:0.984\n",
      "Starting epoch 175\n",
      "Loss after mini-batch     1: 3.937\n",
      "Loss after mini-batch    11: 8.101\n",
      "Loss after mini-batch    21: 1.228\n",
      "Loss after mini-batch    31: 3.051\n",
      "Loss after mini-batch    41: 0.473\n",
      "Loss after mini-batch    51: 0.292\n",
      "Loss after mini-batch    61: 0.160\n",
      "Loss after mini-batch    71: 1.818\n",
      "Loss after mini-batch    81: 10.630\n",
      "Loss after mini-batch    91: 0.718\n",
      "Loss after mini-batch   101: 0.423\n",
      "Loss after mini-batch   111: 5.933\n",
      "Loss after mini-batch   121: 0.060\n",
      "Loss after mini-batch   131: 1.126\n",
      "Loss after mini-batch   141: 0.747\n",
      "Loss after mini-batch   151: 0.981\n",
      "Loss after mini-batch   161: 1.666\n",
      "Loss after mini-batch   171: 0.066\n",
      "Loss after mini-batch   181: 0.183\n",
      "Loss after mini-batch   191: 2.070\n",
      "Loss after mini-batch   201: 0.141\n",
      "Loss after mini-batch   211: 0.546\n",
      "Loss after mini-batch   221: 2.374\n",
      "Loss after mini-batch   231: 0.736\n",
      "Loss after mini-batch   241: 2.093\n",
      "Loss after mini-batch   251: 0.240\n",
      "Loss after mini-batch   261: 1.136\n",
      "Loss after mini-batch   271: 0.857\n",
      "Loss after mini-batch   281: 0.015\n",
      "Loss after mini-batch   291: 5.904\n",
      "Loss after mini-batch   301: 1.395\n",
      "Loss after mini-batch   311: 0.518\n",
      "Loss after mini-batch   321: 1.141\n",
      "Loss after mini-batch   331: 0.586\n",
      "Loss after mini-batch   341: 0.822\n",
      "Loss after mini-batch   351: 0.406\n",
      "Loss after mini-batch   361: 0.230\n",
      "Loss after mini-batch   371: 0.120\n",
      "Training Loss: 0.067 \t\t Validation Loss:0.211\n",
      "Starting epoch 176\n",
      "Loss after mini-batch     1: 0.126\n",
      "Loss after mini-batch    11: 0.987\n",
      "Loss after mini-batch    21: 0.035\n",
      "Loss after mini-batch    31: 1.233\n",
      "Loss after mini-batch    41: 0.136\n",
      "Loss after mini-batch    51: 1.064\n",
      "Loss after mini-batch    61: 6.321\n",
      "Loss after mini-batch    71: 2.752\n",
      "Loss after mini-batch    81: 2.817\n",
      "Loss after mini-batch    91: 3.584\n",
      "Loss after mini-batch   101: 0.116\n",
      "Loss after mini-batch   111: 0.323\n",
      "Loss after mini-batch   121: 0.285\n",
      "Loss after mini-batch   131: 0.079\n",
      "Loss after mini-batch   141: 0.996\n",
      "Loss after mini-batch   151: 2.183\n",
      "Loss after mini-batch   161: 0.168\n",
      "Loss after mini-batch   171: 0.285\n",
      "Loss after mini-batch   181: 0.391\n",
      "Loss after mini-batch   191: 0.076\n",
      "Loss after mini-batch   201: 0.812\n",
      "Loss after mini-batch   211: 0.173\n",
      "Loss after mini-batch   221: 3.030\n",
      "Loss after mini-batch   231: 0.063\n",
      "Loss after mini-batch   241: 2.462\n",
      "Loss after mini-batch   251: 30.273\n",
      "Loss after mini-batch   261: 0.048\n",
      "Loss after mini-batch   271: 0.069\n",
      "Loss after mini-batch   281: 1.330\n",
      "Loss after mini-batch   291: 0.210\n",
      "Loss after mini-batch   301: 0.358\n",
      "Loss after mini-batch   311: 0.276\n",
      "Loss after mini-batch   321: 0.463\n",
      "Loss after mini-batch   331: 0.276\n",
      "Loss after mini-batch   341: 2.329\n",
      "Loss after mini-batch   351: 1.234\n",
      "Loss after mini-batch   361: 0.159\n",
      "Loss after mini-batch   371: 0.021\n",
      "Training Loss: 0.050 \t\t Validation Loss:2.698\n",
      "Starting epoch 177\n",
      "Loss after mini-batch     1: 0.220\n",
      "Loss after mini-batch    11: 0.077\n",
      "Loss after mini-batch    21: 1.390\n",
      "Loss after mini-batch    31: 1.740\n",
      "Loss after mini-batch    41: 3.575\n",
      "Loss after mini-batch    51: 2.431\n",
      "Loss after mini-batch    61: 8.238\n",
      "Loss after mini-batch    71: 0.074\n",
      "Loss after mini-batch    81: 0.206\n",
      "Loss after mini-batch    91: 0.132\n",
      "Loss after mini-batch   101: 0.288\n",
      "Loss after mini-batch   111: 0.182\n",
      "Loss after mini-batch   121: 1.405\n",
      "Loss after mini-batch   131: 1.031\n",
      "Loss after mini-batch   141: 6.874\n",
      "Loss after mini-batch   151: 3.965\n",
      "Loss after mini-batch   161: 1.280\n",
      "Loss after mini-batch   171: 1.710\n",
      "Loss after mini-batch   181: 2.014\n",
      "Loss after mini-batch   191: 0.103\n",
      "Loss after mini-batch   201: 0.250\n",
      "Loss after mini-batch   211: 0.215\n",
      "Loss after mini-batch   221: 1.252\n",
      "Loss after mini-batch   231: 0.098\n",
      "Loss after mini-batch   241: 0.836\n",
      "Loss after mini-batch   251: 0.301\n",
      "Loss after mini-batch   261: 0.166\n",
      "Loss after mini-batch   271: 0.015\n",
      "Loss after mini-batch   281: 0.345\n",
      "Loss after mini-batch   291: 6.814\n",
      "Loss after mini-batch   301: 2.309\n",
      "Loss after mini-batch   311: 4.154\n",
      "Loss after mini-batch   321: 0.479\n",
      "Loss after mini-batch   331: 0.464\n",
      "Loss after mini-batch   341: 0.132\n",
      "Loss after mini-batch   351: 0.318\n",
      "Loss after mini-batch   361: 0.217\n",
      "Loss after mini-batch   371: 0.129\n",
      "Training Loss: 0.059 \t\t Validation Loss:0.082\n",
      "Starting epoch 178\n",
      "Loss after mini-batch     1: 0.099\n",
      "Loss after mini-batch    11: 0.307\n",
      "Loss after mini-batch    21: 0.458\n",
      "Loss after mini-batch    31: 0.146\n",
      "Loss after mini-batch    41: 0.277\n",
      "Loss after mini-batch    51: 3.994\n",
      "Loss after mini-batch    61: 0.085\n",
      "Loss after mini-batch    71: 9.130\n",
      "Loss after mini-batch    81: 0.379\n",
      "Loss after mini-batch    91: 0.005\n",
      "Loss after mini-batch   101: 0.216\n",
      "Loss after mini-batch   111: 0.062\n",
      "Loss after mini-batch   121: 0.405\n",
      "Loss after mini-batch   131: 0.036\n",
      "Loss after mini-batch   141: 5.449\n",
      "Loss after mini-batch   151: 0.176\n",
      "Loss after mini-batch   161: 7.201\n",
      "Loss after mini-batch   171: 1.314\n",
      "Loss after mini-batch   181: 0.146\n",
      "Loss after mini-batch   191: 7.097\n",
      "Loss after mini-batch   201: 0.091\n",
      "Loss after mini-batch   211: 3.067\n",
      "Loss after mini-batch   221: 0.124\n",
      "Loss after mini-batch   231: 0.043\n",
      "Loss after mini-batch   241: 0.369\n",
      "Loss after mini-batch   251: 2.674\n",
      "Loss after mini-batch   261: 3.242\n",
      "Loss after mini-batch   271: 10.195\n",
      "Loss after mini-batch   281: 0.089\n",
      "Loss after mini-batch   291: 0.895\n",
      "Loss after mini-batch   301: 0.109\n",
      "Loss after mini-batch   311: 0.014\n",
      "Loss after mini-batch   321: 2.208\n",
      "Loss after mini-batch   331: 0.604\n",
      "Loss after mini-batch   341: 0.763\n",
      "Loss after mini-batch   351: 0.079\n",
      "Loss after mini-batch   361: 5.963\n",
      "Loss after mini-batch   371: 0.167\n",
      "Training Loss: 1.831 \t\t Validation Loss:2.200\n",
      "Starting epoch 179\n",
      "Loss after mini-batch     1: 0.915\n",
      "Loss after mini-batch    11: 0.099\n",
      "Loss after mini-batch    21: 0.199\n",
      "Loss after mini-batch    31: 1.538\n",
      "Loss after mini-batch    41: 0.202\n",
      "Loss after mini-batch    51: 2.237\n",
      "Loss after mini-batch    61: 0.100\n",
      "Loss after mini-batch    71: 21.998\n",
      "Loss after mini-batch    81: 0.171\n",
      "Loss after mini-batch    91: 0.050\n",
      "Loss after mini-batch   101: 1.405\n",
      "Loss after mini-batch   111: 0.260\n",
      "Loss after mini-batch   121: 3.946\n",
      "Loss after mini-batch   131: 1.833\n",
      "Loss after mini-batch   141: 0.078\n",
      "Loss after mini-batch   151: 3.914\n",
      "Loss after mini-batch   161: 3.326\n",
      "Loss after mini-batch   171: 0.722\n",
      "Loss after mini-batch   181: 0.082\n",
      "Loss after mini-batch   191: 0.902\n",
      "Loss after mini-batch   201: 5.343\n",
      "Loss after mini-batch   211: 3.089\n",
      "Loss after mini-batch   221: 5.954\n",
      "Loss after mini-batch   231: 0.206\n",
      "Loss after mini-batch   241: 0.033\n",
      "Loss after mini-batch   251: 0.237\n",
      "Loss after mini-batch   261: 2.247\n",
      "Loss after mini-batch   271: 3.088\n",
      "Loss after mini-batch   281: 0.411\n",
      "Loss after mini-batch   291: 0.031\n",
      "Loss after mini-batch   301: 0.869\n",
      "Loss after mini-batch   311: 0.241\n",
      "Loss after mini-batch   321: 0.547\n",
      "Loss after mini-batch   331: 1.945\n",
      "Loss after mini-batch   341: 0.235\n",
      "Loss after mini-batch   351: 0.073\n",
      "Loss after mini-batch   361: 0.182\n",
      "Loss after mini-batch   371: 0.593\n",
      "Training Loss: 0.313 \t\t Validation Loss:3.150\n",
      "Starting epoch 180\n",
      "Loss after mini-batch     1: 1.016\n",
      "Loss after mini-batch    11: 0.914\n",
      "Loss after mini-batch    21: 2.207\n",
      "Loss after mini-batch    31: 0.461\n",
      "Loss after mini-batch    41: 2.829\n",
      "Loss after mini-batch    51: 1.809\n",
      "Loss after mini-batch    61: 5.426\n",
      "Loss after mini-batch    71: 2.881\n",
      "Loss after mini-batch    81: 6.136\n",
      "Loss after mini-batch    91: 6.284\n",
      "Loss after mini-batch   101: 0.485\n",
      "Loss after mini-batch   111: 1.901\n",
      "Loss after mini-batch   121: 0.215\n",
      "Loss after mini-batch   131: 0.186\n",
      "Loss after mini-batch   141: 0.162\n",
      "Loss after mini-batch   151: 0.976\n",
      "Loss after mini-batch   161: 0.322\n",
      "Loss after mini-batch   171: 3.813\n",
      "Loss after mini-batch   181: 1.611\n",
      "Loss after mini-batch   191: 1.884\n",
      "Loss after mini-batch   201: 2.755\n",
      "Loss after mini-batch   211: 0.093\n",
      "Loss after mini-batch   221: 6.173\n",
      "Loss after mini-batch   231: 0.471\n",
      "Loss after mini-batch   241: 0.842\n",
      "Loss after mini-batch   251: 3.810\n",
      "Loss after mini-batch   261: 0.318\n",
      "Loss after mini-batch   271: 1.248\n",
      "Loss after mini-batch   281: 0.040\n",
      "Loss after mini-batch   291: 0.896\n",
      "Loss after mini-batch   301: 1.238\n",
      "Loss after mini-batch   311: 0.021\n",
      "Loss after mini-batch   321: 0.429\n",
      "Loss after mini-batch   331: 0.667\n",
      "Loss after mini-batch   341: 7.908\n",
      "Loss after mini-batch   351: 0.366\n",
      "Loss after mini-batch   361: 0.609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   371: 0.214\n",
      "Training Loss: 0.319 \t\t Validation Loss:5.613\n",
      "Starting epoch 181\n",
      "Loss after mini-batch     1: 2.232\n",
      "Loss after mini-batch    11: 0.055\n",
      "Loss after mini-batch    21: 5.875\n",
      "Loss after mini-batch    31: 0.132\n",
      "Loss after mini-batch    41: 7.420\n",
      "Loss after mini-batch    51: 1.449\n",
      "Loss after mini-batch    61: 0.219\n",
      "Loss after mini-batch    71: 0.259\n",
      "Loss after mini-batch    81: 2.850\n",
      "Loss after mini-batch    91: 0.319\n",
      "Loss after mini-batch   101: 0.891\n",
      "Loss after mini-batch   111: 1.331\n",
      "Loss after mini-batch   121: 12.086\n",
      "Loss after mini-batch   131: 0.397\n",
      "Loss after mini-batch   141: 0.954\n",
      "Loss after mini-batch   151: 1.383\n",
      "Loss after mini-batch   161: 0.344\n",
      "Loss after mini-batch   171: 2.063\n",
      "Loss after mini-batch   181: 0.087\n",
      "Loss after mini-batch   191: 3.111\n",
      "Loss after mini-batch   201: 0.175\n",
      "Loss after mini-batch   211: 3.695\n",
      "Loss after mini-batch   221: 0.392\n",
      "Loss after mini-batch   231: 0.092\n",
      "Loss after mini-batch   241: 2.648\n",
      "Loss after mini-batch   251: 0.765\n",
      "Loss after mini-batch   261: 1.803\n",
      "Loss after mini-batch   271: 0.318\n",
      "Loss after mini-batch   281: 1.017\n",
      "Loss after mini-batch   291: 2.039\n",
      "Loss after mini-batch   301: 0.605\n",
      "Loss after mini-batch   311: 0.130\n",
      "Loss after mini-batch   321: 0.444\n",
      "Loss after mini-batch   331: 0.122\n",
      "Loss after mini-batch   341: 0.189\n",
      "Loss after mini-batch   351: 0.261\n",
      "Loss after mini-batch   361: 0.174\n",
      "Loss after mini-batch   371: 0.027\n",
      "Training Loss: 0.150 \t\t Validation Loss:1.057\n",
      "Starting epoch 182\n",
      "Loss after mini-batch     1: 0.214\n",
      "Loss after mini-batch    11: 3.921\n",
      "Loss after mini-batch    21: 5.714\n",
      "Loss after mini-batch    31: 0.014\n",
      "Loss after mini-batch    41: 0.141\n",
      "Loss after mini-batch    51: 0.159\n",
      "Loss after mini-batch    61: 0.337\n",
      "Loss after mini-batch    71: 1.587\n",
      "Loss after mini-batch    81: 0.062\n",
      "Loss after mini-batch    91: 0.609\n",
      "Loss after mini-batch   101: 0.109\n",
      "Loss after mini-batch   111: 0.240\n",
      "Loss after mini-batch   121: 0.793\n",
      "Loss after mini-batch   131: 1.343\n",
      "Loss after mini-batch   141: 5.709\n",
      "Loss after mini-batch   151: 3.271\n",
      "Loss after mini-batch   161: 1.592\n",
      "Loss after mini-batch   171: 1.309\n",
      "Loss after mini-batch   181: 3.428\n",
      "Loss after mini-batch   191: 0.867\n",
      "Loss after mini-batch   201: 1.758\n",
      "Loss after mini-batch   211: 2.091\n",
      "Loss after mini-batch   221: 2.782\n",
      "Loss after mini-batch   231: 0.194\n",
      "Loss after mini-batch   241: 0.431\n",
      "Loss after mini-batch   251: 9.987\n",
      "Loss after mini-batch   261: 0.986\n",
      "Loss after mini-batch   271: 0.191\n",
      "Loss after mini-batch   281: 0.874\n",
      "Loss after mini-batch   291: 0.068\n",
      "Loss after mini-batch   301: 0.022\n",
      "Loss after mini-batch   311: 0.514\n",
      "Loss after mini-batch   321: 1.579\n",
      "Loss after mini-batch   331: 0.828\n",
      "Loss after mini-batch   341: 0.411\n",
      "Loss after mini-batch   351: 0.290\n",
      "Loss after mini-batch   361: 0.076\n",
      "Loss after mini-batch   371: 0.054\n",
      "Training Loss: 0.058 \t\t Validation Loss:1.537\n",
      "Starting epoch 183\n",
      "Loss after mini-batch     1: 5.629\n",
      "Loss after mini-batch    11: 0.093\n",
      "Loss after mini-batch    21: 2.731\n",
      "Loss after mini-batch    31: 0.404\n",
      "Loss after mini-batch    41: 1.144\n",
      "Loss after mini-batch    51: 0.117\n",
      "Loss after mini-batch    61: 0.103\n",
      "Loss after mini-batch    71: 0.204\n",
      "Loss after mini-batch    81: 0.184\n",
      "Loss after mini-batch    91: 0.887\n",
      "Loss after mini-batch   101: 0.156\n",
      "Loss after mini-batch   111: 0.954\n",
      "Loss after mini-batch   121: 7.303\n",
      "Loss after mini-batch   131: 1.602\n",
      "Loss after mini-batch   141: 0.187\n",
      "Loss after mini-batch   151: 1.476\n",
      "Loss after mini-batch   161: 0.809\n",
      "Loss after mini-batch   171: 0.172\n",
      "Loss after mini-batch   181: 0.410\n",
      "Loss after mini-batch   191: 0.422\n",
      "Loss after mini-batch   201: 0.095\n",
      "Loss after mini-batch   211: 0.125\n",
      "Loss after mini-batch   221: 0.140\n",
      "Loss after mini-batch   231: 0.182\n",
      "Loss after mini-batch   241: 0.147\n",
      "Loss after mini-batch   251: 0.131\n",
      "Loss after mini-batch   261: 2.819\n",
      "Loss after mini-batch   271: 6.728\n",
      "Loss after mini-batch   281: 0.184\n",
      "Loss after mini-batch   291: 5.635\n",
      "Loss after mini-batch   301: 0.072\n",
      "Loss after mini-batch   311: 1.446\n",
      "Loss after mini-batch   321: 0.217\n",
      "Loss after mini-batch   331: 0.057\n",
      "Loss after mini-batch   341: 7.048\n",
      "Loss after mini-batch   351: 0.289\n",
      "Loss after mini-batch   361: 0.660\n",
      "Loss after mini-batch   371: 0.076\n",
      "Training Loss: 1.192 \t\t Validation Loss:3.941\n",
      "Starting epoch 184\n",
      "Loss after mini-batch     1: 0.205\n",
      "Loss after mini-batch    11: 1.839\n",
      "Loss after mini-batch    21: 0.050\n",
      "Loss after mini-batch    31: 0.429\n",
      "Loss after mini-batch    41: 0.084\n",
      "Loss after mini-batch    51: 2.429\n",
      "Loss after mini-batch    61: 0.103\n",
      "Loss after mini-batch    71: 0.255\n",
      "Loss after mini-batch    81: 5.857\n",
      "Loss after mini-batch    91: 0.384\n",
      "Loss after mini-batch   101: 0.159\n",
      "Loss after mini-batch   111: 0.297\n",
      "Loss after mini-batch   121: 0.435\n",
      "Loss after mini-batch   131: 3.487\n",
      "Loss after mini-batch   141: 0.608\n",
      "Loss after mini-batch   151: 0.423\n",
      "Loss after mini-batch   161: 0.060\n",
      "Loss after mini-batch   171: 1.694\n",
      "Loss after mini-batch   181: 0.490\n",
      "Loss after mini-batch   191: 0.293\n",
      "Loss after mini-batch   201: 0.052\n",
      "Loss after mini-batch   211: 2.532\n",
      "Loss after mini-batch   221: 3.111\n",
      "Loss after mini-batch   231: 0.054\n",
      "Loss after mini-batch   241: 0.030\n",
      "Loss after mini-batch   251: 1.004\n",
      "Loss after mini-batch   261: 0.393\n",
      "Loss after mini-batch   271: 1.116\n",
      "Loss after mini-batch   281: 0.416\n",
      "Loss after mini-batch   291: 7.394\n",
      "Loss after mini-batch   301: 0.545\n",
      "Loss after mini-batch   311: 0.403\n",
      "Loss after mini-batch   321: 3.423\n",
      "Loss after mini-batch   331: 5.999\n",
      "Loss after mini-batch   341: 2.123\n",
      "Loss after mini-batch   351: 0.723\n",
      "Loss after mini-batch   361: 3.818\n",
      "Loss after mini-batch   371: 4.757\n",
      "Training Loss: 8.589 \t\t Validation Loss:8.813\n",
      "Starting epoch 185\n",
      "Loss after mini-batch     1: 0.367\n",
      "Loss after mini-batch    11: 3.924\n",
      "Loss after mini-batch    21: 6.283\n",
      "Loss after mini-batch    31: 0.987\n",
      "Loss after mini-batch    41: 0.411\n",
      "Loss after mini-batch    51: 2.512\n",
      "Loss after mini-batch    61: 2.063\n",
      "Loss after mini-batch    71: 1.144\n",
      "Loss after mini-batch    81: 0.427\n",
      "Loss after mini-batch    91: 0.048\n",
      "Loss after mini-batch   101: 0.960\n",
      "Loss after mini-batch   111: 0.201\n",
      "Loss after mini-batch   121: 5.574\n",
      "Loss after mini-batch   131: 0.155\n",
      "Loss after mini-batch   141: 1.618\n",
      "Loss after mini-batch   151: 7.617\n",
      "Loss after mini-batch   161: 0.241\n",
      "Loss after mini-batch   171: 0.358\n",
      "Loss after mini-batch   181: 0.873\n",
      "Loss after mini-batch   191: 1.295\n",
      "Loss after mini-batch   201: 0.070\n",
      "Loss after mini-batch   211: 0.207\n",
      "Loss after mini-batch   221: 4.188\n",
      "Loss after mini-batch   231: 6.637\n",
      "Loss after mini-batch   241: 3.154\n",
      "Loss after mini-batch   251: 0.500\n",
      "Loss after mini-batch   261: 3.817\n",
      "Loss after mini-batch   271: 0.300\n",
      "Loss after mini-batch   281: 0.159\n",
      "Loss after mini-batch   291: 5.426\n",
      "Loss after mini-batch   301: 1.662\n",
      "Loss after mini-batch   311: 1.499\n",
      "Loss after mini-batch   321: 0.449\n",
      "Loss after mini-batch   331: 0.893\n",
      "Loss after mini-batch   341: 0.223\n",
      "Loss after mini-batch   351: 4.698\n",
      "Loss after mini-batch   361: 0.255\n",
      "Loss after mini-batch   371: 1.326\n",
      "Training Loss: 0.510 \t\t Validation Loss:0.620\n",
      "Starting epoch 186\n",
      "Loss after mini-batch     1: 0.607\n",
      "Loss after mini-batch    11: 16.206\n",
      "Loss after mini-batch    21: 0.424\n",
      "Loss after mini-batch    31: 0.335\n",
      "Loss after mini-batch    41: 1.935\n",
      "Loss after mini-batch    51: 0.181\n",
      "Loss after mini-batch    61: 5.625\n",
      "Loss after mini-batch    71: 0.191\n",
      "Loss after mini-batch    81: 1.320\n",
      "Loss after mini-batch    91: 0.055\n",
      "Loss after mini-batch   101: 0.222\n",
      "Loss after mini-batch   111: 0.593\n",
      "Loss after mini-batch   121: 0.893\n",
      "Loss after mini-batch   131: 4.501\n",
      "Loss after mini-batch   141: 1.662\n",
      "Loss after mini-batch   151: 0.865\n",
      "Loss after mini-batch   161: 0.833\n",
      "Loss after mini-batch   171: 0.612\n",
      "Loss after mini-batch   181: 2.479\n",
      "Loss after mini-batch   191: 0.557\n",
      "Loss after mini-batch   201: 0.141\n",
      "Loss after mini-batch   211: 10.059\n",
      "Loss after mini-batch   221: 3.126\n",
      "Loss after mini-batch   231: 0.328\n",
      "Loss after mini-batch   241: 4.539\n",
      "Loss after mini-batch   251: 0.946\n",
      "Loss after mini-batch   261: 8.404\n",
      "Loss after mini-batch   271: 1.917\n",
      "Loss after mini-batch   281: 0.217\n",
      "Loss after mini-batch   291: 6.290\n",
      "Loss after mini-batch   301: 6.689\n",
      "Loss after mini-batch   311: 0.125\n",
      "Loss after mini-batch   321: 0.017\n",
      "Loss after mini-batch   331: 0.328\n",
      "Loss after mini-batch   341: 0.116\n",
      "Loss after mini-batch   351: 2.599\n",
      "Loss after mini-batch   361: 1.854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   371: 0.133\n",
      "Training Loss: 0.115 \t\t Validation Loss:0.128\n",
      "Starting epoch 187\n",
      "Loss after mini-batch     1: 4.606\n",
      "Loss after mini-batch    11: 14.380\n",
      "Loss after mini-batch    21: 2.084\n",
      "Loss after mini-batch    31: 0.106\n",
      "Loss after mini-batch    41: 0.044\n",
      "Loss after mini-batch    51: 0.178\n",
      "Loss after mini-batch    61: 0.066\n",
      "Loss after mini-batch    71: 0.034\n",
      "Loss after mini-batch    81: 5.623\n",
      "Loss after mini-batch    91: 0.145\n",
      "Loss after mini-batch   101: 6.724\n",
      "Loss after mini-batch   111: 0.229\n",
      "Loss after mini-batch   121: 1.343\n",
      "Loss after mini-batch   131: 0.450\n",
      "Loss after mini-batch   141: 5.993\n",
      "Loss after mini-batch   151: 4.995\n",
      "Loss after mini-batch   161: 1.227\n",
      "Loss after mini-batch   171: 0.065\n",
      "Loss after mini-batch   181: 0.059\n",
      "Loss after mini-batch   191: 0.138\n",
      "Loss after mini-batch   201: 0.147\n",
      "Loss after mini-batch   211: 0.197\n",
      "Loss after mini-batch   221: 0.927\n",
      "Loss after mini-batch   231: 1.490\n",
      "Loss after mini-batch   241: 2.206\n",
      "Loss after mini-batch   251: 2.468\n",
      "Loss after mini-batch   261: 0.135\n",
      "Loss after mini-batch   271: 0.119\n",
      "Loss after mini-batch   281: 2.330\n",
      "Loss after mini-batch   291: 7.565\n",
      "Loss after mini-batch   301: 0.138\n",
      "Loss after mini-batch   311: 1.597\n",
      "Loss after mini-batch   321: 0.075\n",
      "Loss after mini-batch   331: 3.315\n",
      "Loss after mini-batch   341: 1.284\n",
      "Loss after mini-batch   351: 0.607\n",
      "Loss after mini-batch   361: 2.245\n",
      "Loss after mini-batch   371: 1.350\n",
      "Training Loss: 0.246 \t\t Validation Loss:0.549\n",
      "Starting epoch 188\n",
      "Loss after mini-batch     1: 1.173\n",
      "Loss after mini-batch    11: 0.557\n",
      "Loss after mini-batch    21: 2.719\n",
      "Loss after mini-batch    31: 1.054\n",
      "Loss after mini-batch    41: 4.677\n",
      "Loss after mini-batch    51: 0.285\n",
      "Loss after mini-batch    61: 3.501\n",
      "Loss after mini-batch    71: 0.198\n",
      "Loss after mini-batch    81: 0.093\n",
      "Loss after mini-batch    91: 0.076\n",
      "Loss after mini-batch   101: 0.128\n",
      "Loss after mini-batch   111: 0.927\n",
      "Loss after mini-batch   121: 2.254\n",
      "Loss after mini-batch   131: 1.252\n",
      "Loss after mini-batch   141: 0.026\n",
      "Loss after mini-batch   151: 2.568\n",
      "Loss after mini-batch   161: 4.608\n",
      "Loss after mini-batch   171: 1.483\n",
      "Loss after mini-batch   181: 0.162\n",
      "Loss after mini-batch   191: 0.027\n",
      "Loss after mini-batch   201: 0.097\n",
      "Loss after mini-batch   211: 0.293\n",
      "Loss after mini-batch   221: 0.360\n",
      "Loss after mini-batch   231: 0.328\n",
      "Loss after mini-batch   241: 2.182\n",
      "Loss after mini-batch   251: 0.296\n",
      "Loss after mini-batch   261: 1.688\n",
      "Loss after mini-batch   271: 0.566\n",
      "Loss after mini-batch   281: 0.471\n",
      "Loss after mini-batch   291: 6.085\n",
      "Loss after mini-batch   301: 7.752\n",
      "Loss after mini-batch   311: 3.815\n",
      "Loss after mini-batch   321: 1.139\n",
      "Loss after mini-batch   331: 0.851\n",
      "Loss after mini-batch   341: 0.099\n",
      "Loss after mini-batch   351: 0.343\n",
      "Loss after mini-batch   361: 1.823\n",
      "Loss after mini-batch   371: 0.037\n",
      "Training Loss: 0.121 \t\t Validation Loss:0.795\n",
      "Starting epoch 189\n",
      "Loss after mini-batch     1: 5.038\n",
      "Loss after mini-batch    11: 0.188\n",
      "Loss after mini-batch    21: 1.902\n",
      "Loss after mini-batch    31: 1.284\n",
      "Loss after mini-batch    41: 0.092\n",
      "Loss after mini-batch    51: 2.741\n",
      "Loss after mini-batch    61: 0.151\n",
      "Loss after mini-batch    71: 0.046\n",
      "Loss after mini-batch    81: 2.327\n",
      "Loss after mini-batch    91: 0.162\n",
      "Loss after mini-batch   101: 6.274\n",
      "Loss after mini-batch   111: 0.047\n",
      "Loss after mini-batch   121: 2.294\n",
      "Loss after mini-batch   131: 1.201\n",
      "Loss after mini-batch   141: 0.096\n",
      "Loss after mini-batch   151: 1.163\n",
      "Loss after mini-batch   161: 0.062\n",
      "Loss after mini-batch   171: 0.122\n",
      "Loss after mini-batch   181: 3.862\n",
      "Loss after mini-batch   191: 0.065\n",
      "Loss after mini-batch   201: 0.881\n",
      "Loss after mini-batch   211: 2.030\n",
      "Loss after mini-batch   221: 0.643\n",
      "Loss after mini-batch   231: 0.417\n",
      "Loss after mini-batch   241: 0.864\n",
      "Loss after mini-batch   251: 0.431\n",
      "Loss after mini-batch   261: 0.776\n",
      "Loss after mini-batch   271: 0.266\n",
      "Loss after mini-batch   281: 2.524\n",
      "Loss after mini-batch   291: 1.812\n",
      "Loss after mini-batch   301: 10.108\n",
      "Loss after mini-batch   311: 0.047\n",
      "Loss after mini-batch   321: 0.028\n",
      "Loss after mini-batch   331: 1.222\n",
      "Loss after mini-batch   341: 1.386\n",
      "Loss after mini-batch   351: 0.929\n",
      "Loss after mini-batch   361: 1.120\n",
      "Loss after mini-batch   371: 0.224\n",
      "Training Loss: 3.692 \t\t Validation Loss:3.832\n",
      "Starting epoch 190\n",
      "Loss after mini-batch     1: 0.488\n",
      "Loss after mini-batch    11: 2.405\n",
      "Loss after mini-batch    21: 2.886\n",
      "Loss after mini-batch    31: 2.436\n",
      "Loss after mini-batch    41: 1.340\n",
      "Loss after mini-batch    51: 1.926\n",
      "Loss after mini-batch    61: 6.967\n",
      "Loss after mini-batch    71: 2.056\n",
      "Loss after mini-batch    81: 0.380\n",
      "Loss after mini-batch    91: 0.280\n",
      "Loss after mini-batch   101: 0.180\n",
      "Loss after mini-batch   111: 0.100\n",
      "Loss after mini-batch   121: 1.959\n",
      "Loss after mini-batch   131: 0.156\n",
      "Loss after mini-batch   141: 0.172\n",
      "Loss after mini-batch   151: 1.396\n",
      "Loss after mini-batch   161: 0.437\n",
      "Loss after mini-batch   171: 1.332\n",
      "Loss after mini-batch   181: 7.293\n",
      "Loss after mini-batch   191: 0.840\n",
      "Loss after mini-batch   201: 0.826\n",
      "Loss after mini-batch   211: 0.132\n",
      "Loss after mini-batch   221: 4.650\n",
      "Loss after mini-batch   231: 1.903\n",
      "Loss after mini-batch   241: 0.488\n",
      "Loss after mini-batch   251: 5.856\n",
      "Loss after mini-batch   261: 0.804\n",
      "Loss after mini-batch   271: 0.281\n",
      "Loss after mini-batch   281: 0.180\n",
      "Loss after mini-batch   291: 0.050\n",
      "Loss after mini-batch   301: 9.425\n",
      "Loss after mini-batch   311: 1.135\n",
      "Loss after mini-batch   321: 11.335\n",
      "Loss after mini-batch   331: 1.627\n",
      "Loss after mini-batch   341: 0.046\n",
      "Loss after mini-batch   351: 1.402\n",
      "Loss after mini-batch   361: 0.148\n",
      "Loss after mini-batch   371: 0.297\n",
      "Training Loss: 0.299 \t\t Validation Loss:0.472\n",
      "Starting epoch 191\n",
      "Loss after mini-batch     1: 0.503\n",
      "Loss after mini-batch    11: 1.215\n",
      "Loss after mini-batch    21: 0.068\n",
      "Loss after mini-batch    31: 0.406\n",
      "Loss after mini-batch    41: 0.381\n",
      "Loss after mini-batch    51: 4.037\n",
      "Loss after mini-batch    61: 5.901\n",
      "Loss after mini-batch    71: 0.457\n",
      "Loss after mini-batch    81: 4.925\n",
      "Loss after mini-batch    91: 0.296\n",
      "Loss after mini-batch   101: 4.677\n",
      "Loss after mini-batch   111: 0.237\n",
      "Loss after mini-batch   121: 0.187\n",
      "Loss after mini-batch   131: 0.205\n",
      "Loss after mini-batch   141: 0.930\n",
      "Loss after mini-batch   151: 0.155\n",
      "Loss after mini-batch   161: 1.152\n",
      "Loss after mini-batch   171: 0.647\n",
      "Loss after mini-batch   181: 1.291\n",
      "Loss after mini-batch   191: 4.110\n",
      "Loss after mini-batch   201: 1.372\n",
      "Loss after mini-batch   211: 0.339\n",
      "Loss after mini-batch   221: 5.602\n",
      "Loss after mini-batch   231: 1.056\n",
      "Loss after mini-batch   241: 0.574\n",
      "Loss after mini-batch   251: 4.663\n",
      "Loss after mini-batch   261: 0.582\n",
      "Loss after mini-batch   271: 1.275\n",
      "Loss after mini-batch   281: 0.140\n",
      "Loss after mini-batch   291: 0.376\n",
      "Loss after mini-batch   301: 0.127\n",
      "Loss after mini-batch   311: 0.327\n",
      "Loss after mini-batch   321: 0.136\n",
      "Loss after mini-batch   331: 8.560\n",
      "Loss after mini-batch   341: 1.249\n",
      "Loss after mini-batch   351: 0.749\n",
      "Loss after mini-batch   361: 0.300\n",
      "Loss after mini-batch   371: 0.139\n",
      "Training Loss: 4.041 \t\t Validation Loss:33.945\n",
      "Starting epoch 192\n",
      "Loss after mini-batch     1: 0.093\n",
      "Loss after mini-batch    11: 1.087\n",
      "Loss after mini-batch    21: 0.094\n",
      "Loss after mini-batch    31: 2.079\n",
      "Loss after mini-batch    41: 12.916\n",
      "Loss after mini-batch    51: 15.884\n",
      "Loss after mini-batch    61: 3.450\n",
      "Loss after mini-batch    71: 0.410\n",
      "Loss after mini-batch    81: 0.032\n",
      "Loss after mini-batch    91: 0.102\n",
      "Loss after mini-batch   101: 4.043\n",
      "Loss after mini-batch   111: 0.033\n",
      "Loss after mini-batch   121: 0.498\n",
      "Loss after mini-batch   131: 0.025\n",
      "Loss after mini-batch   141: 1.326\n",
      "Loss after mini-batch   151: 1.481\n",
      "Loss after mini-batch   161: 0.298\n",
      "Loss after mini-batch   171: 0.871\n",
      "Loss after mini-batch   181: 3.190\n",
      "Loss after mini-batch   191: 5.635\n",
      "Loss after mini-batch   201: 0.907\n",
      "Loss after mini-batch   211: 2.193\n",
      "Loss after mini-batch   221: 7.455\n",
      "Loss after mini-batch   231: 0.045\n",
      "Loss after mini-batch   241: 0.791\n",
      "Loss after mini-batch   251: 1.915\n",
      "Loss after mini-batch   261: 0.047\n",
      "Loss after mini-batch   271: 2.650\n",
      "Loss after mini-batch   281: 4.950\n",
      "Loss after mini-batch   291: 0.850\n",
      "Loss after mini-batch   301: 1.083\n",
      "Loss after mini-batch   311: 0.490\n",
      "Loss after mini-batch   321: 0.751\n",
      "Loss after mini-batch   331: 1.408\n",
      "Loss after mini-batch   341: 0.885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   351: 0.202\n",
      "Loss after mini-batch   361: 0.874\n",
      "Loss after mini-batch   371: 1.187\n",
      "Training Loss: 0.793 \t\t Validation Loss:1.026\n",
      "Starting epoch 193\n",
      "Loss after mini-batch     1: 0.775\n",
      "Loss after mini-batch    11: 1.615\n",
      "Loss after mini-batch    21: 0.252\n",
      "Loss after mini-batch    31: 0.608\n",
      "Loss after mini-batch    41: 1.242\n",
      "Loss after mini-batch    51: 0.389\n",
      "Loss after mini-batch    61: 0.555\n",
      "Loss after mini-batch    71: 0.977\n",
      "Loss after mini-batch    81: 4.964\n",
      "Loss after mini-batch    91: 0.025\n",
      "Loss after mini-batch   101: 1.647\n",
      "Loss after mini-batch   111: 0.247\n",
      "Loss after mini-batch   121: 0.025\n",
      "Loss after mini-batch   131: 1.476\n",
      "Loss after mini-batch   141: 0.784\n",
      "Loss after mini-batch   151: 0.400\n",
      "Loss after mini-batch   161: 0.344\n",
      "Loss after mini-batch   171: 2.140\n",
      "Loss after mini-batch   181: 0.178\n",
      "Loss after mini-batch   191: 0.122\n",
      "Loss after mini-batch   201: 0.185\n",
      "Loss after mini-batch   211: 0.161\n",
      "Loss after mini-batch   221: 0.120\n",
      "Loss after mini-batch   231: 2.580\n",
      "Loss after mini-batch   241: 4.686\n",
      "Loss after mini-batch   251: 1.274\n",
      "Loss after mini-batch   261: 0.383\n",
      "Loss after mini-batch   271: 0.176\n",
      "Loss after mini-batch   281: 5.687\n",
      "Loss after mini-batch   291: 1.810\n",
      "Loss after mini-batch   301: 1.885\n",
      "Loss after mini-batch   311: 0.105\n",
      "Loss after mini-batch   321: 2.194\n",
      "Loss after mini-batch   331: 2.647\n",
      "Loss after mini-batch   341: 0.935\n",
      "Loss after mini-batch   351: 5.848\n",
      "Loss after mini-batch   361: 0.135\n",
      "Loss after mini-batch   371: 0.310\n",
      "Training Loss: 0.089 \t\t Validation Loss:1.147\n",
      "Starting epoch 194\n",
      "Loss after mini-batch     1: 1.320\n",
      "Loss after mini-batch    11: 0.290\n",
      "Loss after mini-batch    21: 4.658\n",
      "Loss after mini-batch    31: 0.194\n",
      "Loss after mini-batch    41: 5.775\n",
      "Loss after mini-batch    51: 0.479\n",
      "Loss after mini-batch    61: 6.592\n",
      "Loss after mini-batch    71: 3.281\n",
      "Loss after mini-batch    81: 0.231\n",
      "Loss after mini-batch    91: 0.378\n",
      "Loss after mini-batch   101: 1.374\n",
      "Loss after mini-batch   111: 0.072\n",
      "Loss after mini-batch   121: 1.455\n",
      "Loss after mini-batch   131: 0.206\n",
      "Loss after mini-batch   141: 1.531\n",
      "Loss after mini-batch   151: 0.035\n",
      "Loss after mini-batch   161: 2.829\n",
      "Loss after mini-batch   171: 0.053\n",
      "Loss after mini-batch   181: 0.292\n",
      "Loss after mini-batch   191: 0.307\n",
      "Loss after mini-batch   201: 0.391\n",
      "Loss after mini-batch   211: 1.464\n",
      "Loss after mini-batch   221: 8.416\n",
      "Loss after mini-batch   231: 0.824\n",
      "Loss after mini-batch   241: 0.358\n",
      "Loss after mini-batch   251: 0.045\n",
      "Loss after mini-batch   261: 0.041\n",
      "Loss after mini-batch   271: 3.804\n",
      "Loss after mini-batch   281: 0.137\n",
      "Loss after mini-batch   291: 0.632\n",
      "Loss after mini-batch   301: 0.033\n",
      "Loss after mini-batch   311: 0.958\n",
      "Loss after mini-batch   321: 3.505\n",
      "Loss after mini-batch   331: 6.451\n",
      "Loss after mini-batch   341: 0.436\n",
      "Loss after mini-batch   351: 0.624\n",
      "Loss after mini-batch   361: 3.726\n",
      "Loss after mini-batch   371: 0.364\n",
      "Training Loss: 1.660 \t\t Validation Loss:1.829\n",
      "Starting epoch 195\n",
      "Loss after mini-batch     1: 0.092\n",
      "Loss after mini-batch    11: 0.558\n",
      "Loss after mini-batch    21: 0.682\n",
      "Loss after mini-batch    31: 5.706\n",
      "Loss after mini-batch    41: 0.044\n",
      "Loss after mini-batch    51: 0.364\n",
      "Loss after mini-batch    61: 1.639\n",
      "Loss after mini-batch    71: 0.070\n",
      "Loss after mini-batch    81: 0.072\n",
      "Loss after mini-batch    91: 0.203\n",
      "Loss after mini-batch   101: 0.488\n",
      "Loss after mini-batch   111: 1.797\n",
      "Loss after mini-batch   121: 0.147\n",
      "Loss after mini-batch   131: 1.202\n",
      "Loss after mini-batch   141: 0.849\n",
      "Loss after mini-batch   151: 1.386\n",
      "Loss after mini-batch   161: 0.493\n",
      "Loss after mini-batch   171: 0.057\n",
      "Loss after mini-batch   181: 6.008\n",
      "Loss after mini-batch   191: 2.052\n",
      "Loss after mini-batch   201: 0.456\n",
      "Loss after mini-batch   211: 1.016\n",
      "Loss after mini-batch   221: 0.745\n",
      "Loss after mini-batch   231: 1.899\n",
      "Loss after mini-batch   241: 2.105\n",
      "Loss after mini-batch   251: 2.649\n",
      "Loss after mini-batch   261: 0.335\n",
      "Loss after mini-batch   271: 5.699\n",
      "Loss after mini-batch   281: 0.385\n",
      "Loss after mini-batch   291: 1.732\n",
      "Loss after mini-batch   301: 0.044\n",
      "Loss after mini-batch   311: 3.135\n",
      "Loss after mini-batch   321: 0.310\n",
      "Loss after mini-batch   331: 2.336\n",
      "Loss after mini-batch   341: 0.226\n",
      "Loss after mini-batch   351: 0.750\n",
      "Loss after mini-batch   361: 0.120\n",
      "Loss after mini-batch   371: 0.059\n",
      "Training Loss: 0.088 \t\t Validation Loss:0.395\n",
      "Starting epoch 196\n",
      "Loss after mini-batch     1: 1.541\n",
      "Loss after mini-batch    11: 4.919\n",
      "Loss after mini-batch    21: 3.331\n",
      "Loss after mini-batch    31: 1.559\n",
      "Loss after mini-batch    41: 2.865\n",
      "Loss after mini-batch    51: 1.477\n",
      "Loss after mini-batch    61: 0.286\n",
      "Loss after mini-batch    71: 4.197\n",
      "Loss after mini-batch    81: 0.266\n",
      "Loss after mini-batch    91: 1.233\n",
      "Loss after mini-batch   101: 0.324\n",
      "Loss after mini-batch   111: 1.211\n",
      "Loss after mini-batch   121: 1.876\n",
      "Loss after mini-batch   131: 0.078\n",
      "Loss after mini-batch   141: 0.298\n",
      "Loss after mini-batch   151: 0.566\n",
      "Loss after mini-batch   161: 8.628\n",
      "Loss after mini-batch   171: 1.721\n",
      "Loss after mini-batch   181: 4.142\n",
      "Loss after mini-batch   191: 0.951\n",
      "Loss after mini-batch   201: 2.153\n",
      "Loss after mini-batch   211: 2.878\n",
      "Loss after mini-batch   221: 1.326\n",
      "Loss after mini-batch   231: 1.700\n",
      "Loss after mini-batch   241: 0.526\n",
      "Loss after mini-batch   251: 0.180\n",
      "Loss after mini-batch   261: 1.114\n",
      "Loss after mini-batch   271: 0.946\n",
      "Loss after mini-batch   281: 1.274\n",
      "Loss after mini-batch   291: 0.697\n",
      "Loss after mini-batch   301: 0.081\n",
      "Loss after mini-batch   311: 0.317\n",
      "Loss after mini-batch   321: 5.134\n",
      "Loss after mini-batch   331: 1.581\n",
      "Loss after mini-batch   341: 0.123\n",
      "Loss after mini-batch   351: 0.589\n",
      "Loss after mini-batch   361: 0.060\n",
      "Loss after mini-batch   371: 0.188\n",
      "Training Loss: 0.645 \t\t Validation Loss:2.685\n",
      "Starting epoch 197\n",
      "Loss after mini-batch     1: 0.571\n",
      "Loss after mini-batch    11: 7.131\n",
      "Loss after mini-batch    21: 9.737\n",
      "Loss after mini-batch    31: 0.729\n",
      "Loss after mini-batch    41: 0.014\n",
      "Loss after mini-batch    51: 0.018\n",
      "Loss after mini-batch    61: 7.300\n",
      "Loss after mini-batch    71: 1.115\n",
      "Loss after mini-batch    81: 0.128\n",
      "Loss after mini-batch    91: 0.233\n",
      "Loss after mini-batch   101: 0.604\n",
      "Loss after mini-batch   111: 0.833\n",
      "Loss after mini-batch   121: 0.170\n",
      "Loss after mini-batch   131: 1.046\n",
      "Loss after mini-batch   141: 0.619\n",
      "Loss after mini-batch   151: 0.143\n",
      "Loss after mini-batch   161: 0.115\n",
      "Loss after mini-batch   171: 6.002\n",
      "Loss after mini-batch   181: 1.224\n",
      "Loss after mini-batch   191: 2.161\n",
      "Loss after mini-batch   201: 0.949\n",
      "Loss after mini-batch   211: 0.121\n",
      "Loss after mini-batch   221: 1.546\n",
      "Loss after mini-batch   231: 0.749\n",
      "Loss after mini-batch   241: 2.830\n",
      "Loss after mini-batch   251: 1.361\n",
      "Loss after mini-batch   261: 5.029\n",
      "Loss after mini-batch   271: 0.116\n",
      "Loss after mini-batch   281: 1.781\n",
      "Loss after mini-batch   291: 0.585\n",
      "Loss after mini-batch   301: 0.305\n",
      "Loss after mini-batch   311: 2.583\n",
      "Loss after mini-batch   321: 0.270\n",
      "Loss after mini-batch   331: 0.114\n",
      "Loss after mini-batch   341: 1.279\n",
      "Loss after mini-batch   351: 1.808\n",
      "Loss after mini-batch   361: 1.012\n",
      "Loss after mini-batch   371: 4.563\n",
      "Training Loss: 1.583 \t\t Validation Loss:5.792\n",
      "Starting epoch 198\n",
      "Loss after mini-batch     1: 0.043\n",
      "Loss after mini-batch    11: 0.345\n",
      "Loss after mini-batch    21: 0.553\n",
      "Loss after mini-batch    31: 1.429\n",
      "Loss after mini-batch    41: 0.061\n",
      "Loss after mini-batch    51: 1.059\n",
      "Loss after mini-batch    61: 0.125\n",
      "Loss after mini-batch    71: 0.169\n",
      "Loss after mini-batch    81: 0.224\n",
      "Loss after mini-batch    91: 0.029\n",
      "Loss after mini-batch   101: 1.264\n",
      "Loss after mini-batch   111: 0.716\n",
      "Loss after mini-batch   121: 0.186\n",
      "Loss after mini-batch   131: 0.105\n",
      "Loss after mini-batch   141: 6.554\n",
      "Loss after mini-batch   151: 3.036\n",
      "Loss after mini-batch   161: 0.276\n",
      "Loss after mini-batch   171: 0.145\n",
      "Loss after mini-batch   181: 0.125\n",
      "Loss after mini-batch   191: 0.103\n",
      "Loss after mini-batch   201: 0.050\n",
      "Loss after mini-batch   211: 1.377\n",
      "Loss after mini-batch   221: 2.337\n",
      "Loss after mini-batch   231: 0.234\n",
      "Loss after mini-batch   241: 0.921\n",
      "Loss after mini-batch   251: 0.412\n",
      "Loss after mini-batch   261: 0.104\n",
      "Loss after mini-batch   271: 0.782\n",
      "Loss after mini-batch   281: 0.190\n",
      "Loss after mini-batch   291: 1.227\n",
      "Loss after mini-batch   301: 0.088\n",
      "Loss after mini-batch   311: 2.915\n",
      "Loss after mini-batch   321: 0.133\n",
      "Loss after mini-batch   331: 0.156\n",
      "Loss after mini-batch   341: 1.311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   351: 0.040\n",
      "Loss after mini-batch   361: 0.205\n",
      "Loss after mini-batch   371: 0.527\n",
      "Training Loss: 1.699 \t\t Validation Loss:1.881\n",
      "Starting epoch 199\n",
      "Loss after mini-batch     1: 2.333\n",
      "Loss after mini-batch    11: 1.380\n",
      "Loss after mini-batch    21: 0.234\n",
      "Loss after mini-batch    31: 0.140\n",
      "Loss after mini-batch    41: 0.678\n",
      "Loss after mini-batch    51: 0.125\n",
      "Loss after mini-batch    61: 0.273\n",
      "Loss after mini-batch    71: 0.018\n",
      "Loss after mini-batch    81: 0.444\n",
      "Loss after mini-batch    91: 0.963\n",
      "Loss after mini-batch   101: 2.160\n",
      "Loss after mini-batch   111: 1.700\n",
      "Loss after mini-batch   121: 0.100\n",
      "Loss after mini-batch   131: 2.101\n",
      "Loss after mini-batch   141: 0.332\n",
      "Loss after mini-batch   151: 0.657\n",
      "Loss after mini-batch   161: 7.990\n",
      "Loss after mini-batch   171: 0.130\n",
      "Loss after mini-batch   181: 4.617\n",
      "Loss after mini-batch   191: 0.733\n",
      "Loss after mini-batch   201: 0.885\n",
      "Loss after mini-batch   211: 0.045\n",
      "Loss after mini-batch   221: 0.092\n",
      "Loss after mini-batch   231: 0.204\n",
      "Loss after mini-batch   241: 0.208\n",
      "Loss after mini-batch   251: 1.124\n",
      "Loss after mini-batch   261: 0.004\n",
      "Loss after mini-batch   271: 0.618\n",
      "Loss after mini-batch   281: 0.157\n",
      "Loss after mini-batch   291: 1.249\n",
      "Loss after mini-batch   301: 15.907\n",
      "Loss after mini-batch   311: 5.569\n",
      "Loss after mini-batch   321: 1.139\n",
      "Loss after mini-batch   331: 5.032\n",
      "Loss after mini-batch   341: 1.185\n",
      "Loss after mini-batch   351: 0.123\n",
      "Loss after mini-batch   361: 1.879\n",
      "Loss after mini-batch   371: 0.110\n",
      "Training Loss: 0.687 \t\t Validation Loss:1.928\n",
      "Starting epoch 200\n",
      "Loss after mini-batch     1: 0.184\n",
      "Loss after mini-batch    11: 0.097\n",
      "Loss after mini-batch    21: 1.596\n",
      "Loss after mini-batch    31: 0.081\n",
      "Loss after mini-batch    41: 1.592\n",
      "Loss after mini-batch    51: 1.687\n",
      "Loss after mini-batch    61: 0.110\n",
      "Loss after mini-batch    71: 0.706\n",
      "Loss after mini-batch    81: 1.864\n",
      "Loss after mini-batch    91: 2.886\n",
      "Loss after mini-batch   101: 0.201\n",
      "Loss after mini-batch   111: 0.096\n",
      "Loss after mini-batch   121: 0.033\n",
      "Loss after mini-batch   131: 1.448\n",
      "Loss after mini-batch   141: 0.387\n",
      "Loss after mini-batch   151: 0.461\n",
      "Loss after mini-batch   161: 2.053\n",
      "Loss after mini-batch   171: 0.195\n",
      "Loss after mini-batch   181: 1.113\n",
      "Loss after mini-batch   191: 0.042\n",
      "Loss after mini-batch   201: 1.056\n",
      "Loss after mini-batch   211: 0.423\n",
      "Loss after mini-batch   221: 0.071\n",
      "Loss after mini-batch   231: 0.671\n",
      "Loss after mini-batch   241: 0.316\n",
      "Loss after mini-batch   251: 2.717\n",
      "Loss after mini-batch   261: 0.042\n",
      "Loss after mini-batch   271: 3.892\n",
      "Loss after mini-batch   281: 1.235\n",
      "Loss after mini-batch   291: 7.323\n",
      "Loss after mini-batch   301: 1.037\n",
      "Loss after mini-batch   311: 0.006\n",
      "Loss after mini-batch   321: 4.475\n",
      "Loss after mini-batch   331: 4.484\n",
      "Loss after mini-batch   341: 0.242\n",
      "Loss after mini-batch   351: 2.302\n",
      "Loss after mini-batch   361: 0.197\n",
      "Loss after mini-batch   371: 0.670\n",
      "Training Loss: 1.389 \t\t Validation Loss:1.421\n",
      "Starting epoch 201\n",
      "Loss after mini-batch     1: 5.128\n",
      "Loss after mini-batch    11: 2.987\n",
      "Loss after mini-batch    21: 0.080\n",
      "Loss after mini-batch    31: 0.007\n",
      "Loss after mini-batch    41: 2.307\n",
      "Loss after mini-batch    51: 0.578\n",
      "Loss after mini-batch    61: 0.632\n",
      "Loss after mini-batch    71: 0.063\n",
      "Loss after mini-batch    81: 0.447\n",
      "Loss after mini-batch    91: 0.443\n",
      "Loss after mini-batch   101: 0.606\n",
      "Loss after mini-batch   111: 0.529\n",
      "Loss after mini-batch   121: 0.166\n",
      "Loss after mini-batch   131: 0.954\n",
      "Loss after mini-batch   141: 0.463\n",
      "Loss after mini-batch   151: 2.249\n",
      "Loss after mini-batch   161: 0.229\n",
      "Loss after mini-batch   171: 1.679\n",
      "Loss after mini-batch   181: 0.004\n",
      "Loss after mini-batch   191: 0.030\n",
      "Loss after mini-batch   201: 4.699\n",
      "Loss after mini-batch   211: 0.376\n",
      "Loss after mini-batch   221: 0.065\n",
      "Loss after mini-batch   231: 0.073\n",
      "Loss after mini-batch   241: 1.452\n",
      "Loss after mini-batch   251: 0.080\n",
      "Loss after mini-batch   261: 1.374\n",
      "Loss after mini-batch   271: 6.648\n",
      "Loss after mini-batch   281: 0.336\n",
      "Loss after mini-batch   291: 2.964\n",
      "Loss after mini-batch   301: 1.209\n",
      "Loss after mini-batch   311: 0.350\n",
      "Loss after mini-batch   321: 0.280\n",
      "Loss after mini-batch   331: 0.362\n",
      "Loss after mini-batch   341: 4.184\n",
      "Loss after mini-batch   351: 0.410\n",
      "Loss after mini-batch   361: 0.103\n",
      "Loss after mini-batch   371: 2.861\n",
      "Training Loss: 1.169 \t\t Validation Loss:1.352\n",
      "Starting epoch 202\n",
      "Loss after mini-batch     1: 0.051\n",
      "Loss after mini-batch    11: 1.373\n",
      "Loss after mini-batch    21: 4.417\n",
      "Loss after mini-batch    31: 1.620\n",
      "Loss after mini-batch    41: 0.062\n",
      "Loss after mini-batch    51: 0.133\n",
      "Loss after mini-batch    61: 0.100\n",
      "Loss after mini-batch    71: 1.197\n",
      "Loss after mini-batch    81: 1.351\n",
      "Loss after mini-batch    91: 0.676\n",
      "Loss after mini-batch   101: 0.242\n",
      "Loss after mini-batch   111: 0.613\n",
      "Loss after mini-batch   121: 0.172\n",
      "Loss after mini-batch   131: 1.787\n",
      "Loss after mini-batch   141: 0.417\n",
      "Loss after mini-batch   151: 0.252\n",
      "Loss after mini-batch   161: 0.185\n",
      "Loss after mini-batch   171: 0.113\n",
      "Loss after mini-batch   181: 13.249\n",
      "Loss after mini-batch   191: 1.026\n",
      "Loss after mini-batch   201: 1.164\n",
      "Loss after mini-batch   211: 1.084\n",
      "Loss after mini-batch   221: 0.026\n",
      "Loss after mini-batch   231: 0.104\n",
      "Loss after mini-batch   241: 1.965\n",
      "Loss after mini-batch   251: 1.989\n",
      "Loss after mini-batch   261: 1.685\n",
      "Loss after mini-batch   271: 2.878\n",
      "Loss after mini-batch   281: 0.700\n",
      "Loss after mini-batch   291: 2.772\n",
      "Loss after mini-batch   301: 14.554\n",
      "Loss after mini-batch   311: 0.458\n",
      "Loss after mini-batch   321: 0.060\n",
      "Loss after mini-batch   331: 1.531\n",
      "Loss after mini-batch   341: 3.109\n",
      "Loss after mini-batch   351: 2.448\n",
      "Loss after mini-batch   361: 1.857\n",
      "Loss after mini-batch   371: 6.636\n",
      "Training Loss: 6.203 \t\t Validation Loss:6.293\n",
      "Starting epoch 203\n",
      "Loss after mini-batch     1: 0.601\n",
      "Loss after mini-batch    11: 1.035\n",
      "Loss after mini-batch    21: 10.566\n",
      "Loss after mini-batch    31: 0.201\n",
      "Loss after mini-batch    41: 0.383\n",
      "Loss after mini-batch    51: 1.755\n",
      "Loss after mini-batch    61: 0.306\n",
      "Loss after mini-batch    71: 0.392\n",
      "Loss after mini-batch    81: 1.545\n",
      "Loss after mini-batch    91: 2.158\n",
      "Loss after mini-batch   101: 0.334\n",
      "Loss after mini-batch   111: 6.130\n",
      "Loss after mini-batch   121: 2.451\n",
      "Loss after mini-batch   131: 1.196\n",
      "Loss after mini-batch   141: 1.720\n",
      "Loss after mini-batch   151: 0.048\n",
      "Loss after mini-batch   161: 0.137\n",
      "Loss after mini-batch   171: 2.953\n",
      "Loss after mini-batch   181: 0.309\n",
      "Loss after mini-batch   191: 0.245\n",
      "Loss after mini-batch   201: 0.723\n",
      "Loss after mini-batch   211: 0.056\n",
      "Loss after mini-batch   221: 0.105\n",
      "Loss after mini-batch   231: 0.325\n",
      "Loss after mini-batch   241: 0.082\n",
      "Loss after mini-batch   251: 0.361\n",
      "Loss after mini-batch   261: 4.303\n",
      "Loss after mini-batch   271: 0.555\n",
      "Loss after mini-batch   281: 5.366\n",
      "Loss after mini-batch   291: 0.865\n",
      "Loss after mini-batch   301: 0.905\n",
      "Loss after mini-batch   311: 2.541\n",
      "Loss after mini-batch   321: 0.129\n",
      "Loss after mini-batch   331: 0.185\n",
      "Loss after mini-batch   341: 0.219\n",
      "Loss after mini-batch   351: 1.332\n",
      "Loss after mini-batch   361: 8.259\n",
      "Loss after mini-batch   371: 0.173\n",
      "Training Loss: 0.197 \t\t Validation Loss:2.476\n",
      "Starting epoch 204\n",
      "Loss after mini-batch     1: 0.071\n",
      "Loss after mini-batch    11: 0.601\n",
      "Loss after mini-batch    21: 0.575\n",
      "Loss after mini-batch    31: 0.074\n",
      "Loss after mini-batch    41: 0.314\n",
      "Loss after mini-batch    51: 0.130\n",
      "Loss after mini-batch    61: 2.308\n",
      "Loss after mini-batch    71: 2.016\n",
      "Loss after mini-batch    81: 0.294\n",
      "Loss after mini-batch    91: 2.079\n",
      "Loss after mini-batch   101: 0.550\n",
      "Loss after mini-batch   111: 6.004\n",
      "Loss after mini-batch   121: 0.324\n",
      "Loss after mini-batch   131: 0.850\n",
      "Loss after mini-batch   141: 1.906\n",
      "Loss after mini-batch   151: 0.047\n",
      "Loss after mini-batch   161: 0.105\n",
      "Loss after mini-batch   171: 0.371\n",
      "Loss after mini-batch   181: 0.230\n",
      "Loss after mini-batch   191: 0.117\n",
      "Loss after mini-batch   201: 6.969\n",
      "Loss after mini-batch   211: 0.083\n",
      "Loss after mini-batch   221: 0.133\n",
      "Loss after mini-batch   231: 1.327\n",
      "Loss after mini-batch   241: 0.114\n",
      "Loss after mini-batch   251: 0.558\n",
      "Loss after mini-batch   261: 3.230\n",
      "Loss after mini-batch   271: 0.041\n",
      "Loss after mini-batch   281: 4.909\n",
      "Loss after mini-batch   291: 2.187\n",
      "Loss after mini-batch   301: 0.780\n",
      "Loss after mini-batch   311: 1.854\n",
      "Loss after mini-batch   321: 1.487\n",
      "Loss after mini-batch   331: 7.169\n",
      "Loss after mini-batch   341: 0.476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   351: 1.521\n",
      "Loss after mini-batch   361: 0.739\n",
      "Loss after mini-batch   371: 0.067\n",
      "Training Loss: 1.222 \t\t Validation Loss:2.107\n",
      "Starting epoch 205\n",
      "Loss after mini-batch     1: 0.500\n",
      "Loss after mini-batch    11: 0.577\n",
      "Loss after mini-batch    21: 1.016\n",
      "Loss after mini-batch    31: 0.968\n",
      "Loss after mini-batch    41: 0.873\n",
      "Loss after mini-batch    51: 0.072\n",
      "Loss after mini-batch    61: 0.275\n",
      "Loss after mini-batch    71: 0.581\n",
      "Loss after mini-batch    81: 0.018\n",
      "Loss after mini-batch    91: 20.497\n",
      "Loss after mini-batch   101: 5.264\n",
      "Loss after mini-batch   111: 0.129\n",
      "Loss after mini-batch   121: 1.802\n",
      "Loss after mini-batch   131: 0.141\n",
      "Loss after mini-batch   141: 0.441\n",
      "Loss after mini-batch   151: 0.524\n",
      "Loss after mini-batch   161: 5.611\n",
      "Loss after mini-batch   171: 0.024\n",
      "Loss after mini-batch   181: 8.499\n",
      "Loss after mini-batch   191: 0.117\n",
      "Loss after mini-batch   201: 4.455\n",
      "Loss after mini-batch   211: 2.191\n",
      "Loss after mini-batch   221: 1.511\n",
      "Loss after mini-batch   231: 0.090\n",
      "Loss after mini-batch   241: 0.208\n",
      "Loss after mini-batch   251: 0.889\n",
      "Loss after mini-batch   261: 2.033\n",
      "Loss after mini-batch   271: 2.108\n",
      "Loss after mini-batch   281: 0.171\n",
      "Loss after mini-batch   291: 3.980\n",
      "Loss after mini-batch   301: 6.063\n",
      "Loss after mini-batch   311: 0.038\n",
      "Loss after mini-batch   321: 0.075\n",
      "Loss after mini-batch   331: 1.202\n",
      "Loss after mini-batch   341: 0.062\n",
      "Loss after mini-batch   351: 15.573\n",
      "Loss after mini-batch   361: 0.215\n",
      "Loss after mini-batch   371: 0.938\n",
      "Training Loss: 0.778 \t\t Validation Loss:1.913\n",
      "Starting epoch 206\n",
      "Loss after mini-batch     1: 1.303\n",
      "Loss after mini-batch    11: 1.836\n",
      "Loss after mini-batch    21: 0.379\n",
      "Loss after mini-batch    31: 0.279\n",
      "Loss after mini-batch    41: 2.772\n",
      "Loss after mini-batch    51: 0.182\n",
      "Loss after mini-batch    61: 0.757\n",
      "Loss after mini-batch    71: 1.203\n",
      "Loss after mini-batch    81: 6.069\n",
      "Loss after mini-batch    91: 1.248\n",
      "Loss after mini-batch   101: 0.436\n",
      "Loss after mini-batch   111: 0.996\n",
      "Loss after mini-batch   121: 0.796\n",
      "Loss after mini-batch   131: 1.160\n",
      "Loss after mini-batch   141: 0.673\n",
      "Loss after mini-batch   151: 0.009\n",
      "Loss after mini-batch   161: 0.179\n",
      "Loss after mini-batch   171: 0.199\n",
      "Loss after mini-batch   181: 0.151\n",
      "Loss after mini-batch   191: 1.045\n",
      "Loss after mini-batch   201: 0.064\n",
      "Loss after mini-batch   211: 0.326\n",
      "Loss after mini-batch   221: 1.847\n",
      "Loss after mini-batch   231: 3.689\n",
      "Loss after mini-batch   241: 5.742\n",
      "Loss after mini-batch   251: 0.523\n",
      "Loss after mini-batch   261: 0.147\n",
      "Loss after mini-batch   271: 0.054\n",
      "Loss after mini-batch   281: 4.368\n",
      "Loss after mini-batch   291: 3.056\n",
      "Loss after mini-batch   301: 0.089\n",
      "Loss after mini-batch   311: 1.655\n",
      "Loss after mini-batch   321: 3.675\n",
      "Loss after mini-batch   331: 0.077\n",
      "Loss after mini-batch   341: 0.053\n",
      "Loss after mini-batch   351: 0.512\n",
      "Loss after mini-batch   361: 0.069\n",
      "Loss after mini-batch   371: 2.463\n",
      "Training Loss: 0.705 \t\t Validation Loss:1.732\n",
      "Starting epoch 207\n",
      "Loss after mini-batch     1: 0.163\n",
      "Loss after mini-batch    11: 1.705\n",
      "Loss after mini-batch    21: 1.576\n",
      "Loss after mini-batch    31: 0.751\n",
      "Loss after mini-batch    41: 1.387\n",
      "Loss after mini-batch    51: 0.248\n",
      "Loss after mini-batch    61: 1.670\n",
      "Loss after mini-batch    71: 1.155\n",
      "Loss after mini-batch    81: 2.154\n",
      "Loss after mini-batch    91: 0.036\n",
      "Loss after mini-batch   101: 1.218\n",
      "Loss after mini-batch   111: 0.060\n",
      "Loss after mini-batch   121: 1.370\n",
      "Loss after mini-batch   131: 0.088\n",
      "Loss after mini-batch   141: 0.094\n",
      "Loss after mini-batch   151: 0.290\n",
      "Loss after mini-batch   161: 0.126\n",
      "Loss after mini-batch   171: 0.997\n",
      "Loss after mini-batch   181: 0.225\n",
      "Loss after mini-batch   191: 7.272\n",
      "Loss after mini-batch   201: 0.036\n",
      "Loss after mini-batch   211: 0.185\n",
      "Loss after mini-batch   221: 2.547\n",
      "Loss after mini-batch   231: 0.368\n",
      "Loss after mini-batch   241: 1.400\n",
      "Loss after mini-batch   251: 0.260\n",
      "Loss after mini-batch   261: 2.664\n",
      "Loss after mini-batch   271: 0.119\n",
      "Loss after mini-batch   281: 0.036\n",
      "Loss after mini-batch   291: 1.228\n",
      "Loss after mini-batch   301: 0.385\n",
      "Loss after mini-batch   311: 0.017\n",
      "Loss after mini-batch   321: 0.203\n",
      "Loss after mini-batch   331: 4.320\n",
      "Loss after mini-batch   341: 5.451\n",
      "Loss after mini-batch   351: 3.155\n",
      "Loss after mini-batch   361: 1.946\n",
      "Loss after mini-batch   371: 0.445\n",
      "Training Loss: 3.385 \t\t Validation Loss:10.832\n",
      "Starting epoch 208\n",
      "Loss after mini-batch     1: 0.395\n",
      "Loss after mini-batch    11: 0.211\n",
      "Loss after mini-batch    21: 0.903\n",
      "Loss after mini-batch    31: 0.343\n",
      "Loss after mini-batch    41: 0.460\n",
      "Loss after mini-batch    51: 0.381\n",
      "Loss after mini-batch    61: 0.333\n",
      "Loss after mini-batch    71: 1.486\n",
      "Loss after mini-batch    81: 5.364\n",
      "Loss after mini-batch    91: 0.658\n",
      "Loss after mini-batch   101: 1.770\n",
      "Loss after mini-batch   111: 28.266\n",
      "Loss after mini-batch   121: 0.154\n",
      "Loss after mini-batch   131: 0.738\n",
      "Loss after mini-batch   141: 0.080\n",
      "Loss after mini-batch   151: 0.118\n",
      "Loss after mini-batch   161: 0.334\n",
      "Loss after mini-batch   171: 1.390\n",
      "Loss after mini-batch   181: 1.156\n",
      "Loss after mini-batch   191: 1.635\n",
      "Loss after mini-batch   201: 0.871\n",
      "Loss after mini-batch   211: 8.398\n",
      "Loss after mini-batch   221: 0.410\n",
      "Loss after mini-batch   231: 9.178\n",
      "Loss after mini-batch   241: 0.197\n",
      "Loss after mini-batch   251: 0.458\n",
      "Loss after mini-batch   261: 1.517\n",
      "Loss after mini-batch   271: 0.530\n",
      "Loss after mini-batch   281: 1.202\n",
      "Loss after mini-batch   291: 0.130\n",
      "Loss after mini-batch   301: 0.269\n",
      "Loss after mini-batch   311: 0.119\n",
      "Loss after mini-batch   321: 0.106\n",
      "Loss after mini-batch   331: 3.608\n",
      "Loss after mini-batch   341: 0.377\n",
      "Loss after mini-batch   351: 0.459\n",
      "Loss after mini-batch   361: 0.300\n",
      "Loss after mini-batch   371: 2.157\n",
      "Training Loss: 0.634 \t\t Validation Loss:0.730\n",
      "Starting epoch 209\n",
      "Loss after mini-batch     1: 0.204\n",
      "Loss after mini-batch    11: 0.603\n",
      "Loss after mini-batch    21: 0.177\n",
      "Loss after mini-batch    31: 0.567\n",
      "Loss after mini-batch    41: 1.706\n",
      "Loss after mini-batch    51: 2.659\n",
      "Loss after mini-batch    61: 0.440\n",
      "Loss after mini-batch    71: 0.885\n",
      "Loss after mini-batch    81: 1.802\n",
      "Loss after mini-batch    91: 0.229\n",
      "Loss after mini-batch   101: 2.347\n",
      "Loss after mini-batch   111: 1.899\n",
      "Loss after mini-batch   121: 0.145\n",
      "Loss after mini-batch   131: 0.315\n",
      "Loss after mini-batch   141: 1.384\n",
      "Loss after mini-batch   151: 1.471\n",
      "Loss after mini-batch   161: 1.236\n",
      "Loss after mini-batch   171: 11.057\n",
      "Loss after mini-batch   181: 0.045\n",
      "Loss after mini-batch   191: 0.132\n",
      "Loss after mini-batch   201: 1.201\n",
      "Loss after mini-batch   211: 0.042\n",
      "Loss after mini-batch   221: 6.605\n",
      "Loss after mini-batch   231: 0.738\n",
      "Loss after mini-batch   241: 0.180\n",
      "Loss after mini-batch   251: 0.022\n",
      "Loss after mini-batch   261: 8.825\n",
      "Loss after mini-batch   271: 0.536\n",
      "Loss after mini-batch   281: 1.574\n",
      "Loss after mini-batch   291: 0.549\n",
      "Loss after mini-batch   301: 0.359\n",
      "Loss after mini-batch   311: 0.191\n",
      "Loss after mini-batch   321: 0.049\n",
      "Loss after mini-batch   331: 0.940\n",
      "Loss after mini-batch   341: 1.445\n",
      "Loss after mini-batch   351: 0.932\n",
      "Loss after mini-batch   361: 0.191\n",
      "Loss after mini-batch   371: 0.899\n",
      "Training Loss: 0.570 \t\t Validation Loss:0.964\n",
      "Starting epoch 210\n",
      "Loss after mini-batch     1: 4.453\n",
      "Loss after mini-batch    11: 0.993\n",
      "Loss after mini-batch    21: 0.459\n",
      "Loss after mini-batch    31: 0.114\n",
      "Loss after mini-batch    41: 7.415\n",
      "Loss after mini-batch    51: 0.076\n",
      "Loss after mini-batch    61: 5.445\n",
      "Loss after mini-batch    71: 2.216\n",
      "Loss after mini-batch    81: 1.161\n",
      "Loss after mini-batch    91: 1.486\n",
      "Loss after mini-batch   101: 0.099\n",
      "Loss after mini-batch   111: 0.112\n",
      "Loss after mini-batch   121: 0.278\n",
      "Loss after mini-batch   131: 0.215\n",
      "Loss after mini-batch   141: 0.299\n",
      "Loss after mini-batch   151: 0.320\n",
      "Loss after mini-batch   161: 8.333\n",
      "Loss after mini-batch   171: 0.399\n",
      "Loss after mini-batch   181: 4.203\n",
      "Loss after mini-batch   191: 0.785\n",
      "Loss after mini-batch   201: 0.784\n",
      "Loss after mini-batch   211: 0.327\n",
      "Loss after mini-batch   221: 1.021\n",
      "Loss after mini-batch   231: 0.248\n",
      "Loss after mini-batch   241: 0.164\n",
      "Loss after mini-batch   251: 4.128\n",
      "Loss after mini-batch   261: 0.914\n",
      "Loss after mini-batch   271: 0.132\n",
      "Loss after mini-batch   281: 0.089\n",
      "Loss after mini-batch   291: 0.049\n",
      "Loss after mini-batch   301: 0.840\n",
      "Loss after mini-batch   311: 0.372\n",
      "Loss after mini-batch   321: 0.116\n",
      "Loss after mini-batch   331: 2.720\n",
      "Loss after mini-batch   341: 8.092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   351: 0.184\n",
      "Loss after mini-batch   361: 2.568\n",
      "Loss after mini-batch   371: 0.242\n",
      "Training Loss: 0.056 \t\t Validation Loss:0.361\n",
      "Starting epoch 211\n",
      "Loss after mini-batch     1: 0.841\n",
      "Loss after mini-batch    11: 0.149\n",
      "Loss after mini-batch    21: 2.586\n",
      "Loss after mini-batch    31: 0.041\n",
      "Loss after mini-batch    41: 0.218\n",
      "Loss after mini-batch    51: 0.270\n",
      "Loss after mini-batch    61: 2.372\n",
      "Loss after mini-batch    71: 0.298\n",
      "Loss after mini-batch    81: 4.231\n",
      "Loss after mini-batch    91: 1.524\n",
      "Loss after mini-batch   101: 0.132\n",
      "Loss after mini-batch   111: 1.066\n",
      "Loss after mini-batch   121: 0.549\n",
      "Loss after mini-batch   131: 0.050\n",
      "Loss after mini-batch   141: 0.985\n",
      "Loss after mini-batch   151: 1.852\n",
      "Loss after mini-batch   161: 1.729\n",
      "Loss after mini-batch   171: 0.225\n",
      "Loss after mini-batch   181: 0.246\n",
      "Loss after mini-batch   191: 1.127\n",
      "Loss after mini-batch   201: 0.086\n",
      "Loss after mini-batch   211: 0.040\n",
      "Loss after mini-batch   221: 2.537\n",
      "Loss after mini-batch   231: 0.506\n",
      "Loss after mini-batch   241: 1.619\n",
      "Loss after mini-batch   251: 2.795\n",
      "Loss after mini-batch   261: 0.230\n",
      "Loss after mini-batch   271: 2.882\n",
      "Loss after mini-batch   281: 0.494\n",
      "Loss after mini-batch   291: 0.193\n",
      "Loss after mini-batch   301: 0.203\n",
      "Loss after mini-batch   311: 0.226\n",
      "Loss after mini-batch   321: 8.944\n",
      "Loss after mini-batch   331: 3.283\n",
      "Loss after mini-batch   341: 0.542\n",
      "Loss after mini-batch   351: 0.618\n",
      "Loss after mini-batch   361: 8.050\n",
      "Loss after mini-batch   371: 0.094\n",
      "Training Loss: 1.514 \t\t Validation Loss:2.872\n",
      "Starting epoch 212\n",
      "Loss after mini-batch     1: 0.300\n",
      "Loss after mini-batch    11: 0.267\n",
      "Loss after mini-batch    21: 0.405\n",
      "Loss after mini-batch    31: 0.169\n",
      "Loss after mini-batch    41: 0.224\n",
      "Loss after mini-batch    51: 1.626\n",
      "Loss after mini-batch    61: 0.907\n",
      "Loss after mini-batch    71: 2.801\n",
      "Loss after mini-batch    81: 2.453\n",
      "Loss after mini-batch    91: 4.570\n",
      "Loss after mini-batch   101: 0.083\n",
      "Loss after mini-batch   111: 2.770\n",
      "Loss after mini-batch   121: 1.355\n",
      "Loss after mini-batch   131: 1.694\n",
      "Loss after mini-batch   141: 0.163\n",
      "Loss after mini-batch   151: 0.197\n",
      "Loss after mini-batch   161: 0.330\n",
      "Loss after mini-batch   171: 13.260\n",
      "Loss after mini-batch   181: 0.235\n",
      "Loss after mini-batch   191: 8.581\n",
      "Loss after mini-batch   201: 0.119\n",
      "Loss after mini-batch   211: 0.084\n",
      "Loss after mini-batch   221: 0.481\n",
      "Loss after mini-batch   231: 3.532\n",
      "Loss after mini-batch   241: 1.678\n",
      "Loss after mini-batch   251: 0.399\n",
      "Loss after mini-batch   261: 0.034\n",
      "Loss after mini-batch   271: 2.482\n",
      "Loss after mini-batch   281: 6.314\n",
      "Loss after mini-batch   291: 0.124\n",
      "Loss after mini-batch   301: 0.793\n",
      "Loss after mini-batch   311: 6.508\n",
      "Loss after mini-batch   321: 0.171\n",
      "Loss after mini-batch   331: 0.083\n",
      "Loss after mini-batch   341: 0.066\n",
      "Loss after mini-batch   351: 0.058\n",
      "Loss after mini-batch   361: 0.166\n",
      "Loss after mini-batch   371: 2.584\n",
      "Training Loss: 0.078 \t\t Validation Loss:0.791\n",
      "Starting epoch 213\n",
      "Loss after mini-batch     1: 1.272\n",
      "Loss after mini-batch    11: 5.654\n",
      "Loss after mini-batch    21: 0.097\n",
      "Loss after mini-batch    31: 0.313\n",
      "Loss after mini-batch    41: 0.180\n",
      "Loss after mini-batch    51: 1.342\n",
      "Loss after mini-batch    61: 1.767\n",
      "Loss after mini-batch    71: 0.782\n",
      "Loss after mini-batch    81: 2.049\n",
      "Loss after mini-batch    91: 0.053\n",
      "Loss after mini-batch   101: 14.436\n",
      "Loss after mini-batch   111: 0.203\n",
      "Loss after mini-batch   121: 3.689\n",
      "Loss after mini-batch   131: 0.463\n",
      "Loss after mini-batch   141: 0.446\n",
      "Loss after mini-batch   151: 0.062\n",
      "Loss after mini-batch   161: 0.072\n",
      "Loss after mini-batch   171: 0.174\n",
      "Loss after mini-batch   181: 1.094\n",
      "Loss after mini-batch   191: 0.037\n",
      "Loss after mini-batch   201: 1.709\n",
      "Loss after mini-batch   211: 0.247\n",
      "Loss after mini-batch   221: 0.324\n",
      "Loss after mini-batch   231: 0.027\n",
      "Loss after mini-batch   241: 0.387\n",
      "Loss after mini-batch   251: 2.767\n",
      "Loss after mini-batch   261: 0.069\n",
      "Loss after mini-batch   271: 3.695\n",
      "Loss after mini-batch   281: 0.670\n",
      "Loss after mini-batch   291: 3.292\n",
      "Loss after mini-batch   301: 0.378\n",
      "Loss after mini-batch   311: 0.107\n",
      "Loss after mini-batch   321: 0.178\n",
      "Loss after mini-batch   331: 0.218\n",
      "Loss after mini-batch   341: 0.103\n",
      "Loss after mini-batch   351: 1.405\n",
      "Loss after mini-batch   361: 1.120\n",
      "Loss after mini-batch   371: 2.923\n",
      "Training Loss: 0.109 \t\t Validation Loss:0.670\n",
      "Starting epoch 214\n",
      "Loss after mini-batch     1: 1.586\n",
      "Loss after mini-batch    11: 0.406\n",
      "Loss after mini-batch    21: 0.295\n",
      "Loss after mini-batch    31: 0.271\n",
      "Loss after mini-batch    41: 0.126\n",
      "Loss after mini-batch    51: 14.275\n",
      "Loss after mini-batch    61: 0.361\n",
      "Loss after mini-batch    71: 0.637\n",
      "Loss after mini-batch    81: 0.313\n",
      "Loss after mini-batch    91: 0.179\n",
      "Loss after mini-batch   101: 0.093\n",
      "Loss after mini-batch   111: 0.091\n",
      "Loss after mini-batch   121: 0.105\n",
      "Loss after mini-batch   131: 0.064\n",
      "Loss after mini-batch   141: 0.280\n",
      "Loss after mini-batch   151: 8.847\n",
      "Loss after mini-batch   161: 1.364\n",
      "Loss after mini-batch   171: 0.074\n",
      "Loss after mini-batch   181: 1.035\n",
      "Loss after mini-batch   191: 0.187\n",
      "Loss after mini-batch   201: 3.515\n",
      "Loss after mini-batch   211: 0.149\n",
      "Loss after mini-batch   221: 0.010\n",
      "Loss after mini-batch   231: 0.140\n",
      "Loss after mini-batch   241: 1.993\n",
      "Loss after mini-batch   251: 0.191\n",
      "Loss after mini-batch   261: 0.285\n",
      "Loss after mini-batch   271: 1.666\n",
      "Loss after mini-batch   281: 2.129\n",
      "Loss after mini-batch   291: 2.572\n",
      "Loss after mini-batch   301: 3.423\n",
      "Loss after mini-batch   311: 7.950\n",
      "Loss after mini-batch   321: 0.070\n",
      "Loss after mini-batch   331: 0.109\n",
      "Loss after mini-batch   341: 0.647\n",
      "Loss after mini-batch   351: 0.105\n",
      "Loss after mini-batch   361: 0.534\n",
      "Loss after mini-batch   371: 2.317\n",
      "Training Loss: 0.392 \t\t Validation Loss:2.445\n",
      "Starting epoch 215\n",
      "Loss after mini-batch     1: 0.908\n",
      "Loss after mini-batch    11: 0.852\n",
      "Loss after mini-batch    21: 0.561\n",
      "Loss after mini-batch    31: 0.169\n",
      "Loss after mini-batch    41: 2.185\n",
      "Loss after mini-batch    51: 0.047\n",
      "Loss after mini-batch    61: 0.222\n",
      "Loss after mini-batch    71: 1.124\n",
      "Loss after mini-batch    81: 0.067\n",
      "Loss after mini-batch    91: 1.206\n",
      "Loss after mini-batch   101: 6.918\n",
      "Loss after mini-batch   111: 2.111\n",
      "Loss after mini-batch   121: 0.066\n",
      "Loss after mini-batch   131: 0.213\n",
      "Loss after mini-batch   141: 0.987\n",
      "Loss after mini-batch   151: 0.278\n",
      "Loss after mini-batch   161: 0.174\n",
      "Loss after mini-batch   171: 0.338\n",
      "Loss after mini-batch   181: 7.342\n",
      "Loss after mini-batch   191: 0.076\n",
      "Loss after mini-batch   201: 7.002\n",
      "Loss after mini-batch   211: 1.993\n",
      "Loss after mini-batch   221: 0.224\n",
      "Loss after mini-batch   231: 6.943\n",
      "Loss after mini-batch   241: 0.107\n",
      "Loss after mini-batch   251: 0.040\n",
      "Loss after mini-batch   261: 0.521\n",
      "Loss after mini-batch   271: 0.898\n",
      "Loss after mini-batch   281: 8.035\n",
      "Loss after mini-batch   291: 1.104\n",
      "Loss after mini-batch   301: 2.592\n",
      "Loss after mini-batch   311: 6.284\n",
      "Loss after mini-batch   321: 0.538\n",
      "Loss after mini-batch   331: 0.316\n",
      "Loss after mini-batch   341: 0.076\n",
      "Loss after mini-batch   351: 0.154\n",
      "Loss after mini-batch   361: 0.225\n",
      "Loss after mini-batch   371: 0.194\n",
      "Training Loss: 2.551 \t\t Validation Loss:22.290\n",
      "Starting epoch 216\n",
      "Loss after mini-batch     1: 0.099\n",
      "Loss after mini-batch    11: 0.409\n",
      "Loss after mini-batch    21: 0.631\n",
      "Loss after mini-batch    31: 0.133\n",
      "Loss after mini-batch    41: 0.732\n",
      "Loss after mini-batch    51: 6.650\n",
      "Loss after mini-batch    61: 0.018\n",
      "Loss after mini-batch    71: 0.102\n",
      "Loss after mini-batch    81: 0.473\n",
      "Loss after mini-batch    91: 1.282\n",
      "Loss after mini-batch   101: 0.242\n",
      "Loss after mini-batch   111: 0.189\n",
      "Loss after mini-batch   121: 0.109\n",
      "Loss after mini-batch   131: 0.522\n",
      "Loss after mini-batch   141: 4.539\n",
      "Loss after mini-batch   151: 0.236\n",
      "Loss after mini-batch   161: 0.125\n",
      "Loss after mini-batch   171: 0.130\n",
      "Loss after mini-batch   181: 0.298\n",
      "Loss after mini-batch   191: 0.581\n",
      "Loss after mini-batch   201: 2.328\n",
      "Loss after mini-batch   211: 0.190\n",
      "Loss after mini-batch   221: 0.138\n",
      "Loss after mini-batch   231: 1.335\n",
      "Loss after mini-batch   241: 0.543\n",
      "Loss after mini-batch   251: 2.543\n",
      "Loss after mini-batch   261: 0.875\n",
      "Loss after mini-batch   271: 0.170\n",
      "Loss after mini-batch   281: 0.813\n",
      "Loss after mini-batch   291: 0.276\n",
      "Loss after mini-batch   301: 4.888\n",
      "Loss after mini-batch   311: 0.105\n",
      "Loss after mini-batch   321: 1.631\n",
      "Loss after mini-batch   331: 0.459\n",
      "Loss after mini-batch   341: 27.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   351: 1.609\n",
      "Loss after mini-batch   361: 0.105\n",
      "Loss after mini-batch   371: 1.305\n",
      "Training Loss: 3.724 \t\t Validation Loss:9.421\n",
      "Starting epoch 217\n",
      "Loss after mini-batch     1: 0.151\n",
      "Loss after mini-batch    11: 0.033\n",
      "Loss after mini-batch    21: 0.383\n",
      "Loss after mini-batch    31: 0.097\n",
      "Loss after mini-batch    41: 0.073\n",
      "Loss after mini-batch    51: 1.047\n",
      "Loss after mini-batch    61: 0.109\n",
      "Loss after mini-batch    71: 0.758\n",
      "Loss after mini-batch    81: 12.872\n",
      "Loss after mini-batch    91: 0.851\n",
      "Loss after mini-batch   101: 1.982\n",
      "Loss after mini-batch   111: 0.204\n",
      "Loss after mini-batch   121: 1.406\n",
      "Loss after mini-batch   131: 0.097\n",
      "Loss after mini-batch   141: 0.323\n",
      "Loss after mini-batch   151: 0.826\n",
      "Loss after mini-batch   161: 0.076\n",
      "Loss after mini-batch   171: 0.931\n",
      "Loss after mini-batch   181: 0.241\n",
      "Loss after mini-batch   191: 1.750\n",
      "Loss after mini-batch   201: 0.287\n",
      "Loss after mini-batch   211: 2.707\n",
      "Loss after mini-batch   221: 0.089\n",
      "Loss after mini-batch   231: 0.043\n",
      "Loss after mini-batch   241: 5.072\n",
      "Loss after mini-batch   251: 1.051\n",
      "Loss after mini-batch   261: 1.187\n",
      "Loss after mini-batch   271: 1.035\n",
      "Loss after mini-batch   281: 0.858\n",
      "Loss after mini-batch   291: 0.066\n",
      "Loss after mini-batch   301: 3.407\n",
      "Loss after mini-batch   311: 5.286\n",
      "Loss after mini-batch   321: 0.225\n",
      "Loss after mini-batch   331: 1.259\n",
      "Loss after mini-batch   341: 0.328\n",
      "Loss after mini-batch   351: 5.889\n",
      "Loss after mini-batch   361: 1.949\n",
      "Loss after mini-batch   371: 0.230\n",
      "Training Loss: 0.234 \t\t Validation Loss:0.780\n",
      "Starting epoch 218\n",
      "Loss after mini-batch     1: 1.747\n",
      "Loss after mini-batch    11: 0.156\n",
      "Loss after mini-batch    21: 1.789\n",
      "Loss after mini-batch    31: 0.476\n",
      "Loss after mini-batch    41: 0.044\n",
      "Loss after mini-batch    51: 0.525\n",
      "Loss after mini-batch    61: 0.126\n",
      "Loss after mini-batch    71: 0.060\n",
      "Loss after mini-batch    81: 1.948\n",
      "Loss after mini-batch    91: 0.245\n",
      "Loss after mini-batch   101: 0.208\n",
      "Loss after mini-batch   111: 0.209\n",
      "Loss after mini-batch   121: 0.419\n",
      "Loss after mini-batch   131: 0.142\n",
      "Loss after mini-batch   141: 0.832\n",
      "Loss after mini-batch   151: 0.724\n",
      "Loss after mini-batch   161: 0.108\n",
      "Loss after mini-batch   171: 0.986\n",
      "Loss after mini-batch   181: 0.408\n",
      "Loss after mini-batch   191: 2.878\n",
      "Loss after mini-batch   201: 0.607\n",
      "Loss after mini-batch   211: 1.592\n",
      "Loss after mini-batch   221: 0.853\n",
      "Loss after mini-batch   231: 1.756\n",
      "Loss after mini-batch   241: 0.050\n",
      "Loss after mini-batch   251: 0.084\n",
      "Loss after mini-batch   261: 6.049\n",
      "Loss after mini-batch   271: 8.822\n",
      "Loss after mini-batch   281: 14.723\n",
      "Loss after mini-batch   291: 1.146\n",
      "Loss after mini-batch   301: 2.039\n",
      "Loss after mini-batch   311: 0.156\n",
      "Loss after mini-batch   321: 0.185\n",
      "Loss after mini-batch   331: 0.209\n",
      "Loss after mini-batch   341: 0.287\n",
      "Loss after mini-batch   351: 0.553\n",
      "Loss after mini-batch   361: 0.595\n",
      "Loss after mini-batch   371: 2.421\n",
      "Training Loss: 1.127 \t\t Validation Loss:3.073\n",
      "Starting epoch 219\n",
      "Loss after mini-batch     1: 0.139\n",
      "Loss after mini-batch    11: 0.186\n",
      "Loss after mini-batch    21: 0.119\n",
      "Loss after mini-batch    31: 0.681\n",
      "Loss after mini-batch    41: 0.256\n",
      "Loss after mini-batch    51: 0.254\n",
      "Loss after mini-batch    61: 0.105\n",
      "Loss after mini-batch    71: 3.502\n",
      "Loss after mini-batch    81: 1.231\n",
      "Loss after mini-batch    91: 1.146\n",
      "Loss after mini-batch   101: 0.107\n",
      "Loss after mini-batch   111: 0.207\n",
      "Loss after mini-batch   121: 0.016\n",
      "Loss after mini-batch   131: 0.033\n",
      "Loss after mini-batch   141: 7.528\n",
      "Loss after mini-batch   151: 0.840\n",
      "Loss after mini-batch   161: 7.740\n",
      "Loss after mini-batch   171: 0.587\n",
      "Loss after mini-batch   181: 0.191\n",
      "Loss after mini-batch   191: 8.758\n",
      "Loss after mini-batch   201: 1.610\n",
      "Loss after mini-batch   211: 1.496\n",
      "Loss after mini-batch   221: 0.816\n",
      "Loss after mini-batch   231: 0.127\n",
      "Loss after mini-batch   241: 0.205\n",
      "Loss after mini-batch   251: 0.872\n",
      "Loss after mini-batch   261: 0.415\n",
      "Loss after mini-batch   271: 1.642\n",
      "Loss after mini-batch   281: 0.262\n",
      "Loss after mini-batch   291: 1.812\n",
      "Loss after mini-batch   301: 0.164\n",
      "Loss after mini-batch   311: 0.850\n",
      "Loss after mini-batch   321: 0.275\n",
      "Loss after mini-batch   331: 0.109\n",
      "Loss after mini-batch   341: 0.553\n",
      "Loss after mini-batch   351: 0.022\n",
      "Loss after mini-batch   361: 2.056\n",
      "Loss after mini-batch   371: 0.488\n",
      "Training Loss: 0.548 \t\t Validation Loss:1.597\n",
      "Starting epoch 220\n",
      "Loss after mini-batch     1: 3.407\n",
      "Loss after mini-batch    11: 4.897\n",
      "Loss after mini-batch    21: 6.849\n",
      "Loss after mini-batch    31: 0.105\n",
      "Loss after mini-batch    41: 1.708\n",
      "Loss after mini-batch    51: 0.911\n",
      "Loss after mini-batch    61: 1.361\n",
      "Loss after mini-batch    71: 0.801\n",
      "Loss after mini-batch    81: 2.112\n",
      "Loss after mini-batch    91: 0.055\n",
      "Loss after mini-batch   101: 0.680\n",
      "Loss after mini-batch   111: 0.192\n",
      "Loss after mini-batch   121: 0.087\n",
      "Loss after mini-batch   131: 0.614\n",
      "Loss after mini-batch   141: 0.446\n",
      "Loss after mini-batch   151: 0.243\n",
      "Loss after mini-batch   161: 1.635\n",
      "Loss after mini-batch   171: 1.214\n",
      "Loss after mini-batch   181: 0.345\n",
      "Loss after mini-batch   191: 0.188\n",
      "Loss after mini-batch   201: 4.599\n",
      "Loss after mini-batch   211: 1.106\n",
      "Loss after mini-batch   221: 1.472\n",
      "Loss after mini-batch   231: 0.461\n",
      "Loss after mini-batch   241: 0.870\n",
      "Loss after mini-batch   251: 0.106\n",
      "Loss after mini-batch   261: 0.330\n",
      "Loss after mini-batch   271: 0.038\n",
      "Loss after mini-batch   281: 4.092\n",
      "Loss after mini-batch   291: 1.972\n",
      "Loss after mini-batch   301: 0.100\n",
      "Loss after mini-batch   311: 2.226\n",
      "Loss after mini-batch   321: 0.919\n",
      "Loss after mini-batch   331: 0.044\n",
      "Loss after mini-batch   341: 0.082\n",
      "Loss after mini-batch   351: 1.072\n",
      "Loss after mini-batch   361: 2.160\n",
      "Loss after mini-batch   371: 0.256\n",
      "Training Loss: 0.423 \t\t Validation Loss:1.550\n",
      "Starting epoch 221\n",
      "Loss after mini-batch     1: 0.085\n",
      "Loss after mini-batch    11: 0.056\n",
      "Loss after mini-batch    21: 0.282\n",
      "Loss after mini-batch    31: 0.049\n",
      "Loss after mini-batch    41: 0.281\n",
      "Loss after mini-batch    51: 0.255\n",
      "Loss after mini-batch    61: 0.062\n",
      "Loss after mini-batch    71: 0.146\n",
      "Loss after mini-batch    81: 0.310\n",
      "Loss after mini-batch    91: 0.262\n",
      "Loss after mini-batch   101: 4.889\n",
      "Loss after mini-batch   111: 7.614\n",
      "Loss after mini-batch   121: 0.326\n",
      "Loss after mini-batch   131: 0.172\n",
      "Loss after mini-batch   141: 1.229\n",
      "Loss after mini-batch   151: 8.833\n",
      "Loss after mini-batch   161: 0.215\n",
      "Loss after mini-batch   171: 0.096\n",
      "Loss after mini-batch   181: 1.345\n",
      "Loss after mini-batch   191: 1.395\n",
      "Loss after mini-batch   201: 1.279\n",
      "Loss after mini-batch   211: 1.255\n",
      "Loss after mini-batch   221: 0.633\n",
      "Loss after mini-batch   231: 0.218\n",
      "Loss after mini-batch   241: 3.093\n",
      "Loss after mini-batch   251: 7.319\n",
      "Loss after mini-batch   261: 0.688\n",
      "Loss after mini-batch   271: 0.235\n",
      "Loss after mini-batch   281: 0.527\n",
      "Loss after mini-batch   291: 0.748\n",
      "Loss after mini-batch   301: 1.006\n",
      "Loss after mini-batch   311: 0.179\n",
      "Loss after mini-batch   321: 0.218\n",
      "Loss after mini-batch   331: 2.279\n",
      "Loss after mini-batch   341: 0.125\n",
      "Loss after mini-batch   351: 0.581\n",
      "Loss after mini-batch   361: 0.340\n",
      "Loss after mini-batch   371: 0.089\n",
      "Training Loss: 0.129 \t\t Validation Loss:0.195\n",
      "Starting epoch 222\n",
      "Loss after mini-batch     1: 0.205\n",
      "Loss after mini-batch    11: 0.768\n",
      "Loss after mini-batch    21: 4.144\n",
      "Loss after mini-batch    31: 2.854\n",
      "Loss after mini-batch    41: 0.014\n",
      "Loss after mini-batch    51: 1.020\n",
      "Loss after mini-batch    61: 0.448\n",
      "Loss after mini-batch    71: 0.348\n",
      "Loss after mini-batch    81: 8.150\n",
      "Loss after mini-batch    91: 5.402\n",
      "Loss after mini-batch   101: 0.189\n",
      "Loss after mini-batch   111: 0.115\n",
      "Loss after mini-batch   121: 0.229\n",
      "Loss after mini-batch   131: 0.476\n",
      "Loss after mini-batch   141: 8.276\n",
      "Loss after mini-batch   151: 0.027\n",
      "Loss after mini-batch   161: 0.142\n",
      "Loss after mini-batch   171: 0.159\n",
      "Loss after mini-batch   181: 1.188\n",
      "Loss after mini-batch   191: 0.713\n",
      "Loss after mini-batch   201: 0.419\n",
      "Loss after mini-batch   211: 2.783\n",
      "Loss after mini-batch   221: 0.222\n",
      "Loss after mini-batch   231: 0.891\n",
      "Loss after mini-batch   241: 1.083\n",
      "Loss after mini-batch   251: 3.753\n",
      "Loss after mini-batch   261: 0.270\n",
      "Loss after mini-batch   271: 0.246\n",
      "Loss after mini-batch   281: 1.634\n",
      "Loss after mini-batch   291: 0.193\n",
      "Loss after mini-batch   301: 0.516\n",
      "Loss after mini-batch   311: 0.278\n",
      "Loss after mini-batch   321: 1.862\n",
      "Loss after mini-batch   331: 3.813\n",
      "Loss after mini-batch   341: 7.340\n",
      "Loss after mini-batch   351: 0.209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   361: 0.053\n",
      "Loss after mini-batch   371: 1.249\n",
      "Training Loss: 0.198 \t\t Validation Loss:0.280\n",
      "Starting epoch 223\n",
      "Loss after mini-batch     1: 0.249\n",
      "Loss after mini-batch    11: 0.219\n",
      "Loss after mini-batch    21: 5.504\n",
      "Loss after mini-batch    31: 0.280\n",
      "Loss after mini-batch    41: 3.814\n",
      "Loss after mini-batch    51: 0.110\n",
      "Loss after mini-batch    61: 0.163\n",
      "Loss after mini-batch    71: 0.431\n",
      "Loss after mini-batch    81: 0.060\n",
      "Loss after mini-batch    91: 0.270\n",
      "Loss after mini-batch   101: 2.112\n",
      "Loss after mini-batch   111: 0.381\n",
      "Loss after mini-batch   121: 0.188\n",
      "Loss after mini-batch   131: 0.835\n",
      "Loss after mini-batch   141: 1.457\n",
      "Loss after mini-batch   151: 0.524\n",
      "Loss after mini-batch   161: 1.011\n",
      "Loss after mini-batch   171: 2.477\n",
      "Loss after mini-batch   181: 1.247\n",
      "Loss after mini-batch   191: 0.149\n",
      "Loss after mini-batch   201: 0.161\n",
      "Loss after mini-batch   211: 0.133\n",
      "Loss after mini-batch   221: 1.348\n",
      "Loss after mini-batch   231: 0.178\n",
      "Loss after mini-batch   241: 1.229\n",
      "Loss after mini-batch   251: 0.051\n",
      "Loss after mini-batch   261: 1.770\n",
      "Loss after mini-batch   271: 0.203\n",
      "Loss after mini-batch   281: 0.391\n",
      "Loss after mini-batch   291: 0.052\n",
      "Loss after mini-batch   301: 0.330\n",
      "Loss after mini-batch   311: 0.647\n",
      "Loss after mini-batch   321: 4.388\n",
      "Loss after mini-batch   331: 2.001\n",
      "Loss after mini-batch   341: 0.103\n",
      "Loss after mini-batch   351: 0.297\n",
      "Loss after mini-batch   361: 0.232\n",
      "Loss after mini-batch   371: 0.069\n",
      "Training Loss: 0.316 \t\t Validation Loss:2.105\n",
      "Starting epoch 224\n",
      "Loss after mini-batch     1: 0.099\n",
      "Loss after mini-batch    11: 0.312\n",
      "Loss after mini-batch    21: 2.385\n",
      "Loss after mini-batch    31: 0.842\n",
      "Loss after mini-batch    41: 1.899\n",
      "Loss after mini-batch    51: 8.988\n",
      "Loss after mini-batch    61: 0.384\n",
      "Loss after mini-batch    71: 0.864\n",
      "Loss after mini-batch    81: 0.741\n",
      "Loss after mini-batch    91: 1.437\n",
      "Loss after mini-batch   101: 0.142\n",
      "Loss after mini-batch   111: 1.119\n",
      "Loss after mini-batch   121: 0.033\n",
      "Loss after mini-batch   131: 10.634\n",
      "Loss after mini-batch   141: 1.830\n",
      "Loss after mini-batch   151: 0.619\n",
      "Loss after mini-batch   161: 1.335\n",
      "Loss after mini-batch   171: 0.764\n",
      "Loss after mini-batch   181: 0.332\n",
      "Loss after mini-batch   191: 0.070\n",
      "Loss after mini-batch   201: 1.115\n",
      "Loss after mini-batch   211: 1.814\n",
      "Loss after mini-batch   221: 0.221\n",
      "Loss after mini-batch   231: 1.463\n",
      "Loss after mini-batch   241: 6.145\n",
      "Loss after mini-batch   251: 1.656\n",
      "Loss after mini-batch   261: 0.051\n",
      "Loss after mini-batch   271: 0.237\n",
      "Loss after mini-batch   281: 1.057\n",
      "Loss after mini-batch   291: 5.293\n",
      "Loss after mini-batch   301: 6.067\n",
      "Loss after mini-batch   311: 0.107\n",
      "Loss after mini-batch   321: 0.718\n",
      "Loss after mini-batch   331: 1.180\n",
      "Loss after mini-batch   341: 4.696\n",
      "Loss after mini-batch   351: 12.619\n",
      "Loss after mini-batch   361: 2.061\n",
      "Loss after mini-batch   371: 1.835\n",
      "Training Loss: 1.696 \t\t Validation Loss:2.342\n",
      "Starting epoch 225\n",
      "Loss after mini-batch     1: 1.579\n",
      "Loss after mini-batch    11: 1.442\n",
      "Loss after mini-batch    21: 3.472\n",
      "Loss after mini-batch    31: 6.293\n",
      "Loss after mini-batch    41: 5.914\n",
      "Loss after mini-batch    51: 0.606\n",
      "Loss after mini-batch    61: 0.099\n",
      "Loss after mini-batch    71: 3.788\n",
      "Loss after mini-batch    81: 0.171\n",
      "Loss after mini-batch    91: 14.073\n",
      "Loss after mini-batch   101: 0.029\n",
      "Loss after mini-batch   111: 2.126\n",
      "Loss after mini-batch   121: 0.187\n",
      "Loss after mini-batch   131: 0.668\n",
      "Loss after mini-batch   141: 0.903\n",
      "Loss after mini-batch   151: 2.028\n",
      "Loss after mini-batch   161: 3.931\n",
      "Loss after mini-batch   171: 0.124\n",
      "Loss after mini-batch   181: 1.827\n",
      "Loss after mini-batch   191: 0.022\n",
      "Loss after mini-batch   201: 2.417\n",
      "Loss after mini-batch   211: 2.897\n",
      "Loss after mini-batch   221: 26.264\n",
      "Loss after mini-batch   231: 0.270\n",
      "Loss after mini-batch   241: 14.291\n",
      "Loss after mini-batch   251: 0.163\n",
      "Loss after mini-batch   261: 1.150\n",
      "Loss after mini-batch   271: 1.141\n",
      "Loss after mini-batch   281: 0.090\n",
      "Loss after mini-batch   291: 1.364\n",
      "Loss after mini-batch   301: 4.491\n",
      "Loss after mini-batch   311: 0.684\n",
      "Loss after mini-batch   321: 0.130\n",
      "Loss after mini-batch   331: 1.134\n",
      "Loss after mini-batch   341: 0.126\n",
      "Loss after mini-batch   351: 0.200\n",
      "Loss after mini-batch   361: 0.175\n",
      "Loss after mini-batch   371: 1.101\n",
      "Training Loss: 1.688 \t\t Validation Loss:3.084\n",
      "Starting epoch 226\n",
      "Loss after mini-batch     1: 7.850\n",
      "Loss after mini-batch    11: 0.085\n",
      "Loss after mini-batch    21: 0.354\n",
      "Loss after mini-batch    31: 4.596\n",
      "Loss after mini-batch    41: 0.679\n",
      "Loss after mini-batch    51: 1.197\n",
      "Loss after mini-batch    61: 0.379\n",
      "Loss after mini-batch    71: 0.125\n",
      "Loss after mini-batch    81: 0.373\n",
      "Loss after mini-batch    91: 0.894\n",
      "Loss after mini-batch   101: 0.282\n",
      "Loss after mini-batch   111: 0.091\n",
      "Loss after mini-batch   121: 0.158\n",
      "Loss after mini-batch   131: 0.134\n",
      "Loss after mini-batch   141: 7.638\n",
      "Loss after mini-batch   151: 0.137\n",
      "Loss after mini-batch   161: 0.347\n",
      "Loss after mini-batch   171: 0.226\n",
      "Loss after mini-batch   181: 1.591\n",
      "Loss after mini-batch   191: 0.023\n",
      "Loss after mini-batch   201: 1.393\n",
      "Loss after mini-batch   211: 6.391\n",
      "Loss after mini-batch   221: 0.124\n",
      "Loss after mini-batch   231: 5.695\n",
      "Loss after mini-batch   241: 5.519\n",
      "Loss after mini-batch   251: 0.184\n",
      "Loss after mini-batch   261: 0.133\n",
      "Loss after mini-batch   271: 2.074\n",
      "Loss after mini-batch   281: 4.764\n",
      "Loss after mini-batch   291: 1.816\n",
      "Loss after mini-batch   301: 0.208\n",
      "Loss after mini-batch   311: 0.124\n",
      "Loss after mini-batch   321: 0.132\n",
      "Loss after mini-batch   331: 0.280\n",
      "Loss after mini-batch   341: 0.397\n",
      "Loss after mini-batch   351: 10.225\n",
      "Loss after mini-batch   361: 0.254\n",
      "Loss after mini-batch   371: 0.016\n",
      "Training Loss: 2.816 \t\t Validation Loss:4.311\n",
      "Starting epoch 227\n",
      "Loss after mini-batch     1: 0.233\n",
      "Loss after mini-batch    11: 0.247\n",
      "Loss after mini-batch    21: 0.219\n",
      "Loss after mini-batch    31: 0.260\n",
      "Loss after mini-batch    41: 0.774\n",
      "Loss after mini-batch    51: 2.022\n",
      "Loss after mini-batch    61: 0.630\n",
      "Loss after mini-batch    71: 0.052\n",
      "Loss after mini-batch    81: 0.112\n",
      "Loss after mini-batch    91: 5.415\n",
      "Loss after mini-batch   101: 0.032\n",
      "Loss after mini-batch   111: 0.138\n",
      "Loss after mini-batch   121: 0.301\n",
      "Loss after mini-batch   131: 1.351\n",
      "Loss after mini-batch   141: 0.268\n",
      "Loss after mini-batch   151: 0.036\n",
      "Loss after mini-batch   161: 0.991\n",
      "Loss after mini-batch   171: 0.317\n",
      "Loss after mini-batch   181: 0.164\n",
      "Loss after mini-batch   191: 13.952\n",
      "Loss after mini-batch   201: 0.587\n",
      "Loss after mini-batch   211: 1.769\n",
      "Loss after mini-batch   221: 6.730\n",
      "Loss after mini-batch   231: 1.973\n",
      "Loss after mini-batch   241: 1.486\n",
      "Loss after mini-batch   251: 1.265\n",
      "Loss after mini-batch   261: 0.096\n",
      "Loss after mini-batch   271: 0.541\n",
      "Loss after mini-batch   281: 1.287\n",
      "Loss after mini-batch   291: 1.225\n",
      "Loss after mini-batch   301: 1.718\n",
      "Loss after mini-batch   311: 0.262\n",
      "Loss after mini-batch   321: 0.968\n",
      "Loss after mini-batch   331: 6.036\n",
      "Loss after mini-batch   341: 2.092\n",
      "Loss after mini-batch   351: 0.270\n",
      "Loss after mini-batch   361: 1.798\n",
      "Loss after mini-batch   371: 0.295\n",
      "Training Loss: 3.007 \t\t Validation Loss:7.371\n",
      "Starting epoch 228\n",
      "Loss after mini-batch     1: 0.204\n",
      "Loss after mini-batch    11: 0.094\n",
      "Loss after mini-batch    21: 0.126\n",
      "Loss after mini-batch    31: 0.493\n",
      "Loss after mini-batch    41: 0.257\n",
      "Loss after mini-batch    51: 1.131\n",
      "Loss after mini-batch    61: 0.350\n",
      "Loss after mini-batch    71: 0.334\n",
      "Loss after mini-batch    81: 0.078\n",
      "Loss after mini-batch    91: 2.225\n",
      "Loss after mini-batch   101: 0.258\n",
      "Loss after mini-batch   111: 0.757\n",
      "Loss after mini-batch   121: 0.201\n",
      "Loss after mini-batch   131: 1.071\n",
      "Loss after mini-batch   141: 5.552\n",
      "Loss after mini-batch   151: 7.634\n",
      "Loss after mini-batch   161: 2.533\n",
      "Loss after mini-batch   171: 0.086\n",
      "Loss after mini-batch   181: 0.097\n",
      "Loss after mini-batch   191: 0.171\n",
      "Loss after mini-batch   201: 0.111\n",
      "Loss after mini-batch   211: 0.054\n",
      "Loss after mini-batch   221: 0.140\n",
      "Loss after mini-batch   231: 0.098\n",
      "Loss after mini-batch   241: 1.675\n",
      "Loss after mini-batch   251: 1.060\n",
      "Loss after mini-batch   261: 0.011\n",
      "Loss after mini-batch   271: 0.233\n",
      "Loss after mini-batch   281: 1.926\n",
      "Loss after mini-batch   291: 3.231\n",
      "Loss after mini-batch   301: 0.204\n",
      "Loss after mini-batch   311: 0.092\n",
      "Loss after mini-batch   321: 1.133\n",
      "Loss after mini-batch   331: 0.221\n",
      "Loss after mini-batch   341: 3.920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   351: 0.138\n",
      "Loss after mini-batch   361: 0.808\n",
      "Loss after mini-batch   371: 0.336\n",
      "Training Loss: 0.905 \t\t Validation Loss:4.361\n",
      "Starting epoch 229\n",
      "Loss after mini-batch     1: 0.222\n",
      "Loss after mini-batch    11: 0.486\n",
      "Loss after mini-batch    21: 0.807\n",
      "Loss after mini-batch    31: 2.570\n",
      "Loss after mini-batch    41: 0.095\n",
      "Loss after mini-batch    51: 0.298\n",
      "Loss after mini-batch    61: 0.960\n",
      "Loss after mini-batch    71: 0.080\n",
      "Loss after mini-batch    81: 0.489\n",
      "Loss after mini-batch    91: 7.667\n",
      "Loss after mini-batch   101: 0.267\n",
      "Loss after mini-batch   111: 0.922\n",
      "Loss after mini-batch   121: 2.909\n",
      "Loss after mini-batch   131: 0.404\n",
      "Loss after mini-batch   141: 0.314\n",
      "Loss after mini-batch   151: 1.097\n",
      "Loss after mini-batch   161: 6.727\n",
      "Loss after mini-batch   171: 0.055\n",
      "Loss after mini-batch   181: 0.154\n",
      "Loss after mini-batch   191: 2.824\n",
      "Loss after mini-batch   201: 0.913\n",
      "Loss after mini-batch   211: 0.414\n",
      "Loss after mini-batch   221: 0.229\n",
      "Loss after mini-batch   231: 0.764\n",
      "Loss after mini-batch   241: 0.181\n",
      "Loss after mini-batch   251: 5.981\n",
      "Loss after mini-batch   261: 0.120\n",
      "Loss after mini-batch   271: 0.097\n",
      "Loss after mini-batch   281: 6.754\n",
      "Loss after mini-batch   291: 0.085\n",
      "Loss after mini-batch   301: 2.821\n",
      "Loss after mini-batch   311: 0.457\n",
      "Loss after mini-batch   321: 1.603\n",
      "Loss after mini-batch   331: 0.086\n",
      "Loss after mini-batch   341: 0.075\n",
      "Loss after mini-batch   351: 1.336\n",
      "Loss after mini-batch   361: 4.096\n",
      "Loss after mini-batch   371: 0.635\n",
      "Training Loss: 0.211 \t\t Validation Loss:18.747\n",
      "Starting epoch 230\n",
      "Loss after mini-batch     1: 0.463\n",
      "Loss after mini-batch    11: 0.287\n",
      "Loss after mini-batch    21: 0.206\n",
      "Loss after mini-batch    31: 0.981\n",
      "Loss after mini-batch    41: 3.946\n",
      "Loss after mini-batch    51: 0.870\n",
      "Loss after mini-batch    61: 0.207\n",
      "Loss after mini-batch    71: 2.498\n",
      "Loss after mini-batch    81: 13.563\n",
      "Loss after mini-batch    91: 1.590\n",
      "Loss after mini-batch   101: 0.438\n",
      "Loss after mini-batch   111: 1.126\n",
      "Loss after mini-batch   121: 2.379\n",
      "Loss after mini-batch   131: 0.285\n",
      "Loss after mini-batch   141: 1.144\n",
      "Loss after mini-batch   151: 0.196\n",
      "Loss after mini-batch   161: 1.475\n",
      "Loss after mini-batch   171: 6.374\n",
      "Loss after mini-batch   181: 5.894\n",
      "Loss after mini-batch   191: 0.167\n",
      "Loss after mini-batch   201: 1.714\n",
      "Loss after mini-batch   211: 0.135\n",
      "Loss after mini-batch   221: 0.106\n",
      "Loss after mini-batch   231: 1.815\n",
      "Loss after mini-batch   241: 3.710\n",
      "Loss after mini-batch   251: 0.927\n",
      "Loss after mini-batch   261: 5.384\n",
      "Loss after mini-batch   271: 0.113\n",
      "Loss after mini-batch   281: 5.975\n",
      "Loss after mini-batch   291: 1.711\n",
      "Loss after mini-batch   301: 0.057\n",
      "Loss after mini-batch   311: 0.108\n",
      "Loss after mini-batch   321: 0.484\n",
      "Loss after mini-batch   331: 1.668\n",
      "Loss after mini-batch   341: 0.278\n",
      "Loss after mini-batch   351: 0.249\n",
      "Loss after mini-batch   361: 0.046\n",
      "Loss after mini-batch   371: 0.016\n",
      "Training Loss: 0.328 \t\t Validation Loss:0.362\n",
      "Starting epoch 231\n",
      "Loss after mini-batch     1: 0.068\n",
      "Loss after mini-batch    11: 4.072\n",
      "Loss after mini-batch    21: 2.166\n",
      "Loss after mini-batch    31: 0.220\n",
      "Loss after mini-batch    41: 0.117\n",
      "Loss after mini-batch    51: 7.428\n",
      "Loss after mini-batch    61: 7.145\n",
      "Loss after mini-batch    71: 0.186\n",
      "Loss after mini-batch    81: 1.451\n",
      "Loss after mini-batch    91: 1.101\n",
      "Loss after mini-batch   101: 0.078\n",
      "Loss after mini-batch   111: 0.199\n",
      "Loss after mini-batch   121: 0.253\n",
      "Loss after mini-batch   131: 4.031\n",
      "Loss after mini-batch   141: 0.904\n",
      "Loss after mini-batch   151: 1.174\n",
      "Loss after mini-batch   161: 2.737\n",
      "Loss after mini-batch   171: 0.730\n",
      "Loss after mini-batch   181: 2.004\n",
      "Loss after mini-batch   191: 5.829\n",
      "Loss after mini-batch   201: 0.158\n",
      "Loss after mini-batch   211: 3.017\n",
      "Loss after mini-batch   221: 6.302\n",
      "Loss after mini-batch   231: 1.803\n",
      "Loss after mini-batch   241: 0.093\n",
      "Loss after mini-batch   251: 0.221\n",
      "Loss after mini-batch   261: 0.226\n",
      "Loss after mini-batch   271: 0.037\n",
      "Loss after mini-batch   281: 2.349\n",
      "Loss after mini-batch   291: 4.260\n",
      "Loss after mini-batch   301: 0.110\n",
      "Loss after mini-batch   311: 1.059\n",
      "Loss after mini-batch   321: 0.343\n",
      "Loss after mini-batch   331: 0.209\n",
      "Loss after mini-batch   341: 0.186\n",
      "Loss after mini-batch   351: 0.642\n",
      "Loss after mini-batch   361: 0.209\n",
      "Loss after mini-batch   371: 0.021\n",
      "Training Loss: 0.076 \t\t Validation Loss:3.090\n",
      "Starting epoch 232\n",
      "Loss after mini-batch     1: 1.679\n",
      "Loss after mini-batch    11: 4.823\n",
      "Loss after mini-batch    21: 0.736\n",
      "Loss after mini-batch    31: 0.510\n",
      "Loss after mini-batch    41: 2.492\n",
      "Loss after mini-batch    51: 1.717\n",
      "Loss after mini-batch    61: 6.136\n",
      "Loss after mini-batch    71: 0.368\n",
      "Loss after mini-batch    81: 0.897\n",
      "Loss after mini-batch    91: 3.819\n",
      "Loss after mini-batch   101: 1.344\n",
      "Loss after mini-batch   111: 1.733\n",
      "Loss after mini-batch   121: 0.219\n",
      "Loss after mini-batch   131: 3.712\n",
      "Loss after mini-batch   141: 0.629\n",
      "Loss after mini-batch   151: 1.512\n",
      "Loss after mini-batch   161: 5.698\n",
      "Loss after mini-batch   171: 0.331\n",
      "Loss after mini-batch   181: 0.243\n",
      "Loss after mini-batch   191: 2.431\n",
      "Loss after mini-batch   201: 2.471\n",
      "Loss after mini-batch   211: 0.275\n",
      "Loss after mini-batch   221: 0.339\n",
      "Loss after mini-batch   231: 0.019\n",
      "Loss after mini-batch   241: 0.054\n",
      "Loss after mini-batch   251: 3.076\n",
      "Loss after mini-batch   261: 7.497\n",
      "Loss after mini-batch   271: 0.140\n",
      "Loss after mini-batch   281: 0.805\n",
      "Loss after mini-batch   291: 0.082\n",
      "Loss after mini-batch   301: 0.217\n",
      "Loss after mini-batch   311: 0.157\n",
      "Loss after mini-batch   321: 0.297\n",
      "Loss after mini-batch   331: 0.224\n",
      "Loss after mini-batch   341: 2.818\n",
      "Loss after mini-batch   351: 0.039\n",
      "Loss after mini-batch   361: 0.873\n",
      "Loss after mini-batch   371: 0.269\n",
      "Training Loss: 0.160 \t\t Validation Loss:1.487\n",
      "Starting epoch 233\n",
      "Loss after mini-batch     1: 0.497\n",
      "Loss after mini-batch    11: 1.036\n",
      "Loss after mini-batch    21: 0.299\n",
      "Loss after mini-batch    31: 0.355\n",
      "Loss after mini-batch    41: 6.862\n",
      "Loss after mini-batch    51: 0.272\n",
      "Loss after mini-batch    61: 0.113\n",
      "Loss after mini-batch    71: 0.191\n",
      "Loss after mini-batch    81: 0.544\n",
      "Loss after mini-batch    91: 2.594\n",
      "Loss after mini-batch   101: 0.133\n",
      "Loss after mini-batch   111: 3.036\n",
      "Loss after mini-batch   121: 0.437\n",
      "Loss after mini-batch   131: 0.021\n",
      "Loss after mini-batch   141: 1.649\n",
      "Loss after mini-batch   151: 0.090\n",
      "Loss after mini-batch   161: 0.562\n",
      "Loss after mini-batch   171: 5.698\n",
      "Loss after mini-batch   181: 0.254\n",
      "Loss after mini-batch   191: 0.944\n",
      "Loss after mini-batch   201: 0.016\n",
      "Loss after mini-batch   211: 1.166\n",
      "Loss after mini-batch   221: 0.483\n",
      "Loss after mini-batch   231: 0.349\n",
      "Loss after mini-batch   241: 1.688\n",
      "Loss after mini-batch   251: 1.930\n",
      "Loss after mini-batch   261: 0.039\n",
      "Loss after mini-batch   271: 0.178\n",
      "Loss after mini-batch   281: 0.615\n",
      "Loss after mini-batch   291: 0.126\n",
      "Loss after mini-batch   301: 2.088\n",
      "Loss after mini-batch   311: 1.619\n",
      "Loss after mini-batch   321: 0.215\n",
      "Loss after mini-batch   331: 0.172\n",
      "Loss after mini-batch   341: 1.817\n",
      "Loss after mini-batch   351: 0.907\n",
      "Loss after mini-batch   361: 7.062\n",
      "Loss after mini-batch   371: 0.232\n",
      "Training Loss: 1.680 \t\t Validation Loss:3.722\n",
      "Starting epoch 234\n",
      "Loss after mini-batch     1: 0.032\n",
      "Loss after mini-batch    11: 1.264\n",
      "Loss after mini-batch    21: 0.095\n",
      "Loss after mini-batch    31: 0.019\n",
      "Loss after mini-batch    41: 3.182\n",
      "Loss after mini-batch    51: 0.335\n",
      "Loss after mini-batch    61: 8.570\n",
      "Loss after mini-batch    71: 0.213\n",
      "Loss after mini-batch    81: 3.759\n",
      "Loss after mini-batch    91: 0.978\n",
      "Loss after mini-batch   101: 6.705\n",
      "Loss after mini-batch   111: 0.484\n",
      "Loss after mini-batch   121: 0.108\n",
      "Loss after mini-batch   131: 0.710\n",
      "Loss after mini-batch   141: 0.115\n",
      "Loss after mini-batch   151: 0.170\n",
      "Loss after mini-batch   161: 0.151\n",
      "Loss after mini-batch   171: 5.995\n",
      "Loss after mini-batch   181: 2.024\n",
      "Loss after mini-batch   191: 2.409\n",
      "Loss after mini-batch   201: 0.646\n",
      "Loss after mini-batch   211: 0.372\n",
      "Loss after mini-batch   221: 2.575\n",
      "Loss after mini-batch   231: 0.062\n",
      "Loss after mini-batch   241: 14.381\n",
      "Loss after mini-batch   251: 0.082\n",
      "Loss after mini-batch   261: 0.348\n",
      "Loss after mini-batch   271: 0.119\n",
      "Loss after mini-batch   281: 0.149\n",
      "Loss after mini-batch   291: 1.448\n",
      "Loss after mini-batch   301: 0.287\n",
      "Loss after mini-batch   311: 0.727\n",
      "Loss after mini-batch   321: 0.107\n",
      "Loss after mini-batch   331: 26.222\n",
      "Loss after mini-batch   341: 0.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   351: 0.104\n",
      "Loss after mini-batch   361: 1.644\n",
      "Loss after mini-batch   371: 0.029\n",
      "Training Loss: 5.048 \t\t Validation Loss:5.332\n",
      "Starting epoch 235\n",
      "Loss after mini-batch     1: 0.095\n",
      "Loss after mini-batch    11: 11.752\n",
      "Loss after mini-batch    21: 0.080\n",
      "Loss after mini-batch    31: 0.087\n",
      "Loss after mini-batch    41: 0.139\n",
      "Loss after mini-batch    51: 7.897\n",
      "Loss after mini-batch    61: 0.979\n",
      "Loss after mini-batch    71: 0.250\n",
      "Loss after mini-batch    81: 1.826\n",
      "Loss after mini-batch    91: 0.129\n",
      "Loss after mini-batch   101: 0.876\n",
      "Loss after mini-batch   111: 6.002\n",
      "Loss after mini-batch   121: 2.091\n",
      "Loss after mini-batch   131: 2.536\n",
      "Loss after mini-batch   141: 3.123\n",
      "Loss after mini-batch   151: 1.517\n",
      "Loss after mini-batch   161: 1.125\n",
      "Loss after mini-batch   171: 0.583\n",
      "Loss after mini-batch   181: 0.193\n",
      "Loss after mini-batch   191: 2.443\n",
      "Loss after mini-batch   201: 0.291\n",
      "Loss after mini-batch   211: 1.926\n",
      "Loss after mini-batch   221: 0.085\n",
      "Loss after mini-batch   231: 0.119\n",
      "Loss after mini-batch   241: 0.042\n",
      "Loss after mini-batch   251: 0.196\n",
      "Loss after mini-batch   261: 0.168\n",
      "Loss after mini-batch   271: 0.149\n",
      "Loss after mini-batch   281: 0.394\n",
      "Loss after mini-batch   291: 0.142\n",
      "Loss after mini-batch   301: 0.879\n",
      "Loss after mini-batch   311: 2.661\n",
      "Loss after mini-batch   321: 6.437\n",
      "Loss after mini-batch   331: 0.076\n",
      "Loss after mini-batch   341: 2.928\n",
      "Loss after mini-batch   351: 1.518\n",
      "Loss after mini-batch   361: 2.105\n",
      "Loss after mini-batch   371: 0.084\n",
      "Training Loss: 0.265 \t\t Validation Loss:3.614\n",
      "Starting epoch 236\n",
      "Loss after mini-batch     1: 8.815\n",
      "Loss after mini-batch    11: 1.914\n",
      "Loss after mini-batch    21: 7.929\n",
      "Loss after mini-batch    31: 1.374\n",
      "Loss after mini-batch    41: 0.073\n",
      "Loss after mini-batch    51: 0.071\n",
      "Loss after mini-batch    61: 5.377\n",
      "Loss after mini-batch    71: 0.147\n",
      "Loss after mini-batch    81: 2.357\n",
      "Loss after mini-batch    91: 0.291\n",
      "Loss after mini-batch   101: 0.549\n",
      "Loss after mini-batch   111: 0.039\n",
      "Loss after mini-batch   121: 0.144\n",
      "Loss after mini-batch   131: 1.408\n",
      "Loss after mini-batch   141: 0.299\n",
      "Loss after mini-batch   151: 2.654\n",
      "Loss after mini-batch   161: 6.209\n",
      "Loss after mini-batch   171: 3.829\n",
      "Loss after mini-batch   181: 0.046\n",
      "Loss after mini-batch   191: 0.262\n",
      "Loss after mini-batch   201: 0.134\n",
      "Loss after mini-batch   211: 0.785\n",
      "Loss after mini-batch   221: 1.311\n",
      "Loss after mini-batch   231: 0.664\n",
      "Loss after mini-batch   241: 0.300\n",
      "Loss after mini-batch   251: 0.210\n",
      "Loss after mini-batch   261: 0.274\n",
      "Loss after mini-batch   271: 0.031\n",
      "Loss after mini-batch   281: 7.760\n",
      "Loss after mini-batch   291: 0.052\n",
      "Loss after mini-batch   301: 0.053\n",
      "Loss after mini-batch   311: 1.351\n",
      "Loss after mini-batch   321: 0.163\n",
      "Loss after mini-batch   331: 0.070\n",
      "Loss after mini-batch   341: 0.649\n",
      "Loss after mini-batch   351: 0.164\n",
      "Loss after mini-batch   361: 12.616\n",
      "Loss after mini-batch   371: 0.108\n",
      "Training Loss: 0.646 \t\t Validation Loss:3.624\n",
      "Starting epoch 237\n",
      "Loss after mini-batch     1: 0.311\n",
      "Loss after mini-batch    11: 2.588\n",
      "Loss after mini-batch    21: 1.548\n",
      "Loss after mini-batch    31: 0.357\n",
      "Loss after mini-batch    41: 0.085\n",
      "Loss after mini-batch    51: 0.573\n",
      "Loss after mini-batch    61: 0.023\n",
      "Loss after mini-batch    71: 0.012\n",
      "Loss after mini-batch    81: 1.337\n",
      "Loss after mini-batch    91: 0.370\n",
      "Loss after mini-batch   101: 0.381\n",
      "Loss after mini-batch   111: 0.657\n",
      "Loss after mini-batch   121: 0.831\n",
      "Loss after mini-batch   131: 0.431\n",
      "Loss after mini-batch   141: 0.023\n",
      "Loss after mini-batch   151: 0.329\n",
      "Loss after mini-batch   161: 1.058\n",
      "Loss after mini-batch   171: 2.266\n",
      "Loss after mini-batch   181: 0.105\n",
      "Loss after mini-batch   191: 1.713\n",
      "Loss after mini-batch   201: 2.101\n",
      "Loss after mini-batch   211: 0.832\n",
      "Loss after mini-batch   221: 1.762\n",
      "Loss after mini-batch   231: 1.713\n",
      "Loss after mini-batch   241: 0.601\n",
      "Loss after mini-batch   251: 3.939\n",
      "Loss after mini-batch   261: 0.174\n",
      "Loss after mini-batch   271: 3.973\n",
      "Loss after mini-batch   281: 1.238\n",
      "Loss after mini-batch   291: 2.544\n",
      "Loss after mini-batch   301: 1.301\n",
      "Loss after mini-batch   311: 0.784\n",
      "Loss after mini-batch   321: 0.247\n",
      "Loss after mini-batch   331: 1.079\n",
      "Loss after mini-batch   341: 0.045\n",
      "Loss after mini-batch   351: 0.120\n",
      "Loss after mini-batch   361: 0.075\n",
      "Loss after mini-batch   371: 0.915\n",
      "Training Loss: 4.430 \t\t Validation Loss:11.002\n",
      "Starting epoch 238\n",
      "Loss after mini-batch     1: 25.741\n",
      "Loss after mini-batch    11: 0.282\n",
      "Loss after mini-batch    21: 3.307\n",
      "Loss after mini-batch    31: 0.505\n",
      "Loss after mini-batch    41: 0.746\n",
      "Loss after mini-batch    51: 3.908\n",
      "Loss after mini-batch    61: 7.226\n",
      "Loss after mini-batch    71: 0.328\n",
      "Loss after mini-batch    81: 3.385\n",
      "Loss after mini-batch    91: 0.139\n",
      "Loss after mini-batch   101: 7.611\n",
      "Loss after mini-batch   111: 8.132\n",
      "Loss after mini-batch   121: 0.821\n",
      "Loss after mini-batch   131: 0.293\n",
      "Loss after mini-batch   141: 1.696\n",
      "Loss after mini-batch   151: 0.098\n",
      "Loss after mini-batch   161: 12.639\n",
      "Loss after mini-batch   171: 2.926\n",
      "Loss after mini-batch   181: 0.028\n",
      "Loss after mini-batch   191: 0.042\n",
      "Loss after mini-batch   201: 2.704\n",
      "Loss after mini-batch   211: 5.848\n",
      "Loss after mini-batch   221: 1.666\n",
      "Loss after mini-batch   231: 0.246\n",
      "Loss after mini-batch   241: 3.126\n",
      "Loss after mini-batch   251: 0.341\n",
      "Loss after mini-batch   261: 0.986\n",
      "Loss after mini-batch   271: 0.558\n",
      "Loss after mini-batch   281: 0.178\n",
      "Loss after mini-batch   291: 1.497\n",
      "Loss after mini-batch   301: 4.671\n",
      "Loss after mini-batch   311: 0.170\n",
      "Loss after mini-batch   321: 0.525\n",
      "Loss after mini-batch   331: 1.297\n",
      "Loss after mini-batch   341: 0.320\n",
      "Loss after mini-batch   351: 4.508\n",
      "Loss after mini-batch   361: 0.064\n",
      "Loss after mini-batch   371: 3.893\n",
      "Training Loss: 0.412 \t\t Validation Loss:15.138\n",
      "Starting epoch 239\n",
      "Loss after mini-batch     1: 3.737\n",
      "Loss after mini-batch    11: 0.816\n",
      "Loss after mini-batch    21: 1.964\n",
      "Loss after mini-batch    31: 0.089\n",
      "Loss after mini-batch    41: 0.552\n",
      "Loss after mini-batch    51: 0.305\n",
      "Loss after mini-batch    61: 2.794\n",
      "Loss after mini-batch    71: 2.183\n",
      "Loss after mini-batch    81: 0.128\n",
      "Loss after mini-batch    91: 0.565\n",
      "Loss after mini-batch   101: 2.950\n",
      "Loss after mini-batch   111: 2.031\n",
      "Loss after mini-batch   121: 6.118\n",
      "Loss after mini-batch   131: 0.165\n",
      "Loss after mini-batch   141: 5.529\n",
      "Loss after mini-batch   151: 11.161\n",
      "Loss after mini-batch   161: 0.427\n",
      "Loss after mini-batch   171: 2.024\n",
      "Loss after mini-batch   181: 0.484\n",
      "Loss after mini-batch   191: 1.417\n",
      "Loss after mini-batch   201: 0.253\n",
      "Loss after mini-batch   211: 3.748\n",
      "Loss after mini-batch   221: 0.267\n",
      "Loss after mini-batch   231: 0.119\n",
      "Loss after mini-batch   241: 0.076\n",
      "Loss after mini-batch   251: 0.167\n",
      "Loss after mini-batch   261: 0.141\n",
      "Loss after mini-batch   271: 2.882\n",
      "Loss after mini-batch   281: 0.995\n",
      "Loss after mini-batch   291: 0.126\n",
      "Loss after mini-batch   301: 0.068\n",
      "Loss after mini-batch   311: 7.566\n",
      "Loss after mini-batch   321: 0.538\n",
      "Loss after mini-batch   331: 7.074\n",
      "Loss after mini-batch   341: 0.983\n",
      "Loss after mini-batch   351: 2.314\n",
      "Loss after mini-batch   361: 1.931\n",
      "Loss after mini-batch   371: 0.881\n",
      "Training Loss: 0.183 \t\t Validation Loss:1.194\n",
      "Starting epoch 240\n",
      "Loss after mini-batch     1: 0.132\n",
      "Loss after mini-batch    11: 1.075\n",
      "Loss after mini-batch    21: 0.555\n",
      "Loss after mini-batch    31: 2.064\n",
      "Loss after mini-batch    41: 0.201\n",
      "Loss after mini-batch    51: 0.542\n",
      "Loss after mini-batch    61: 0.530\n",
      "Loss after mini-batch    71: 1.760\n",
      "Loss after mini-batch    81: 0.100\n",
      "Loss after mini-batch    91: 1.142\n",
      "Loss after mini-batch   101: 2.008\n",
      "Loss after mini-batch   111: 0.120\n",
      "Loss after mini-batch   121: 0.084\n",
      "Loss after mini-batch   131: 1.691\n",
      "Loss after mini-batch   141: 1.262\n",
      "Loss after mini-batch   151: 5.995\n",
      "Loss after mini-batch   161: 1.566\n",
      "Loss after mini-batch   171: 0.180\n",
      "Loss after mini-batch   181: 0.834\n",
      "Loss after mini-batch   191: 0.135\n",
      "Loss after mini-batch   201: 0.379\n",
      "Loss after mini-batch   211: 7.904\n",
      "Loss after mini-batch   221: 0.196\n",
      "Loss after mini-batch   231: 1.279\n",
      "Loss after mini-batch   241: 0.087\n",
      "Loss after mini-batch   251: 1.250\n",
      "Loss after mini-batch   261: 0.279\n",
      "Loss after mini-batch   271: 1.049\n",
      "Loss after mini-batch   281: 0.413\n",
      "Loss after mini-batch   291: 0.054\n",
      "Loss after mini-batch   301: 0.061\n",
      "Loss after mini-batch   311: 0.057\n",
      "Loss after mini-batch   321: 0.175\n",
      "Loss after mini-batch   331: 0.239\n",
      "Loss after mini-batch   341: 0.398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   351: 0.060\n",
      "Loss after mini-batch   361: 0.065\n",
      "Loss after mini-batch   371: 2.122\n",
      "Training Loss: 6.239 \t\t Validation Loss:7.680\n",
      "Starting epoch 241\n",
      "Loss after mini-batch     1: 7.348\n",
      "Loss after mini-batch    11: 2.057\n",
      "Loss after mini-batch    21: 0.370\n",
      "Loss after mini-batch    31: 10.009\n",
      "Loss after mini-batch    41: 0.046\n",
      "Loss after mini-batch    51: 0.199\n",
      "Loss after mini-batch    61: 1.984\n",
      "Loss after mini-batch    71: 8.491\n",
      "Loss after mini-batch    81: 0.097\n",
      "Loss after mini-batch    91: 1.807\n",
      "Loss after mini-batch   101: 0.972\n",
      "Loss after mini-batch   111: 4.268\n",
      "Loss after mini-batch   121: 5.096\n",
      "Loss after mini-batch   131: 0.484\n",
      "Loss after mini-batch   141: 2.949\n",
      "Loss after mini-batch   151: 0.205\n",
      "Loss after mini-batch   161: 0.057\n",
      "Loss after mini-batch   171: 3.901\n",
      "Loss after mini-batch   181: 0.030\n",
      "Loss after mini-batch   191: 6.026\n",
      "Loss after mini-batch   201: 0.026\n",
      "Loss after mini-batch   211: 2.893\n",
      "Loss after mini-batch   221: 2.941\n",
      "Loss after mini-batch   231: 1.128\n",
      "Loss after mini-batch   241: 1.249\n",
      "Loss after mini-batch   251: 1.479\n",
      "Loss after mini-batch   261: 7.803\n",
      "Loss after mini-batch   271: 0.256\n",
      "Loss after mini-batch   281: 0.069\n",
      "Loss after mini-batch   291: 1.313\n",
      "Loss after mini-batch   301: 0.090\n",
      "Loss after mini-batch   311: 4.367\n",
      "Loss after mini-batch   321: 0.148\n",
      "Loss after mini-batch   331: 0.035\n",
      "Loss after mini-batch   341: 1.261\n",
      "Loss after mini-batch   351: 1.457\n",
      "Loss after mini-batch   361: 0.686\n",
      "Loss after mini-batch   371: 12.919\n",
      "Training Loss: 0.394 \t\t Validation Loss:5.948\n",
      "Starting epoch 242\n",
      "Loss after mini-batch     1: 0.549\n",
      "Loss after mini-batch    11: 1.226\n",
      "Loss after mini-batch    21: 0.107\n",
      "Loss after mini-batch    31: 0.037\n",
      "Loss after mini-batch    41: 7.884\n",
      "Loss after mini-batch    51: 0.076\n",
      "Loss after mini-batch    61: 1.337\n",
      "Loss after mini-batch    71: 0.170\n",
      "Loss after mini-batch    81: 4.432\n",
      "Loss after mini-batch    91: 0.124\n",
      "Loss after mini-batch   101: 1.304\n",
      "Loss after mini-batch   111: 1.166\n",
      "Loss after mini-batch   121: 1.423\n",
      "Loss after mini-batch   131: 6.086\n",
      "Loss after mini-batch   141: 0.100\n",
      "Loss after mini-batch   151: 0.218\n",
      "Loss after mini-batch   161: 0.225\n",
      "Loss after mini-batch   171: 7.664\n",
      "Loss after mini-batch   181: 0.036\n",
      "Loss after mini-batch   191: 0.581\n",
      "Loss after mini-batch   201: 0.159\n",
      "Loss after mini-batch   211: 0.321\n",
      "Loss after mini-batch   221: 0.142\n",
      "Loss after mini-batch   231: 1.777\n",
      "Loss after mini-batch   241: 0.081\n",
      "Loss after mini-batch   251: 0.090\n",
      "Loss after mini-batch   261: 0.591\n",
      "Loss after mini-batch   271: 0.161\n",
      "Loss after mini-batch   281: 0.039\n",
      "Loss after mini-batch   291: 0.351\n",
      "Loss after mini-batch   301: 4.459\n",
      "Loss after mini-batch   311: 0.426\n",
      "Loss after mini-batch   321: 0.204\n",
      "Loss after mini-batch   331: 0.695\n",
      "Loss after mini-batch   341: 0.301\n",
      "Loss after mini-batch   351: 1.097\n",
      "Loss after mini-batch   361: 0.282\n",
      "Loss after mini-batch   371: 0.857\n",
      "Training Loss: 0.594 \t\t Validation Loss:1.108\n",
      "Starting epoch 243\n",
      "Loss after mini-batch     1: 0.525\n",
      "Loss after mini-batch    11: 2.276\n",
      "Loss after mini-batch    21: 1.550\n",
      "Loss after mini-batch    31: 1.303\n",
      "Loss after mini-batch    41: 1.244\n",
      "Loss after mini-batch    51: 0.164\n",
      "Loss after mini-batch    61: 0.551\n",
      "Loss after mini-batch    71: 0.128\n",
      "Loss after mini-batch    81: 0.062\n",
      "Loss after mini-batch    91: 0.138\n",
      "Loss after mini-batch   101: 1.327\n",
      "Loss after mini-batch   111: 0.656\n",
      "Loss after mini-batch   121: 0.082\n",
      "Loss after mini-batch   131: 4.249\n",
      "Loss after mini-batch   141: 0.252\n",
      "Loss after mini-batch   151: 24.753\n",
      "Loss after mini-batch   161: 0.081\n",
      "Loss after mini-batch   171: 0.224\n",
      "Loss after mini-batch   181: 0.375\n",
      "Loss after mini-batch   191: 0.254\n",
      "Loss after mini-batch   201: 0.154\n",
      "Loss after mini-batch   211: 0.208\n",
      "Loss after mini-batch   221: 5.962\n",
      "Loss after mini-batch   231: 0.075\n",
      "Loss after mini-batch   241: 0.349\n",
      "Loss after mini-batch   251: 0.168\n",
      "Loss after mini-batch   261: 1.000\n",
      "Loss after mini-batch   271: 0.749\n",
      "Loss after mini-batch   281: 1.309\n",
      "Loss after mini-batch   291: 5.788\n",
      "Loss after mini-batch   301: 0.053\n",
      "Loss after mini-batch   311: 2.868\n",
      "Loss after mini-batch   321: 0.063\n",
      "Loss after mini-batch   331: 1.652\n",
      "Loss after mini-batch   341: 1.264\n",
      "Loss after mini-batch   351: 0.303\n",
      "Loss after mini-batch   361: 0.247\n",
      "Loss after mini-batch   371: 9.320\n",
      "Training Loss: 1.949 \t\t Validation Loss:3.834\n",
      "Starting epoch 244\n",
      "Loss after mini-batch     1: 8.407\n",
      "Loss after mini-batch    11: 0.291\n",
      "Loss after mini-batch    21: 3.055\n",
      "Loss after mini-batch    31: 3.816\n",
      "Loss after mini-batch    41: 0.092\n",
      "Loss after mini-batch    51: 0.137\n",
      "Loss after mini-batch    61: 0.151\n",
      "Loss after mini-batch    71: 0.748\n",
      "Loss after mini-batch    81: 1.161\n",
      "Loss after mini-batch    91: 0.970\n",
      "Loss after mini-batch   101: 0.181\n",
      "Loss after mini-batch   111: 0.166\n",
      "Loss after mini-batch   121: 0.411\n",
      "Loss after mini-batch   131: 0.840\n",
      "Loss after mini-batch   141: 0.085\n",
      "Loss after mini-batch   151: 1.251\n",
      "Loss after mini-batch   161: 0.690\n",
      "Loss after mini-batch   171: 8.327\n",
      "Loss after mini-batch   181: 0.242\n",
      "Loss after mini-batch   191: 1.617\n",
      "Loss after mini-batch   201: 1.626\n",
      "Loss after mini-batch   211: 0.313\n",
      "Loss after mini-batch   221: 6.220\n",
      "Loss after mini-batch   231: 7.173\n",
      "Loss after mini-batch   241: 2.524\n",
      "Loss after mini-batch   251: 0.105\n",
      "Loss after mini-batch   261: 0.043\n",
      "Loss after mini-batch   271: 4.814\n",
      "Loss after mini-batch   281: 0.221\n",
      "Loss after mini-batch   291: 11.476\n",
      "Loss after mini-batch   301: 0.057\n",
      "Loss after mini-batch   311: 5.955\n",
      "Loss after mini-batch   321: 1.707\n",
      "Loss after mini-batch   331: 3.170\n",
      "Loss after mini-batch   341: 0.222\n",
      "Loss after mini-batch   351: 1.657\n",
      "Loss after mini-batch   361: 2.616\n",
      "Loss after mini-batch   371: 0.772\n",
      "Training Loss: 0.878 \t\t Validation Loss:1.029\n",
      "Starting epoch 245\n",
      "Loss after mini-batch     1: 0.782\n",
      "Loss after mini-batch    11: 3.846\n",
      "Loss after mini-batch    21: 0.438\n",
      "Loss after mini-batch    31: 0.021\n",
      "Loss after mini-batch    41: 0.131\n",
      "Loss after mini-batch    51: 0.178\n",
      "Loss after mini-batch    61: 0.108\n",
      "Loss after mini-batch    71: 0.183\n",
      "Loss after mini-batch    81: 7.082\n",
      "Loss after mini-batch    91: 2.585\n",
      "Loss after mini-batch   101: 0.048\n",
      "Loss after mini-batch   111: 0.061\n",
      "Loss after mini-batch   121: 0.217\n",
      "Loss after mini-batch   131: 7.071\n",
      "Loss after mini-batch   141: 0.195\n",
      "Loss after mini-batch   151: 0.111\n",
      "Loss after mini-batch   161: 2.163\n",
      "Loss after mini-batch   171: 0.145\n",
      "Loss after mini-batch   181: 0.078\n",
      "Loss after mini-batch   191: 1.329\n",
      "Loss after mini-batch   201: 0.709\n",
      "Loss after mini-batch   211: 0.095\n",
      "Loss after mini-batch   221: 2.202\n",
      "Loss after mini-batch   231: 2.271\n",
      "Loss after mini-batch   241: 1.191\n",
      "Loss after mini-batch   251: 0.191\n",
      "Loss after mini-batch   261: 4.781\n",
      "Loss after mini-batch   271: 0.904\n",
      "Loss after mini-batch   281: 1.894\n",
      "Loss after mini-batch   291: 0.255\n",
      "Loss after mini-batch   301: 0.949\n",
      "Loss after mini-batch   311: 1.227\n",
      "Loss after mini-batch   321: 3.800\n",
      "Loss after mini-batch   331: 0.275\n",
      "Loss after mini-batch   341: 0.044\n",
      "Loss after mini-batch   351: 0.246\n",
      "Loss after mini-batch   361: 0.313\n",
      "Loss after mini-batch   371: 1.695\n",
      "Training Loss: 0.131 \t\t Validation Loss:0.416\n",
      "Starting epoch 246\n",
      "Loss after mini-batch     1: 0.240\n",
      "Loss after mini-batch    11: 1.126\n",
      "Loss after mini-batch    21: 0.980\n",
      "Loss after mini-batch    31: 1.471\n",
      "Loss after mini-batch    41: 1.793\n",
      "Loss after mini-batch    51: 0.028\n",
      "Loss after mini-batch    61: 3.667\n",
      "Loss after mini-batch    71: 0.229\n",
      "Loss after mini-batch    81: 1.439\n",
      "Loss after mini-batch    91: 0.232\n",
      "Loss after mini-batch   101: 24.801\n",
      "Loss after mini-batch   111: 0.110\n",
      "Loss after mini-batch   121: 0.963\n",
      "Loss after mini-batch   131: 0.350\n",
      "Loss after mini-batch   141: 0.291\n",
      "Loss after mini-batch   151: 0.793\n",
      "Loss after mini-batch   161: 0.659\n",
      "Loss after mini-batch   171: 1.937\n",
      "Loss after mini-batch   181: 0.419\n",
      "Loss after mini-batch   191: 0.667\n",
      "Loss after mini-batch   201: 1.428\n",
      "Loss after mini-batch   211: 0.759\n",
      "Loss after mini-batch   221: 1.297\n",
      "Loss after mini-batch   231: 0.105\n",
      "Loss after mini-batch   241: 0.092\n",
      "Loss after mini-batch   251: 1.114\n",
      "Loss after mini-batch   261: 0.109\n",
      "Loss after mini-batch   271: 8.208\n",
      "Loss after mini-batch   281: 0.047\n",
      "Loss after mini-batch   291: 0.083\n",
      "Loss after mini-batch   301: 1.034\n",
      "Loss after mini-batch   311: 0.112\n",
      "Loss after mini-batch   321: 2.262\n",
      "Loss after mini-batch   331: 1.448\n",
      "Loss after mini-batch   341: 3.780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   351: 5.889\n",
      "Loss after mini-batch   361: 0.061\n",
      "Loss after mini-batch   371: 0.050\n",
      "Training Loss: 2.011 \t\t Validation Loss:5.683\n",
      "Starting epoch 247\n",
      "Loss after mini-batch     1: 0.080\n",
      "Loss after mini-batch    11: 0.232\n",
      "Loss after mini-batch    21: 0.111\n",
      "Loss after mini-batch    31: 0.634\n",
      "Loss after mini-batch    41: 4.449\n",
      "Loss after mini-batch    51: 1.483\n",
      "Loss after mini-batch    61: 0.204\n",
      "Loss after mini-batch    71: 0.114\n",
      "Loss after mini-batch    81: 0.856\n",
      "Loss after mini-batch    91: 0.098\n",
      "Loss after mini-batch   101: 0.437\n",
      "Loss after mini-batch   111: 2.645\n",
      "Loss after mini-batch   121: 7.938\n",
      "Loss after mini-batch   131: 0.105\n",
      "Loss after mini-batch   141: 0.483\n",
      "Loss after mini-batch   151: 0.091\n",
      "Loss after mini-batch   161: 0.574\n",
      "Loss after mini-batch   171: 0.181\n",
      "Loss after mini-batch   181: 0.571\n",
      "Loss after mini-batch   191: 1.535\n",
      "Loss after mini-batch   201: 1.448\n",
      "Loss after mini-batch   211: 1.116\n",
      "Loss after mini-batch   221: 0.385\n",
      "Loss after mini-batch   231: 0.123\n",
      "Loss after mini-batch   241: 3.610\n",
      "Loss after mini-batch   251: 1.745\n",
      "Loss after mini-batch   261: 0.495\n",
      "Loss after mini-batch   271: 0.110\n",
      "Loss after mini-batch   281: 0.074\n",
      "Loss after mini-batch   291: 0.033\n",
      "Loss after mini-batch   301: 3.860\n",
      "Loss after mini-batch   311: 0.068\n",
      "Loss after mini-batch   321: 0.161\n",
      "Loss after mini-batch   331: 2.319\n",
      "Loss after mini-batch   341: 1.927\n",
      "Loss after mini-batch   351: 0.356\n",
      "Loss after mini-batch   361: 0.579\n",
      "Loss after mini-batch   371: 0.430\n",
      "Training Loss: 0.872 \t\t Validation Loss:1.632\n",
      "Starting epoch 248\n",
      "Loss after mini-batch     1: 0.384\n",
      "Loss after mini-batch    11: 0.031\n",
      "Loss after mini-batch    21: 1.591\n",
      "Loss after mini-batch    31: 0.986\n",
      "Loss after mini-batch    41: 11.358\n",
      "Loss after mini-batch    51: 0.081\n",
      "Loss after mini-batch    61: 1.857\n",
      "Loss after mini-batch    71: 0.048\n",
      "Loss after mini-batch    81: 0.439\n",
      "Loss after mini-batch    91: 0.049\n",
      "Loss after mini-batch   101: 0.170\n",
      "Loss after mini-batch   111: 0.431\n",
      "Loss after mini-batch   121: 0.145\n",
      "Loss after mini-batch   131: 1.046\n",
      "Loss after mini-batch   141: 0.074\n",
      "Loss after mini-batch   151: 0.065\n",
      "Loss after mini-batch   161: 1.019\n",
      "Loss after mini-batch   171: 1.249\n",
      "Loss after mini-batch   181: 0.106\n",
      "Loss after mini-batch   191: 0.084\n",
      "Loss after mini-batch   201: 0.362\n",
      "Loss after mini-batch   211: 2.837\n",
      "Loss after mini-batch   221: 0.959\n",
      "Loss after mini-batch   231: 1.242\n",
      "Loss after mini-batch   241: 0.086\n",
      "Loss after mini-batch   251: 0.096\n",
      "Loss after mini-batch   261: 0.832\n",
      "Loss after mini-batch   271: 2.617\n",
      "Loss after mini-batch   281: 1.752\n",
      "Loss after mini-batch   291: 2.500\n",
      "Loss after mini-batch   301: 12.669\n",
      "Loss after mini-batch   311: 0.145\n",
      "Loss after mini-batch   321: 7.846\n",
      "Loss after mini-batch   331: 0.399\n",
      "Loss after mini-batch   341: 0.764\n",
      "Loss after mini-batch   351: 1.908\n",
      "Loss after mini-batch   361: 0.088\n",
      "Loss after mini-batch   371: 0.091\n",
      "Training Loss: 0.007 \t\t Validation Loss:0.107\n",
      "Starting epoch 249\n",
      "Loss after mini-batch     1: 0.079\n",
      "Loss after mini-batch    11: 0.897\n",
      "Loss after mini-batch    21: 7.906\n",
      "Loss after mini-batch    31: 4.740\n",
      "Loss after mini-batch    41: 0.258\n",
      "Loss after mini-batch    51: 3.533\n",
      "Loss after mini-batch    61: 0.083\n",
      "Loss after mini-batch    71: 1.680\n",
      "Loss after mini-batch    81: 0.655\n",
      "Loss after mini-batch    91: 1.104\n",
      "Loss after mini-batch   101: 2.641\n",
      "Loss after mini-batch   111: 0.923\n",
      "Loss after mini-batch   121: 0.166\n",
      "Loss after mini-batch   131: 1.263\n",
      "Loss after mini-batch   141: 0.190\n",
      "Loss after mini-batch   151: 0.562\n",
      "Loss after mini-batch   161: 0.240\n",
      "Loss after mini-batch   171: 0.313\n",
      "Loss after mini-batch   181: 1.389\n",
      "Loss after mini-batch   191: 1.763\n",
      "Loss after mini-batch   201: 6.836\n",
      "Loss after mini-batch   211: 1.028\n",
      "Loss after mini-batch   221: 2.832\n",
      "Loss after mini-batch   231: 0.172\n",
      "Loss after mini-batch   241: 0.089\n",
      "Loss after mini-batch   251: 2.584\n",
      "Loss after mini-batch   261: 2.726\n",
      "Loss after mini-batch   271: 0.142\n",
      "Loss after mini-batch   281: 0.043\n",
      "Loss after mini-batch   291: 0.052\n",
      "Loss after mini-batch   301: 25.085\n",
      "Loss after mini-batch   311: 0.568\n",
      "Loss after mini-batch   321: 0.131\n",
      "Loss after mini-batch   331: 0.202\n",
      "Loss after mini-batch   341: 0.721\n",
      "Loss after mini-batch   351: 5.738\n",
      "Loss after mini-batch   361: 0.480\n",
      "Loss after mini-batch   371: 0.066\n",
      "Training Loss: 2.512 \t\t Validation Loss:4.548\n",
      "Starting epoch 250\n",
      "Loss after mini-batch     1: 0.183\n",
      "Loss after mini-batch    11: 0.017\n",
      "Loss after mini-batch    21: 0.051\n",
      "Loss after mini-batch    31: 1.911\n",
      "Loss after mini-batch    41: 0.118\n",
      "Loss after mini-batch    51: 8.494\n",
      "Loss after mini-batch    61: 1.727\n",
      "Loss after mini-batch    71: 0.118\n",
      "Loss after mini-batch    81: 0.138\n",
      "Loss after mini-batch    91: 0.072\n",
      "Loss after mini-batch   101: 7.947\n",
      "Loss after mini-batch   111: 0.470\n",
      "Loss after mini-batch   121: 0.107\n",
      "Loss after mini-batch   131: 4.309\n",
      "Loss after mini-batch   141: 0.309\n",
      "Loss after mini-batch   151: 1.250\n",
      "Loss after mini-batch   161: 5.963\n",
      "Loss after mini-batch   171: 0.991\n",
      "Loss after mini-batch   181: 0.716\n",
      "Loss after mini-batch   191: 1.760\n",
      "Loss after mini-batch   201: 1.664\n",
      "Loss after mini-batch   211: 0.711\n",
      "Loss after mini-batch   221: 0.185\n",
      "Loss after mini-batch   231: 0.359\n",
      "Loss after mini-batch   241: 1.295\n",
      "Loss after mini-batch   251: 0.684\n",
      "Loss after mini-batch   261: 1.970\n",
      "Loss after mini-batch   271: 0.851\n",
      "Loss after mini-batch   281: 2.243\n",
      "Loss after mini-batch   291: 0.753\n",
      "Loss after mini-batch   301: 1.194\n",
      "Loss after mini-batch   311: 2.463\n",
      "Loss after mini-batch   321: 0.362\n",
      "Loss after mini-batch   331: 0.101\n",
      "Loss after mini-batch   341: 1.084\n",
      "Loss after mini-batch   351: 0.111\n",
      "Loss after mini-batch   361: 0.120\n",
      "Loss after mini-batch   371: 1.107\n",
      "Training Loss: 8.180 \t\t Validation Loss:11.481\n",
      "Starting epoch 251\n",
      "Loss after mini-batch     1: 0.291\n",
      "Loss after mini-batch    11: 1.066\n",
      "Loss after mini-batch    21: 0.171\n",
      "Loss after mini-batch    31: 0.186\n",
      "Loss after mini-batch    41: 0.033\n",
      "Loss after mini-batch    51: 0.227\n",
      "Loss after mini-batch    61: 0.031\n",
      "Loss after mini-batch    71: 1.541\n",
      "Loss after mini-batch    81: 8.314\n",
      "Loss after mini-batch    91: 1.289\n",
      "Loss after mini-batch   101: 0.072\n",
      "Loss after mini-batch   111: 0.058\n",
      "Loss after mini-batch   121: 0.224\n",
      "Loss after mini-batch   131: 1.339\n",
      "Loss after mini-batch   141: 0.143\n",
      "Loss after mini-batch   151: 5.401\n",
      "Loss after mini-batch   161: 0.048\n",
      "Loss after mini-batch   171: 2.830\n",
      "Loss after mini-batch   181: 2.654\n",
      "Loss after mini-batch   191: 0.475\n",
      "Loss after mini-batch   201: 0.193\n",
      "Loss after mini-batch   211: 1.306\n",
      "Loss after mini-batch   221: 6.435\n",
      "Loss after mini-batch   231: 2.825\n",
      "Loss after mini-batch   241: 0.271\n",
      "Loss after mini-batch   251: 1.990\n",
      "Loss after mini-batch   261: 0.700\n",
      "Loss after mini-batch   271: 4.885\n",
      "Loss after mini-batch   281: 1.776\n",
      "Loss after mini-batch   291: 5.883\n",
      "Loss after mini-batch   301: 0.170\n",
      "Loss after mini-batch   311: 0.427\n",
      "Loss after mini-batch   321: 0.092\n",
      "Loss after mini-batch   331: 0.313\n",
      "Loss after mini-batch   341: 0.568\n",
      "Loss after mini-batch   351: 1.133\n",
      "Loss after mini-batch   361: 0.146\n",
      "Loss after mini-batch   371: 1.834\n",
      "Training Loss: 0.981 \t\t Validation Loss:1.987\n",
      "Starting epoch 252\n",
      "Loss after mini-batch     1: 0.455\n",
      "Loss after mini-batch    11: 1.765\n",
      "Loss after mini-batch    21: 0.357\n",
      "Loss after mini-batch    31: 0.916\n",
      "Loss after mini-batch    41: 0.067\n",
      "Loss after mini-batch    51: 0.396\n",
      "Loss after mini-batch    61: 1.014\n",
      "Loss after mini-batch    71: 0.970\n",
      "Loss after mini-batch    81: 0.255\n",
      "Loss after mini-batch    91: 4.438\n",
      "Loss after mini-batch   101: 0.386\n",
      "Loss after mini-batch   111: 0.138\n",
      "Loss after mini-batch   121: 0.411\n",
      "Loss after mini-batch   131: 1.292\n",
      "Loss after mini-batch   141: 0.125\n",
      "Loss after mini-batch   151: 0.772\n",
      "Loss after mini-batch   161: 1.263\n",
      "Loss after mini-batch   171: 0.574\n",
      "Loss after mini-batch   181: 1.332\n",
      "Loss after mini-batch   191: 0.039\n",
      "Loss after mini-batch   201: 0.741\n",
      "Loss after mini-batch   211: 4.770\n",
      "Loss after mini-batch   221: 0.073\n",
      "Loss after mini-batch   231: 1.203\n",
      "Loss after mini-batch   241: 0.217\n",
      "Loss after mini-batch   251: 0.044\n",
      "Loss after mini-batch   261: 0.071\n",
      "Loss after mini-batch   271: 2.684\n",
      "Loss after mini-batch   281: 0.094\n",
      "Loss after mini-batch   291: 10.017\n",
      "Loss after mini-batch   301: 0.151\n",
      "Loss after mini-batch   311: 0.034\n",
      "Loss after mini-batch   321: 0.877\n",
      "Loss after mini-batch   331: 0.269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   341: 0.174\n",
      "Loss after mini-batch   351: 1.090\n",
      "Loss after mini-batch   361: 0.010\n",
      "Loss after mini-batch   371: 0.146\n",
      "Training Loss: 0.101 \t\t Validation Loss:0.656\n",
      "Starting epoch 253\n",
      "Loss after mini-batch     1: 0.678\n",
      "Loss after mini-batch    11: 0.226\n",
      "Loss after mini-batch    21: 7.526\n",
      "Loss after mini-batch    31: 1.780\n",
      "Loss after mini-batch    41: 0.087\n",
      "Loss after mini-batch    51: 2.871\n",
      "Loss after mini-batch    61: 0.268\n",
      "Loss after mini-batch    71: 0.036\n",
      "Loss after mini-batch    81: 0.154\n",
      "Loss after mini-batch    91: 0.124\n",
      "Loss after mini-batch   101: 0.497\n",
      "Loss after mini-batch   111: 1.614\n",
      "Loss after mini-batch   121: 0.170\n",
      "Loss after mini-batch   131: 1.045\n",
      "Loss after mini-batch   141: 7.988\n",
      "Loss after mini-batch   151: 0.569\n",
      "Loss after mini-batch   161: 1.316\n",
      "Loss after mini-batch   171: 0.484\n",
      "Loss after mini-batch   181: 0.400\n",
      "Loss after mini-batch   191: 0.248\n",
      "Loss after mini-batch   201: 0.750\n",
      "Loss after mini-batch   211: 0.169\n",
      "Loss after mini-batch   221: 2.360\n",
      "Loss after mini-batch   231: 2.043\n",
      "Loss after mini-batch   241: 0.725\n",
      "Loss after mini-batch   251: 5.850\n",
      "Loss after mini-batch   261: 0.038\n",
      "Loss after mini-batch   271: 0.550\n",
      "Loss after mini-batch   281: 1.989\n",
      "Loss after mini-batch   291: 2.734\n",
      "Loss after mini-batch   301: 1.525\n",
      "Loss after mini-batch   311: 1.872\n",
      "Loss after mini-batch   321: 0.161\n",
      "Loss after mini-batch   331: 0.418\n",
      "Loss after mini-batch   341: 0.587\n",
      "Loss after mini-batch   351: 1.170\n",
      "Loss after mini-batch   361: 0.873\n",
      "Loss after mini-batch   371: 0.342\n",
      "Training Loss: 3.156 \t\t Validation Loss:10.275\n",
      "Starting epoch 254\n",
      "Loss after mini-batch     1: 0.568\n",
      "Loss after mini-batch    11: 7.517\n",
      "Loss after mini-batch    21: 1.133\n",
      "Loss after mini-batch    31: 1.193\n",
      "Loss after mini-batch    41: 2.141\n",
      "Loss after mini-batch    51: 1.214\n",
      "Loss after mini-batch    61: 7.500\n",
      "Loss after mini-batch    71: 2.505\n",
      "Loss after mini-batch    81: 0.898\n",
      "Loss after mini-batch    91: 1.511\n",
      "Loss after mini-batch   101: 0.117\n",
      "Loss after mini-batch   111: 0.435\n",
      "Loss after mini-batch   121: 0.459\n",
      "Loss after mini-batch   131: 1.697\n",
      "Loss after mini-batch   141: 1.938\n",
      "Loss after mini-batch   151: 0.539\n",
      "Loss after mini-batch   161: 0.070\n",
      "Loss after mini-batch   171: 0.229\n",
      "Loss after mini-batch   181: 7.486\n",
      "Loss after mini-batch   191: 0.091\n",
      "Loss after mini-batch   201: 0.068\n",
      "Loss after mini-batch   211: 3.501\n",
      "Loss after mini-batch   221: 0.124\n",
      "Loss after mini-batch   231: 0.154\n",
      "Loss after mini-batch   241: 2.381\n",
      "Loss after mini-batch   251: 0.558\n",
      "Loss after mini-batch   261: 0.172\n",
      "Loss after mini-batch   271: 0.263\n",
      "Loss after mini-batch   281: 0.682\n",
      "Loss after mini-batch   291: 0.749\n",
      "Loss after mini-batch   301: 1.445\n",
      "Loss after mini-batch   311: 0.046\n",
      "Loss after mini-batch   321: 0.033\n",
      "Loss after mini-batch   331: 4.372\n",
      "Loss after mini-batch   341: 3.624\n",
      "Loss after mini-batch   351: 0.820\n",
      "Loss after mini-batch   361: 2.303\n",
      "Loss after mini-batch   371: 0.011\n",
      "Training Loss: 1.162 \t\t Validation Loss:4.035\n",
      "Starting epoch 255\n",
      "Loss after mini-batch     1: 3.523\n",
      "Loss after mini-batch    11: 2.697\n",
      "Loss after mini-batch    21: 0.409\n",
      "Loss after mini-batch    31: 5.387\n",
      "Loss after mini-batch    41: 0.262\n",
      "Loss after mini-batch    51: 0.068\n",
      "Loss after mini-batch    61: 5.231\n",
      "Loss after mini-batch    71: 2.473\n",
      "Loss after mini-batch    81: 0.029\n",
      "Loss after mini-batch    91: 0.097\n",
      "Loss after mini-batch   101: 0.162\n",
      "Loss after mini-batch   111: 0.138\n",
      "Loss after mini-batch   121: 0.170\n",
      "Loss after mini-batch   131: 2.712\n",
      "Loss after mini-batch   141: 2.012\n",
      "Loss after mini-batch   151: 0.259\n",
      "Loss after mini-batch   161: 3.948\n",
      "Loss after mini-batch   171: 0.180\n",
      "Loss after mini-batch   181: 0.436\n",
      "Loss after mini-batch   191: 0.100\n",
      "Loss after mini-batch   201: 0.068\n",
      "Loss after mini-batch   211: 0.064\n",
      "Loss after mini-batch   221: 0.042\n",
      "Loss after mini-batch   231: 1.648\n",
      "Loss after mini-batch   241: 2.258\n",
      "Loss after mini-batch   251: 7.215\n",
      "Loss after mini-batch   261: 0.106\n",
      "Loss after mini-batch   271: 0.288\n",
      "Loss after mini-batch   281: 0.188\n",
      "Loss after mini-batch   291: 2.118\n",
      "Loss after mini-batch   301: 6.685\n",
      "Loss after mini-batch   311: 0.183\n",
      "Loss after mini-batch   321: 1.379\n",
      "Loss after mini-batch   331: 5.540\n",
      "Loss after mini-batch   341: 0.061\n",
      "Loss after mini-batch   351: 3.580\n",
      "Loss after mini-batch   361: 0.965\n",
      "Loss after mini-batch   371: 0.134\n",
      "Training Loss: 0.171 \t\t Validation Loss:0.543\n",
      "Starting epoch 256\n",
      "Loss after mini-batch     1: 7.234\n",
      "Loss after mini-batch    11: 4.870\n",
      "Loss after mini-batch    21: 0.106\n",
      "Loss after mini-batch    31: 0.491\n",
      "Loss after mini-batch    41: 1.013\n",
      "Loss after mini-batch    51: 0.885\n",
      "Loss after mini-batch    61: 0.172\n",
      "Loss after mini-batch    71: 1.166\n",
      "Loss after mini-batch    81: 0.534\n",
      "Loss after mini-batch    91: 0.295\n",
      "Loss after mini-batch   101: 1.548\n",
      "Loss after mini-batch   111: 0.311\n",
      "Loss after mini-batch   121: 0.314\n",
      "Loss after mini-batch   131: 0.020\n",
      "Loss after mini-batch   141: 0.430\n",
      "Loss after mini-batch   151: 7.071\n",
      "Loss after mini-batch   161: 0.080\n",
      "Loss after mini-batch   171: 0.550\n",
      "Loss after mini-batch   181: 0.381\n",
      "Loss after mini-batch   191: 0.680\n",
      "Loss after mini-batch   201: 1.076\n",
      "Loss after mini-batch   211: 4.200\n",
      "Loss after mini-batch   221: 2.823\n",
      "Loss after mini-batch   231: 7.784\n",
      "Loss after mini-batch   241: 1.974\n",
      "Loss after mini-batch   251: 13.692\n",
      "Loss after mini-batch   261: 0.228\n",
      "Loss after mini-batch   271: 0.852\n",
      "Loss after mini-batch   281: 0.160\n",
      "Loss after mini-batch   291: 0.129\n",
      "Loss after mini-batch   301: 1.854\n",
      "Loss after mini-batch   311: 0.692\n",
      "Loss after mini-batch   321: 1.705\n",
      "Loss after mini-batch   331: 0.031\n",
      "Loss after mini-batch   341: 0.440\n",
      "Loss after mini-batch   351: 0.424\n",
      "Loss after mini-batch   361: 4.525\n",
      "Loss after mini-batch   371: 2.664\n",
      "Training Loss: 0.215 \t\t Validation Loss:0.834\n",
      "Starting epoch 257\n",
      "Loss after mini-batch     1: 4.735\n",
      "Loss after mini-batch    11: 0.221\n",
      "Loss after mini-batch    21: 0.354\n",
      "Loss after mini-batch    31: 1.237\n",
      "Loss after mini-batch    41: 2.030\n",
      "Loss after mini-batch    51: 0.307\n",
      "Loss after mini-batch    61: 0.445\n",
      "Loss after mini-batch    71: 2.161\n",
      "Loss after mini-batch    81: 0.089\n",
      "Loss after mini-batch    91: 0.186\n",
      "Loss after mini-batch   101: 0.227\n",
      "Loss after mini-batch   111: 6.828\n",
      "Loss after mini-batch   121: 0.233\n",
      "Loss after mini-batch   131: 1.700\n",
      "Loss after mini-batch   141: 0.147\n",
      "Loss after mini-batch   151: 0.016\n",
      "Loss after mini-batch   161: 0.057\n",
      "Loss after mini-batch   171: 7.111\n",
      "Loss after mini-batch   181: 2.165\n",
      "Loss after mini-batch   191: 1.408\n",
      "Loss after mini-batch   201: 1.210\n",
      "Loss after mini-batch   211: 1.438\n",
      "Loss after mini-batch   221: 0.196\n",
      "Loss after mini-batch   231: 0.644\n",
      "Loss after mini-batch   241: 0.382\n",
      "Loss after mini-batch   251: 0.804\n",
      "Loss after mini-batch   261: 0.022\n",
      "Loss after mini-batch   271: 0.995\n",
      "Loss after mini-batch   281: 0.096\n",
      "Loss after mini-batch   291: 0.108\n",
      "Loss after mini-batch   301: 1.854\n",
      "Loss after mini-batch   311: 0.592\n",
      "Loss after mini-batch   321: 0.166\n",
      "Loss after mini-batch   331: 3.763\n",
      "Loss after mini-batch   341: 0.238\n",
      "Loss after mini-batch   351: 0.237\n",
      "Loss after mini-batch   361: 3.909\n",
      "Loss after mini-batch   371: 2.501\n",
      "Training Loss: 0.508 \t\t Validation Loss:3.573\n",
      "Starting epoch 258\n",
      "Loss after mini-batch     1: 13.308\n",
      "Loss after mini-batch    11: 0.173\n",
      "Loss after mini-batch    21: 0.555\n",
      "Loss after mini-batch    31: 1.739\n",
      "Loss after mini-batch    41: 1.510\n",
      "Loss after mini-batch    51: 2.346\n",
      "Loss after mini-batch    61: 5.446\n",
      "Loss after mini-batch    71: 0.769\n",
      "Loss after mini-batch    81: 2.772\n",
      "Loss after mini-batch    91: 2.494\n",
      "Loss after mini-batch   101: 0.086\n",
      "Loss after mini-batch   111: 0.222\n",
      "Loss after mini-batch   121: 2.117\n",
      "Loss after mini-batch   131: 1.259\n",
      "Loss after mini-batch   141: 0.992\n",
      "Loss after mini-batch   151: 7.518\n",
      "Loss after mini-batch   161: 1.188\n",
      "Loss after mini-batch   171: 5.488\n",
      "Loss after mini-batch   181: 0.348\n",
      "Loss after mini-batch   191: 0.196\n",
      "Loss after mini-batch   201: 2.762\n",
      "Loss after mini-batch   211: 0.187\n",
      "Loss after mini-batch   221: 0.126\n",
      "Loss after mini-batch   231: 0.106\n",
      "Loss after mini-batch   241: 8.341\n",
      "Loss after mini-batch   251: 1.282\n",
      "Loss after mini-batch   261: 8.737\n",
      "Loss after mini-batch   271: 1.702\n",
      "Loss after mini-batch   281: 0.052\n",
      "Loss after mini-batch   291: 2.661\n",
      "Loss after mini-batch   301: 0.072\n",
      "Loss after mini-batch   311: 0.854\n",
      "Loss after mini-batch   321: 0.290\n",
      "Loss after mini-batch   331: 2.307\n",
      "Loss after mini-batch   341: 0.212\n",
      "Loss after mini-batch   351: 0.222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   361: 4.029\n",
      "Loss after mini-batch   371: 0.544\n",
      "Training Loss: 0.082 \t\t Validation Loss:5.840\n",
      "Starting epoch 259\n",
      "Loss after mini-batch     1: 1.856\n",
      "Loss after mini-batch    11: 0.500\n",
      "Loss after mini-batch    21: 0.256\n",
      "Loss after mini-batch    31: 3.089\n",
      "Loss after mini-batch    41: 0.147\n",
      "Loss after mini-batch    51: 7.308\n",
      "Loss after mini-batch    61: 1.060\n",
      "Loss after mini-batch    71: 2.606\n",
      "Loss after mini-batch    81: 1.682\n",
      "Loss after mini-batch    91: 0.349\n",
      "Loss after mini-batch   101: 3.578\n",
      "Loss after mini-batch   111: 8.059\n",
      "Loss after mini-batch   121: 0.588\n",
      "Loss after mini-batch   131: 3.777\n",
      "Loss after mini-batch   141: 0.072\n",
      "Loss after mini-batch   151: 0.252\n",
      "Loss after mini-batch   161: 0.924\n",
      "Loss after mini-batch   171: 0.746\n",
      "Loss after mini-batch   181: 0.899\n",
      "Loss after mini-batch   191: 0.561\n",
      "Loss after mini-batch   201: 3.452\n",
      "Loss after mini-batch   211: 0.667\n",
      "Loss after mini-batch   221: 0.898\n",
      "Loss after mini-batch   231: 0.158\n",
      "Loss after mini-batch   241: 0.217\n",
      "Loss after mini-batch   251: 0.193\n",
      "Loss after mini-batch   261: 1.281\n",
      "Loss after mini-batch   271: 2.115\n",
      "Loss after mini-batch   281: 5.838\n",
      "Loss after mini-batch   291: 0.787\n",
      "Loss after mini-batch   301: 0.050\n",
      "Loss after mini-batch   311: 3.305\n",
      "Loss after mini-batch   321: 0.076\n",
      "Loss after mini-batch   331: 0.032\n",
      "Loss after mini-batch   341: 0.136\n",
      "Loss after mini-batch   351: 0.022\n",
      "Loss after mini-batch   361: 0.071\n",
      "Loss after mini-batch   371: 5.883\n",
      "Training Loss: 13.223 \t\t Validation Loss:14.168\n",
      "Starting epoch 260\n",
      "Loss after mini-batch     1: 1.256\n",
      "Loss after mini-batch    11: 1.249\n",
      "Loss after mini-batch    21: 0.685\n",
      "Loss after mini-batch    31: 0.227\n",
      "Loss after mini-batch    41: 1.727\n",
      "Loss after mini-batch    51: 0.487\n",
      "Loss after mini-batch    61: 0.124\n",
      "Loss after mini-batch    71: 0.148\n",
      "Loss after mini-batch    81: 2.760\n",
      "Loss after mini-batch    91: 0.119\n",
      "Loss after mini-batch   101: 0.050\n",
      "Loss after mini-batch   111: 1.419\n",
      "Loss after mini-batch   121: 0.347\n",
      "Loss after mini-batch   131: 7.710\n",
      "Loss after mini-batch   141: 7.408\n",
      "Loss after mini-batch   151: 8.392\n",
      "Loss after mini-batch   161: 3.666\n",
      "Loss after mini-batch   171: 1.385\n",
      "Loss after mini-batch   181: 0.381\n",
      "Loss after mini-batch   191: 0.248\n",
      "Loss after mini-batch   201: 1.104\n",
      "Loss after mini-batch   211: 3.222\n",
      "Loss after mini-batch   221: 0.097\n",
      "Loss after mini-batch   231: 1.285\n",
      "Loss after mini-batch   241: 1.743\n",
      "Loss after mini-batch   251: 0.066\n",
      "Loss after mini-batch   261: 1.243\n",
      "Loss after mini-batch   271: 0.968\n",
      "Loss after mini-batch   281: 0.303\n",
      "Loss after mini-batch   291: 9.921\n",
      "Loss after mini-batch   301: 0.184\n",
      "Loss after mini-batch   311: 0.106\n",
      "Loss after mini-batch   321: 3.092\n",
      "Loss after mini-batch   331: 0.624\n",
      "Loss after mini-batch   341: 0.122\n",
      "Loss after mini-batch   351: 2.292\n",
      "Loss after mini-batch   361: 0.775\n",
      "Loss after mini-batch   371: 2.034\n",
      "Training Loss: 1.126 \t\t Validation Loss:1.547\n",
      "Starting epoch 261\n",
      "Loss after mini-batch     1: 0.249\n",
      "Loss after mini-batch    11: 0.891\n",
      "Loss after mini-batch    21: 0.583\n",
      "Loss after mini-batch    31: 0.285\n",
      "Loss after mini-batch    41: 5.869\n",
      "Loss after mini-batch    51: 1.731\n",
      "Loss after mini-batch    61: 5.020\n",
      "Loss after mini-batch    71: 0.270\n",
      "Loss after mini-batch    81: 0.256\n",
      "Loss after mini-batch    91: 0.310\n",
      "Loss after mini-batch   101: 0.236\n",
      "Loss after mini-batch   111: 0.919\n",
      "Loss after mini-batch   121: 4.931\n",
      "Loss after mini-batch   131: 0.455\n",
      "Loss after mini-batch   141: 0.344\n",
      "Loss after mini-batch   151: 0.342\n",
      "Loss after mini-batch   161: 0.065\n",
      "Loss after mini-batch   171: 0.276\n",
      "Loss after mini-batch   181: 1.717\n",
      "Loss after mini-batch   191: 0.140\n",
      "Loss after mini-batch   201: 0.627\n",
      "Loss after mini-batch   211: 0.790\n",
      "Loss after mini-batch   221: 1.015\n",
      "Loss after mini-batch   231: 1.004\n",
      "Loss after mini-batch   241: 1.693\n",
      "Loss after mini-batch   251: 4.279\n",
      "Loss after mini-batch   261: 4.804\n",
      "Loss after mini-batch   271: 0.562\n",
      "Loss after mini-batch   281: 0.226\n",
      "Loss after mini-batch   291: 0.394\n",
      "Loss after mini-batch   301: 0.089\n",
      "Loss after mini-batch   311: 1.247\n",
      "Loss after mini-batch   321: 0.045\n",
      "Loss after mini-batch   331: 0.090\n",
      "Loss after mini-batch   341: 0.167\n",
      "Loss after mini-batch   351: 0.202\n",
      "Loss after mini-batch   361: 0.699\n",
      "Loss after mini-batch   371: 4.042\n",
      "Training Loss: 0.534 \t\t Validation Loss:0.915\n",
      "Starting epoch 262\n",
      "Loss after mini-batch     1: 0.019\n",
      "Loss after mini-batch    11: 0.164\n",
      "Loss after mini-batch    21: 14.728\n",
      "Loss after mini-batch    31: 0.113\n",
      "Loss after mini-batch    41: 1.907\n",
      "Loss after mini-batch    51: 16.196\n",
      "Loss after mini-batch    61: 1.668\n",
      "Loss after mini-batch    71: 0.189\n",
      "Loss after mini-batch    81: 8.508\n",
      "Loss after mini-batch    91: 2.103\n",
      "Loss after mini-batch   101: 12.000\n",
      "Loss after mini-batch   111: 0.983\n",
      "Loss after mini-batch   121: 1.473\n",
      "Loss after mini-batch   131: 0.275\n",
      "Loss after mini-batch   141: 0.924\n",
      "Loss after mini-batch   151: 0.335\n",
      "Loss after mini-batch   161: 1.285\n",
      "Loss after mini-batch   171: 2.735\n",
      "Loss after mini-batch   181: 0.115\n",
      "Loss after mini-batch   191: 1.659\n",
      "Loss after mini-batch   201: 1.751\n",
      "Loss after mini-batch   211: 0.276\n",
      "Loss after mini-batch   221: 0.115\n",
      "Loss after mini-batch   231: 0.186\n",
      "Loss after mini-batch   241: 1.119\n",
      "Loss after mini-batch   251: 0.265\n",
      "Loss after mini-batch   261: 2.353\n",
      "Loss after mini-batch   271: 0.174\n",
      "Loss after mini-batch   281: 0.120\n",
      "Loss after mini-batch   291: 4.587\n",
      "Loss after mini-batch   301: 0.375\n",
      "Loss after mini-batch   311: 0.015\n",
      "Loss after mini-batch   321: 3.440\n",
      "Loss after mini-batch   331: 0.788\n",
      "Loss after mini-batch   341: 0.864\n",
      "Loss after mini-batch   351: 0.177\n",
      "Loss after mini-batch   361: 3.298\n",
      "Loss after mini-batch   371: 6.127\n",
      "Training Loss: 9.902 \t\t Validation Loss:10.235\n",
      "Starting epoch 263\n",
      "Loss after mini-batch     1: 1.055\n",
      "Loss after mini-batch    11: 1.218\n",
      "Loss after mini-batch    21: 2.461\n",
      "Loss after mini-batch    31: 1.591\n",
      "Loss after mini-batch    41: 0.981\n",
      "Loss after mini-batch    51: 0.256\n",
      "Loss after mini-batch    61: 0.179\n",
      "Loss after mini-batch    71: 0.103\n",
      "Loss after mini-batch    81: 0.143\n",
      "Loss after mini-batch    91: 0.167\n",
      "Loss after mini-batch   101: 0.074\n",
      "Loss after mini-batch   111: 0.693\n",
      "Loss after mini-batch   121: 2.272\n",
      "Loss after mini-batch   131: 0.052\n",
      "Loss after mini-batch   141: 0.305\n",
      "Loss after mini-batch   151: 1.241\n",
      "Loss after mini-batch   161: 3.718\n",
      "Loss after mini-batch   171: 3.329\n",
      "Loss after mini-batch   181: 0.387\n",
      "Loss after mini-batch   191: 0.503\n",
      "Loss after mini-batch   201: 6.484\n",
      "Loss after mini-batch   211: 1.376\n",
      "Loss after mini-batch   221: 0.107\n",
      "Loss after mini-batch   231: 1.492\n",
      "Loss after mini-batch   241: 1.392\n",
      "Loss after mini-batch   251: 4.542\n",
      "Loss after mini-batch   261: 0.057\n",
      "Loss after mini-batch   271: 0.097\n",
      "Loss after mini-batch   281: 0.652\n",
      "Loss after mini-batch   291: 1.549\n",
      "Loss after mini-batch   301: 0.322\n",
      "Loss after mini-batch   311: 1.242\n",
      "Loss after mini-batch   321: 2.002\n",
      "Loss after mini-batch   331: 3.254\n",
      "Loss after mini-batch   341: 3.846\n",
      "Loss after mini-batch   351: 0.110\n",
      "Loss after mini-batch   361: 0.052\n",
      "Loss after mini-batch   371: 0.776\n",
      "Training Loss: 2.592 \t\t Validation Loss:5.613\n",
      "Starting epoch 264\n",
      "Loss after mini-batch     1: 1.894\n",
      "Loss after mini-batch    11: 0.166\n",
      "Loss after mini-batch    21: 0.487\n",
      "Loss after mini-batch    31: 0.071\n",
      "Loss after mini-batch    41: 0.076\n",
      "Loss after mini-batch    51: 0.288\n",
      "Loss after mini-batch    61: 0.249\n",
      "Loss after mini-batch    71: 2.159\n",
      "Loss after mini-batch    81: 0.110\n",
      "Loss after mini-batch    91: 0.196\n",
      "Loss after mini-batch   101: 0.305\n",
      "Loss after mini-batch   111: 0.144\n",
      "Loss after mini-batch   121: 0.397\n",
      "Loss after mini-batch   131: 2.212\n",
      "Loss after mini-batch   141: 0.945\n",
      "Loss after mini-batch   151: 7.890\n",
      "Loss after mini-batch   161: 2.494\n",
      "Loss after mini-batch   171: 0.489\n",
      "Loss after mini-batch   181: 0.149\n",
      "Loss after mini-batch   191: 0.304\n",
      "Loss after mini-batch   201: 3.409\n",
      "Loss after mini-batch   211: 5.756\n",
      "Loss after mini-batch   221: 0.541\n",
      "Loss after mini-batch   231: 0.476\n",
      "Loss after mini-batch   241: 0.173\n",
      "Loss after mini-batch   251: 0.007\n",
      "Loss after mini-batch   261: 0.176\n",
      "Loss after mini-batch   271: 4.629\n",
      "Loss after mini-batch   281: 0.236\n",
      "Loss after mini-batch   291: 0.725\n",
      "Loss after mini-batch   301: 4.036\n",
      "Loss after mini-batch   311: 0.164\n",
      "Loss after mini-batch   321: 0.134\n",
      "Loss after mini-batch   331: 0.310\n",
      "Loss after mini-batch   341: 2.413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   351: 0.660\n",
      "Loss after mini-batch   361: 8.393\n",
      "Loss after mini-batch   371: 0.748\n",
      "Training Loss: 2.699 \t\t Validation Loss:4.976\n",
      "Starting epoch 265\n",
      "Loss after mini-batch     1: 0.092\n",
      "Loss after mini-batch    11: 1.029\n",
      "Loss after mini-batch    21: 0.135\n",
      "Loss after mini-batch    31: 0.343\n",
      "Loss after mini-batch    41: 7.078\n",
      "Loss after mini-batch    51: 1.098\n",
      "Loss after mini-batch    61: 0.842\n",
      "Loss after mini-batch    71: 0.054\n",
      "Loss after mini-batch    81: 0.125\n",
      "Loss after mini-batch    91: 7.847\n",
      "Loss after mini-batch   101: 2.755\n",
      "Loss after mini-batch   111: 0.095\n",
      "Loss after mini-batch   121: 2.550\n",
      "Loss after mini-batch   131: 1.807\n",
      "Loss after mini-batch   141: 1.302\n",
      "Loss after mini-batch   151: 0.056\n",
      "Loss after mini-batch   161: 1.171\n",
      "Loss after mini-batch   171: 2.436\n",
      "Loss after mini-batch   181: 1.924\n",
      "Loss after mini-batch   191: 0.063\n",
      "Loss after mini-batch   201: 0.975\n",
      "Loss after mini-batch   211: 0.295\n",
      "Loss after mini-batch   221: 0.035\n",
      "Loss after mini-batch   231: 0.159\n",
      "Loss after mini-batch   241: 0.196\n",
      "Loss after mini-batch   251: 2.660\n",
      "Loss after mini-batch   261: 1.696\n",
      "Loss after mini-batch   271: 4.913\n",
      "Loss after mini-batch   281: 0.101\n",
      "Loss after mini-batch   291: 1.322\n",
      "Loss after mini-batch   301: 0.425\n",
      "Loss after mini-batch   311: 5.776\n",
      "Loss after mini-batch   321: 5.915\n",
      "Loss after mini-batch   331: 0.956\n",
      "Loss after mini-batch   341: 0.146\n",
      "Loss after mini-batch   351: 0.212\n",
      "Loss after mini-batch   361: 0.491\n",
      "Loss after mini-batch   371: 0.204\n",
      "Training Loss: 1.116 \t\t Validation Loss:1.188\n",
      "Starting epoch 266\n",
      "Loss after mini-batch     1: 0.948\n",
      "Loss after mini-batch    11: 1.037\n",
      "Loss after mini-batch    21: 0.608\n",
      "Loss after mini-batch    31: 8.387\n",
      "Loss after mini-batch    41: 1.658\n",
      "Loss after mini-batch    51: 0.384\n",
      "Loss after mini-batch    61: 0.079\n",
      "Loss after mini-batch    71: 3.565\n",
      "Loss after mini-batch    81: 0.476\n",
      "Loss after mini-batch    91: 0.212\n",
      "Loss after mini-batch   101: 2.693\n",
      "Loss after mini-batch   111: 0.368\n",
      "Loss after mini-batch   121: 2.141\n",
      "Loss after mini-batch   131: 0.197\n",
      "Loss after mini-batch   141: 0.133\n",
      "Loss after mini-batch   151: 3.715\n",
      "Loss after mini-batch   161: 0.405\n",
      "Loss after mini-batch   171: 10.096\n",
      "Loss after mini-batch   181: 0.245\n",
      "Loss after mini-batch   191: 0.176\n",
      "Loss after mini-batch   201: 2.010\n",
      "Loss after mini-batch   211: 1.386\n",
      "Loss after mini-batch   221: 0.504\n",
      "Loss after mini-batch   231: 2.676\n",
      "Loss after mini-batch   241: 0.116\n",
      "Loss after mini-batch   251: 0.231\n",
      "Loss after mini-batch   261: 0.322\n",
      "Loss after mini-batch   271: 1.494\n",
      "Loss after mini-batch   281: 1.441\n",
      "Loss after mini-batch   291: 0.108\n",
      "Loss after mini-batch   301: 1.311\n",
      "Loss after mini-batch   311: 0.384\n",
      "Loss after mini-batch   321: 0.434\n",
      "Loss after mini-batch   331: 0.075\n",
      "Loss after mini-batch   341: 0.281\n",
      "Loss after mini-batch   351: 0.247\n",
      "Loss after mini-batch   361: 0.287\n",
      "Loss after mini-batch   371: 0.148\n",
      "Training Loss: 0.762 \t\t Validation Loss:1.786\n",
      "Starting epoch 267\n",
      "Loss after mini-batch     1: 0.228\n",
      "Loss after mini-batch    11: 0.453\n",
      "Loss after mini-batch    21: 2.552\n",
      "Loss after mini-batch    31: 1.025\n",
      "Loss after mini-batch    41: 0.191\n",
      "Loss after mini-batch    51: 0.216\n",
      "Loss after mini-batch    61: 0.836\n",
      "Loss after mini-batch    71: 8.798\n",
      "Loss after mini-batch    81: 0.280\n",
      "Loss after mini-batch    91: 0.279\n",
      "Loss after mini-batch   101: 0.079\n",
      "Loss after mini-batch   111: 11.216\n",
      "Loss after mini-batch   121: 4.172\n",
      "Loss after mini-batch   131: 0.166\n",
      "Loss after mini-batch   141: 7.378\n",
      "Loss after mini-batch   151: 5.916\n",
      "Loss after mini-batch   161: 0.399\n",
      "Loss after mini-batch   171: 0.267\n",
      "Loss after mini-batch   181: 7.044\n",
      "Loss after mini-batch   191: 1.453\n",
      "Loss after mini-batch   201: 2.451\n",
      "Loss after mini-batch   211: 13.225\n",
      "Loss after mini-batch   221: 0.624\n",
      "Loss after mini-batch   231: 1.388\n",
      "Loss after mini-batch   241: 0.051\n",
      "Loss after mini-batch   251: 0.089\n",
      "Loss after mini-batch   261: 1.179\n",
      "Loss after mini-batch   271: 7.523\n",
      "Loss after mini-batch   281: 2.572\n",
      "Loss after mini-batch   291: 0.176\n",
      "Loss after mini-batch   301: 0.104\n",
      "Loss after mini-batch   311: 0.181\n",
      "Loss after mini-batch   321: 0.132\n",
      "Loss after mini-batch   331: 4.684\n",
      "Loss after mini-batch   341: 1.885\n",
      "Loss after mini-batch   351: 0.252\n",
      "Loss after mini-batch   361: 0.090\n",
      "Loss after mini-batch   371: 0.118\n",
      "Training Loss: 8.688 \t\t Validation Loss:14.830\n",
      "Starting epoch 268\n",
      "Loss after mini-batch     1: 1.976\n",
      "Loss after mini-batch    11: 0.787\n",
      "Loss after mini-batch    21: 0.849\n",
      "Loss after mini-batch    31: 0.176\n",
      "Loss after mini-batch    41: 1.020\n",
      "Loss after mini-batch    51: 0.188\n",
      "Loss after mini-batch    61: 0.223\n",
      "Loss after mini-batch    71: 0.140\n",
      "Loss after mini-batch    81: 0.034\n",
      "Loss after mini-batch    91: 0.057\n",
      "Loss after mini-batch   101: 1.477\n",
      "Loss after mini-batch   111: 13.664\n",
      "Loss after mini-batch   121: 0.481\n",
      "Loss after mini-batch   131: 0.054\n",
      "Loss after mini-batch   141: 0.543\n",
      "Loss after mini-batch   151: 0.227\n",
      "Loss after mini-batch   161: 0.798\n",
      "Loss after mini-batch   171: 0.069\n",
      "Loss after mini-batch   181: 1.229\n",
      "Loss after mini-batch   191: 0.669\n",
      "Loss after mini-batch   201: 0.031\n",
      "Loss after mini-batch   211: 0.444\n",
      "Loss after mini-batch   221: 0.123\n",
      "Loss after mini-batch   231: 0.142\n",
      "Loss after mini-batch   241: 0.177\n",
      "Loss after mini-batch   251: 1.182\n",
      "Loss after mini-batch   261: 5.921\n",
      "Loss after mini-batch   271: 0.119\n",
      "Loss after mini-batch   281: 0.100\n",
      "Loss after mini-batch   291: 0.269\n",
      "Loss after mini-batch   301: 0.481\n",
      "Loss after mini-batch   311: 1.284\n",
      "Loss after mini-batch   321: 1.638\n",
      "Loss after mini-batch   331: 1.754\n",
      "Loss after mini-batch   341: 1.384\n",
      "Loss after mini-batch   351: 0.099\n",
      "Loss after mini-batch   361: 2.704\n",
      "Loss after mini-batch   371: 1.164\n",
      "Training Loss: 24.330 \t\t Validation Loss:25.773\n",
      "Starting epoch 269\n",
      "Loss after mini-batch     1: 1.617\n",
      "Loss after mini-batch    11: 1.151\n",
      "Loss after mini-batch    21: 7.075\n",
      "Loss after mini-batch    31: 0.148\n",
      "Loss after mini-batch    41: 0.123\n",
      "Loss after mini-batch    51: 1.164\n",
      "Loss after mini-batch    61: 0.366\n",
      "Loss after mini-batch    71: 0.185\n",
      "Loss after mini-batch    81: 0.015\n",
      "Loss after mini-batch    91: 0.189\n",
      "Loss after mini-batch   101: 0.920\n",
      "Loss after mini-batch   111: 2.147\n",
      "Loss after mini-batch   121: 0.049\n",
      "Loss after mini-batch   131: 0.225\n",
      "Loss after mini-batch   141: 0.221\n",
      "Loss after mini-batch   151: 8.503\n",
      "Loss after mini-batch   161: 0.036\n",
      "Loss after mini-batch   171: 0.170\n",
      "Loss after mini-batch   181: 0.404\n",
      "Loss after mini-batch   191: 0.074\n",
      "Loss after mini-batch   201: 1.600\n",
      "Loss after mini-batch   211: 1.293\n",
      "Loss after mini-batch   221: 0.018\n",
      "Loss after mini-batch   231: 0.060\n",
      "Loss after mini-batch   241: 0.068\n",
      "Loss after mini-batch   251: 0.016\n",
      "Loss after mini-batch   261: 0.223\n",
      "Loss after mini-batch   271: 0.576\n",
      "Loss after mini-batch   281: 0.534\n",
      "Loss after mini-batch   291: 5.642\n",
      "Loss after mini-batch   301: 0.325\n",
      "Loss after mini-batch   311: 0.232\n",
      "Loss after mini-batch   321: 0.470\n",
      "Loss after mini-batch   331: 0.244\n",
      "Loss after mini-batch   341: 0.048\n",
      "Loss after mini-batch   351: 1.410\n",
      "Loss after mini-batch   361: 0.177\n",
      "Loss after mini-batch   371: 1.892\n",
      "Training Loss: 0.251 \t\t Validation Loss:5.994\n",
      "Starting epoch 270\n",
      "Loss after mini-batch     1: 4.686\n",
      "Loss after mini-batch    11: 2.000\n",
      "Loss after mini-batch    21: 1.431\n",
      "Loss after mini-batch    31: 0.356\n",
      "Loss after mini-batch    41: 0.162\n",
      "Loss after mini-batch    51: 0.245\n",
      "Loss after mini-batch    61: 0.049\n",
      "Loss after mini-batch    71: 0.060\n",
      "Loss after mini-batch    81: 6.921\n",
      "Loss after mini-batch    91: 0.167\n",
      "Loss after mini-batch   101: 0.327\n",
      "Loss after mini-batch   111: 0.267\n",
      "Loss after mini-batch   121: 0.135\n",
      "Loss after mini-batch   131: 0.077\n",
      "Loss after mini-batch   141: 4.011\n",
      "Loss after mini-batch   151: 7.427\n",
      "Loss after mini-batch   161: 0.695\n",
      "Loss after mini-batch   171: 0.174\n",
      "Loss after mini-batch   181: 0.637\n",
      "Loss after mini-batch   191: 2.025\n",
      "Loss after mini-batch   201: 0.149\n",
      "Loss after mini-batch   211: 0.107\n",
      "Loss after mini-batch   221: 2.844\n",
      "Loss after mini-batch   231: 0.447\n",
      "Loss after mini-batch   241: 1.032\n",
      "Loss after mini-batch   251: 0.811\n",
      "Loss after mini-batch   261: 1.313\n",
      "Loss after mini-batch   271: 0.988\n",
      "Loss after mini-batch   281: 0.173\n",
      "Loss after mini-batch   291: 0.172\n",
      "Loss after mini-batch   301: 0.047\n",
      "Loss after mini-batch   311: 0.063\n",
      "Loss after mini-batch   321: 0.373\n",
      "Loss after mini-batch   331: 6.409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   341: 2.136\n",
      "Loss after mini-batch   351: 0.053\n",
      "Loss after mini-batch   361: 0.105\n",
      "Loss after mini-batch   371: 0.118\n",
      "Training Loss: 1.563 \t\t Validation Loss:5.446\n",
      "Starting epoch 271\n",
      "Loss after mini-batch     1: 3.960\n",
      "Loss after mini-batch    11: 1.236\n",
      "Loss after mini-batch    21: 0.282\n",
      "Loss after mini-batch    31: 3.214\n",
      "Loss after mini-batch    41: 1.434\n",
      "Loss after mini-batch    51: 0.288\n",
      "Loss after mini-batch    61: 1.628\n",
      "Loss after mini-batch    71: 2.964\n",
      "Loss after mini-batch    81: 0.058\n",
      "Loss after mini-batch    91: 0.303\n",
      "Loss after mini-batch   101: 0.035\n",
      "Loss after mini-batch   111: 3.735\n",
      "Loss after mini-batch   121: 0.139\n",
      "Loss after mini-batch   131: 0.204\n",
      "Loss after mini-batch   141: 0.734\n",
      "Loss after mini-batch   151: 0.576\n",
      "Loss after mini-batch   161: 1.413\n",
      "Loss after mini-batch   171: 0.119\n",
      "Loss after mini-batch   181: 0.505\n",
      "Loss after mini-batch   191: 0.987\n",
      "Loss after mini-batch   201: 0.149\n",
      "Loss after mini-batch   211: 0.098\n",
      "Loss after mini-batch   221: 0.748\n",
      "Loss after mini-batch   231: 6.829\n",
      "Loss after mini-batch   241: 0.242\n",
      "Loss after mini-batch   251: 1.769\n",
      "Loss after mini-batch   261: 5.377\n",
      "Loss after mini-batch   271: 0.293\n",
      "Loss after mini-batch   281: 0.086\n",
      "Loss after mini-batch   291: 0.820\n",
      "Loss after mini-batch   301: 4.119\n",
      "Loss after mini-batch   311: 0.272\n",
      "Loss after mini-batch   321: 0.981\n",
      "Loss after mini-batch   331: 2.197\n",
      "Loss after mini-batch   341: 0.059\n",
      "Loss after mini-batch   351: 0.754\n",
      "Loss after mini-batch   361: 0.147\n",
      "Loss after mini-batch   371: 0.620\n",
      "Training Loss: 0.122 \t\t Validation Loss:0.278\n",
      "Starting epoch 272\n",
      "Loss after mini-batch     1: 2.416\n",
      "Loss after mini-batch    11: 1.832\n",
      "Loss after mini-batch    21: 0.040\n",
      "Loss after mini-batch    31: 1.664\n",
      "Loss after mini-batch    41: 0.420\n",
      "Loss after mini-batch    51: 0.151\n",
      "Loss after mini-batch    61: 6.213\n",
      "Loss after mini-batch    71: 1.559\n",
      "Loss after mini-batch    81: 0.257\n",
      "Loss after mini-batch    91: 1.080\n",
      "Loss after mini-batch   101: 1.200\n",
      "Loss after mini-batch   111: 1.697\n",
      "Loss after mini-batch   121: 0.300\n",
      "Loss after mini-batch   131: 0.200\n",
      "Loss after mini-batch   141: 7.837\n",
      "Loss after mini-batch   151: 0.155\n",
      "Loss after mini-batch   161: 0.121\n",
      "Loss after mini-batch   171: 5.039\n",
      "Loss after mini-batch   181: 0.168\n",
      "Loss after mini-batch   191: 0.182\n",
      "Loss after mini-batch   201: 0.267\n",
      "Loss after mini-batch   211: 7.670\n",
      "Loss after mini-batch   221: 0.173\n",
      "Loss after mini-batch   231: 1.654\n",
      "Loss after mini-batch   241: 1.741\n",
      "Loss after mini-batch   251: 0.106\n",
      "Loss after mini-batch   261: 9.043\n",
      "Loss after mini-batch   271: 1.073\n",
      "Loss after mini-batch   281: 0.121\n",
      "Loss after mini-batch   291: 0.836\n",
      "Loss after mini-batch   301: 0.132\n",
      "Loss after mini-batch   311: 4.034\n",
      "Loss after mini-batch   321: 0.409\n",
      "Loss after mini-batch   331: 2.186\n",
      "Loss after mini-batch   341: 3.915\n",
      "Loss after mini-batch   351: 1.961\n",
      "Loss after mini-batch   361: 0.980\n",
      "Loss after mini-batch   371: 13.074\n",
      "Training Loss: 0.870 \t\t Validation Loss:0.912\n",
      "Starting epoch 273\n",
      "Loss after mini-batch     1: 1.018\n",
      "Loss after mini-batch    11: 0.410\n",
      "Loss after mini-batch    21: 1.706\n",
      "Loss after mini-batch    31: 1.398\n",
      "Loss after mini-batch    41: 0.826\n",
      "Loss after mini-batch    51: 2.511\n",
      "Loss after mini-batch    61: 3.216\n",
      "Loss after mini-batch    71: 2.907\n",
      "Loss after mini-batch    81: 1.586\n",
      "Loss after mini-batch    91: 0.386\n",
      "Loss after mini-batch   101: 0.140\n",
      "Loss after mini-batch   111: 0.129\n",
      "Loss after mini-batch   121: 0.977\n",
      "Loss after mini-batch   131: 0.279\n",
      "Loss after mini-batch   141: 0.134\n",
      "Loss after mini-batch   151: 1.087\n",
      "Loss after mini-batch   161: 0.863\n",
      "Loss after mini-batch   171: 1.291\n",
      "Loss after mini-batch   181: 0.242\n",
      "Loss after mini-batch   191: 0.234\n",
      "Loss after mini-batch   201: 8.634\n",
      "Loss after mini-batch   211: 0.950\n",
      "Loss after mini-batch   221: 2.610\n",
      "Loss after mini-batch   231: 1.220\n",
      "Loss after mini-batch   241: 0.155\n",
      "Loss after mini-batch   251: 0.034\n",
      "Loss after mini-batch   261: 0.159\n",
      "Loss after mini-batch   271: 0.035\n",
      "Loss after mini-batch   281: 1.890\n",
      "Loss after mini-batch   291: 0.844\n",
      "Loss after mini-batch   301: 7.628\n",
      "Loss after mini-batch   311: 1.041\n",
      "Loss after mini-batch   321: 1.321\n",
      "Loss after mini-batch   331: 0.135\n",
      "Loss after mini-batch   341: 0.310\n",
      "Loss after mini-batch   351: 0.190\n",
      "Loss after mini-batch   361: 0.150\n",
      "Loss after mini-batch   371: 0.038\n",
      "Training Loss: 0.495 \t\t Validation Loss:0.799\n",
      "Starting epoch 274\n",
      "Loss after mini-batch     1: 3.224\n",
      "Loss after mini-batch    11: 3.772\n",
      "Loss after mini-batch    21: 1.375\n",
      "Loss after mini-batch    31: 0.946\n",
      "Loss after mini-batch    41: 1.362\n",
      "Loss after mini-batch    51: 1.441\n",
      "Loss after mini-batch    61: 0.108\n",
      "Loss after mini-batch    71: 1.700\n",
      "Loss after mini-batch    81: 0.049\n",
      "Loss after mini-batch    91: 0.886\n",
      "Loss after mini-batch   101: 2.304\n",
      "Loss after mini-batch   111: 0.132\n",
      "Loss after mini-batch   121: 0.863\n",
      "Loss after mini-batch   131: 0.167\n",
      "Loss after mini-batch   141: 3.055\n",
      "Loss after mini-batch   151: 0.952\n",
      "Loss after mini-batch   161: 0.631\n",
      "Loss after mini-batch   171: 10.505\n",
      "Loss after mini-batch   181: 0.744\n",
      "Loss after mini-batch   191: 1.448\n",
      "Loss after mini-batch   201: 0.120\n",
      "Loss after mini-batch   211: 2.169\n",
      "Loss after mini-batch   221: 1.964\n",
      "Loss after mini-batch   231: 0.612\n",
      "Loss after mini-batch   241: 0.906\n",
      "Loss after mini-batch   251: 5.925\n",
      "Loss after mini-batch   261: 1.578\n",
      "Loss after mini-batch   271: 11.666\n",
      "Loss after mini-batch   281: 0.086\n",
      "Loss after mini-batch   291: 0.080\n",
      "Loss after mini-batch   301: 0.319\n",
      "Loss after mini-batch   311: 0.535\n",
      "Loss after mini-batch   321: 9.959\n",
      "Loss after mini-batch   331: 0.325\n",
      "Loss after mini-batch   341: 1.437\n",
      "Loss after mini-batch   351: 1.477\n",
      "Loss after mini-batch   361: 2.472\n",
      "Loss after mini-batch   371: 11.659\n",
      "Training Loss: 0.301 \t\t Validation Loss:3.565\n",
      "Starting epoch 275\n",
      "Loss after mini-batch     1: 1.983\n",
      "Loss after mini-batch    11: 0.181\n",
      "Loss after mini-batch    21: 0.252\n",
      "Loss after mini-batch    31: 0.418\n",
      "Loss after mini-batch    41: 2.899\n",
      "Loss after mini-batch    51: 7.808\n",
      "Loss after mini-batch    61: 0.080\n",
      "Loss after mini-batch    71: 0.057\n",
      "Loss after mini-batch    81: 0.271\n",
      "Loss after mini-batch    91: 0.981\n",
      "Loss after mini-batch   101: 0.175\n",
      "Loss after mini-batch   111: 6.703\n",
      "Loss after mini-batch   121: 0.148\n",
      "Loss after mini-batch   131: 10.200\n",
      "Loss after mini-batch   141: 8.055\n",
      "Loss after mini-batch   151: 0.203\n",
      "Loss after mini-batch   161: 0.092\n",
      "Loss after mini-batch   171: 9.025\n",
      "Loss after mini-batch   181: 0.127\n",
      "Loss after mini-batch   191: 0.969\n",
      "Loss after mini-batch   201: 0.259\n",
      "Loss after mini-batch   211: 1.211\n",
      "Loss after mini-batch   221: 0.254\n",
      "Loss after mini-batch   231: 0.032\n",
      "Loss after mini-batch   241: 1.565\n",
      "Loss after mini-batch   251: 0.139\n",
      "Loss after mini-batch   261: 0.134\n",
      "Loss after mini-batch   271: 0.070\n",
      "Loss after mini-batch   281: 1.467\n",
      "Loss after mini-batch   291: 0.329\n",
      "Loss after mini-batch   301: 0.366\n",
      "Loss after mini-batch   311: 1.065\n",
      "Loss after mini-batch   321: 5.833\n",
      "Loss after mini-batch   331: 0.628\n",
      "Loss after mini-batch   341: 2.089\n",
      "Loss after mini-batch   351: 0.120\n",
      "Loss after mini-batch   361: 0.086\n",
      "Loss after mini-batch   371: 7.349\n",
      "Training Loss: 0.125 \t\t Validation Loss:2.012\n",
      "Starting epoch 276\n",
      "Loss after mini-batch     1: 0.125\n",
      "Loss after mini-batch    11: 6.887\n",
      "Loss after mini-batch    21: 5.080\n",
      "Loss after mini-batch    31: 0.191\n",
      "Loss after mini-batch    41: 1.402\n",
      "Loss after mini-batch    51: 0.637\n",
      "Loss after mini-batch    61: 1.124\n",
      "Loss after mini-batch    71: 2.018\n",
      "Loss after mini-batch    81: 0.075\n",
      "Loss after mini-batch    91: 0.615\n",
      "Loss after mini-batch   101: 0.136\n",
      "Loss after mini-batch   111: 0.054\n",
      "Loss after mini-batch   121: 4.910\n",
      "Loss after mini-batch   131: 8.507\n",
      "Loss after mini-batch   141: 6.278\n",
      "Loss after mini-batch   151: 1.021\n",
      "Loss after mini-batch   161: 7.848\n",
      "Loss after mini-batch   171: 0.055\n",
      "Loss after mini-batch   181: 0.720\n",
      "Loss after mini-batch   191: 1.995\n",
      "Loss after mini-batch   201: 0.234\n",
      "Loss after mini-batch   211: 0.136\n",
      "Loss after mini-batch   221: 0.102\n",
      "Loss after mini-batch   231: 0.222\n",
      "Loss after mini-batch   241: 0.382\n",
      "Loss after mini-batch   251: 0.195\n",
      "Loss after mini-batch   261: 0.057\n",
      "Loss after mini-batch   271: 0.167\n",
      "Loss after mini-batch   281: 0.722\n",
      "Loss after mini-batch   291: 0.757\n",
      "Loss after mini-batch   301: 0.119\n",
      "Loss after mini-batch   311: 0.092\n",
      "Loss after mini-batch   321: 2.299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   331: 0.534\n",
      "Loss after mini-batch   341: 0.542\n",
      "Loss after mini-batch   351: 0.477\n",
      "Loss after mini-batch   361: 0.253\n",
      "Loss after mini-batch   371: 1.447\n",
      "Training Loss: 1.528 \t\t Validation Loss:1.628\n",
      "Starting epoch 277\n",
      "Loss after mini-batch     1: 0.119\n",
      "Loss after mini-batch    11: 1.396\n",
      "Loss after mini-batch    21: 0.210\n",
      "Loss after mini-batch    31: 0.819\n",
      "Loss after mini-batch    41: 0.123\n",
      "Loss after mini-batch    51: 0.860\n",
      "Loss after mini-batch    61: 0.818\n",
      "Loss after mini-batch    71: 0.626\n",
      "Loss after mini-batch    81: 0.175\n",
      "Loss after mini-batch    91: 2.429\n",
      "Loss after mini-batch   101: 0.495\n",
      "Loss after mini-batch   111: 0.338\n",
      "Loss after mini-batch   121: 2.230\n",
      "Loss after mini-batch   131: 3.542\n",
      "Loss after mini-batch   141: 0.251\n",
      "Loss after mini-batch   151: 0.136\n",
      "Loss after mini-batch   161: 0.420\n",
      "Loss after mini-batch   171: 0.063\n",
      "Loss after mini-batch   181: 0.071\n",
      "Loss after mini-batch   191: 1.269\n",
      "Loss after mini-batch   201: 0.177\n",
      "Loss after mini-batch   211: 5.205\n",
      "Loss after mini-batch   221: 0.394\n",
      "Loss after mini-batch   231: 0.069\n",
      "Loss after mini-batch   241: 1.223\n",
      "Loss after mini-batch   251: 0.166\n",
      "Loss after mini-batch   261: 7.372\n",
      "Loss after mini-batch   271: 0.984\n",
      "Loss after mini-batch   281: 7.342\n",
      "Loss after mini-batch   291: 0.348\n",
      "Loss after mini-batch   301: 5.856\n",
      "Loss after mini-batch   311: 0.113\n",
      "Loss after mini-batch   321: 0.081\n",
      "Loss after mini-batch   331: 1.323\n",
      "Loss after mini-batch   341: 0.139\n",
      "Loss after mini-batch   351: 0.124\n",
      "Loss after mini-batch   361: 0.149\n",
      "Loss after mini-batch   371: 0.688\n",
      "Training Loss: 0.313 \t\t Validation Loss:2.111\n",
      "Starting epoch 278\n",
      "Loss after mini-batch     1: 1.156\n",
      "Loss after mini-batch    11: 0.265\n",
      "Loss after mini-batch    21: 0.351\n",
      "Loss after mini-batch    31: 0.093\n",
      "Loss after mini-batch    41: 0.267\n",
      "Loss after mini-batch    51: 2.753\n",
      "Loss after mini-batch    61: 1.157\n",
      "Loss after mini-batch    71: 0.230\n",
      "Loss after mini-batch    81: 1.208\n",
      "Loss after mini-batch    91: 0.740\n",
      "Loss after mini-batch   101: 0.072\n",
      "Loss after mini-batch   111: 7.905\n",
      "Loss after mini-batch   121: 0.037\n",
      "Loss after mini-batch   131: 0.258\n",
      "Loss after mini-batch   141: 0.259\n",
      "Loss after mini-batch   151: 1.174\n",
      "Loss after mini-batch   161: 1.658\n",
      "Loss after mini-batch   171: 0.620\n",
      "Loss after mini-batch   181: 1.649\n",
      "Loss after mini-batch   191: 2.332\n",
      "Loss after mini-batch   201: 1.241\n",
      "Loss after mini-batch   211: 0.147\n",
      "Loss after mini-batch   221: 0.230\n",
      "Loss after mini-batch   231: 0.211\n",
      "Loss after mini-batch   241: 3.336\n",
      "Loss after mini-batch   251: 5.701\n",
      "Loss after mini-batch   261: 0.276\n",
      "Loss after mini-batch   271: 1.334\n",
      "Loss after mini-batch   281: 0.258\n",
      "Loss after mini-batch   291: 0.512\n",
      "Loss after mini-batch   301: 0.833\n",
      "Loss after mini-batch   311: 0.401\n",
      "Loss after mini-batch   321: 0.497\n",
      "Loss after mini-batch   331: 0.317\n",
      "Loss after mini-batch   341: 0.118\n",
      "Loss after mini-batch   351: 0.074\n",
      "Loss after mini-batch   361: 1.461\n",
      "Loss after mini-batch   371: 0.399\n",
      "Training Loss: 0.112 \t\t Validation Loss:4.190\n",
      "Starting epoch 279\n",
      "Loss after mini-batch     1: 0.361\n",
      "Loss after mini-batch    11: 6.895\n",
      "Loss after mini-batch    21: 0.017\n",
      "Loss after mini-batch    31: 0.471\n",
      "Loss after mini-batch    41: 0.212\n",
      "Loss after mini-batch    51: 0.154\n",
      "Loss after mini-batch    61: 0.082\n",
      "Loss after mini-batch    71: 1.508\n",
      "Loss after mini-batch    81: 6.642\n",
      "Loss after mini-batch    91: 0.256\n",
      "Loss after mini-batch   101: 0.306\n",
      "Loss after mini-batch   111: 10.096\n",
      "Loss after mini-batch   121: 12.733\n",
      "Loss after mini-batch   131: 4.123\n",
      "Loss after mini-batch   141: 0.153\n",
      "Loss after mini-batch   151: 0.745\n",
      "Loss after mini-batch   161: 7.422\n",
      "Loss after mini-batch   171: 1.468\n",
      "Loss after mini-batch   181: 0.845\n",
      "Loss after mini-batch   191: 0.173\n",
      "Loss after mini-batch   201: 1.047\n",
      "Loss after mini-batch   211: 0.032\n",
      "Loss after mini-batch   221: 0.599\n",
      "Loss after mini-batch   231: 0.766\n",
      "Loss after mini-batch   241: 0.234\n",
      "Loss after mini-batch   251: 0.071\n",
      "Loss after mini-batch   261: 2.691\n",
      "Loss after mini-batch   271: 0.629\n",
      "Loss after mini-batch   281: 0.099\n",
      "Loss after mini-batch   291: 0.308\n",
      "Loss after mini-batch   301: 0.804\n",
      "Loss after mini-batch   311: 0.947\n",
      "Loss after mini-batch   321: 0.513\n",
      "Loss after mini-batch   331: 0.161\n",
      "Loss after mini-batch   341: 0.149\n",
      "Loss after mini-batch   351: 2.845\n",
      "Loss after mini-batch   361: 0.109\n",
      "Loss after mini-batch   371: 5.842\n",
      "Training Loss: 0.040 \t\t Validation Loss:0.212\n",
      "Starting epoch 280\n",
      "Loss after mini-batch     1: 0.248\n",
      "Loss after mini-batch    11: 2.621\n",
      "Loss after mini-batch    21: 0.647\n",
      "Loss after mini-batch    31: 2.370\n",
      "Loss after mini-batch    41: 0.350\n",
      "Loss after mini-batch    51: 0.243\n",
      "Loss after mini-batch    61: 0.202\n",
      "Loss after mini-batch    71: 0.154\n",
      "Loss after mini-batch    81: 0.236\n",
      "Loss after mini-batch    91: 0.024\n",
      "Loss after mini-batch   101: 0.112\n",
      "Loss after mini-batch   111: 0.887\n",
      "Loss after mini-batch   121: 0.628\n",
      "Loss after mini-batch   131: 0.259\n",
      "Loss after mini-batch   141: 1.997\n",
      "Loss after mini-batch   151: 0.024\n",
      "Loss after mini-batch   161: 1.513\n",
      "Loss after mini-batch   171: 0.064\n",
      "Loss after mini-batch   181: 7.399\n",
      "Loss after mini-batch   191: 1.422\n",
      "Loss after mini-batch   201: 0.746\n",
      "Loss after mini-batch   211: 0.277\n",
      "Loss after mini-batch   221: 6.936\n",
      "Loss after mini-batch   231: 0.209\n",
      "Loss after mini-batch   241: 0.355\n",
      "Loss after mini-batch   251: 0.496\n",
      "Loss after mini-batch   261: 1.167\n",
      "Loss after mini-batch   271: 0.205\n",
      "Loss after mini-batch   281: 0.758\n",
      "Loss after mini-batch   291: 5.841\n",
      "Loss after mini-batch   301: 0.931\n",
      "Loss after mini-batch   311: 0.773\n",
      "Loss after mini-batch   321: 1.066\n",
      "Loss after mini-batch   331: 3.711\n",
      "Loss after mini-batch   341: 1.399\n",
      "Loss after mini-batch   351: 0.913\n",
      "Loss after mini-batch   361: 0.754\n",
      "Loss after mini-batch   371: 0.372\n",
      "Training Loss: 1.682 \t\t Validation Loss:2.118\n",
      "Starting epoch 281\n",
      "Loss after mini-batch     1: 0.518\n",
      "Loss after mini-batch    11: 1.525\n",
      "Loss after mini-batch    21: 0.671\n",
      "Loss after mini-batch    31: 0.704\n",
      "Loss after mini-batch    41: 0.048\n",
      "Loss after mini-batch    51: 0.239\n",
      "Loss after mini-batch    61: 4.040\n",
      "Loss after mini-batch    71: 0.111\n",
      "Loss after mini-batch    81: 0.201\n",
      "Loss after mini-batch    91: 0.056\n",
      "Loss after mini-batch   101: 0.205\n",
      "Loss after mini-batch   111: 0.107\n",
      "Loss after mini-batch   121: 6.993\n",
      "Loss after mini-batch   131: 1.128\n",
      "Loss after mini-batch   141: 0.056\n",
      "Loss after mini-batch   151: 0.498\n",
      "Loss after mini-batch   161: 0.230\n",
      "Loss after mini-batch   171: 6.139\n",
      "Loss after mini-batch   181: 0.055\n",
      "Loss after mini-batch   191: 0.699\n",
      "Loss after mini-batch   201: 0.343\n",
      "Loss after mini-batch   211: 0.290\n",
      "Loss after mini-batch   221: 0.175\n",
      "Loss after mini-batch   231: 23.860\n",
      "Loss after mini-batch   241: 0.069\n",
      "Loss after mini-batch   251: 2.005\n",
      "Loss after mini-batch   261: 0.024\n",
      "Loss after mini-batch   271: 1.339\n",
      "Loss after mini-batch   281: 0.507\n",
      "Loss after mini-batch   291: 0.332\n",
      "Loss after mini-batch   301: 5.656\n",
      "Loss after mini-batch   311: 0.324\n",
      "Loss after mini-batch   321: 0.915\n",
      "Loss after mini-batch   331: 0.840\n",
      "Loss after mini-batch   341: 0.166\n",
      "Loss after mini-batch   351: 1.553\n",
      "Loss after mini-batch   361: 0.014\n",
      "Loss after mini-batch   371: 0.581\n",
      "Training Loss: 0.450 \t\t Validation Loss:1.009\n",
      "Starting epoch 282\n",
      "Loss after mini-batch     1: 0.254\n",
      "Loss after mini-batch    11: 0.607\n",
      "Loss after mini-batch    21: 0.351\n",
      "Loss after mini-batch    31: 1.117\n",
      "Loss after mini-batch    41: 2.261\n",
      "Loss after mini-batch    51: 0.033\n",
      "Loss after mini-batch    61: 0.137\n",
      "Loss after mini-batch    71: 0.056\n",
      "Loss after mini-batch    81: 0.076\n",
      "Loss after mini-batch    91: 2.497\n",
      "Loss after mini-batch   101: 0.934\n",
      "Loss after mini-batch   111: 2.130\n",
      "Loss after mini-batch   121: 1.546\n",
      "Loss after mini-batch   131: 3.302\n",
      "Loss after mini-batch   141: 0.149\n",
      "Loss after mini-batch   151: 0.263\n",
      "Loss after mini-batch   161: 0.106\n",
      "Loss after mini-batch   171: 1.548\n",
      "Loss after mini-batch   181: 0.509\n",
      "Loss after mini-batch   191: 0.127\n",
      "Loss after mini-batch   201: 2.508\n",
      "Loss after mini-batch   211: 0.501\n",
      "Loss after mini-batch   221: 0.042\n",
      "Loss after mini-batch   231: 1.355\n",
      "Loss after mini-batch   241: 0.865\n",
      "Loss after mini-batch   251: 1.770\n",
      "Loss after mini-batch   261: 5.908\n",
      "Loss after mini-batch   271: 0.329\n",
      "Loss after mini-batch   281: 0.234\n",
      "Loss after mini-batch   291: 0.473\n",
      "Loss after mini-batch   301: 0.080\n",
      "Loss after mini-batch   311: 0.176\n",
      "Loss after mini-batch   321: 0.174\n",
      "Loss after mini-batch   331: 0.638\n",
      "Loss after mini-batch   341: 0.131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   351: 2.223\n",
      "Loss after mini-batch   361: 1.149\n",
      "Loss after mini-batch   371: 0.307\n",
      "Training Loss: 0.208 \t\t Validation Loss:2.877\n",
      "Starting epoch 283\n",
      "Loss after mini-batch     1: 6.308\n",
      "Loss after mini-batch    11: 2.504\n",
      "Loss after mini-batch    21: 2.381\n",
      "Loss after mini-batch    31: 0.748\n",
      "Loss after mini-batch    41: 1.382\n",
      "Loss after mini-batch    51: 0.221\n",
      "Loss after mini-batch    61: 0.826\n",
      "Loss after mini-batch    71: 0.583\n",
      "Loss after mini-batch    81: 0.170\n",
      "Loss after mini-batch    91: 7.752\n",
      "Loss after mini-batch   101: 3.417\n",
      "Loss after mini-batch   111: 0.781\n",
      "Loss after mini-batch   121: 6.757\n",
      "Loss after mini-batch   131: 0.122\n",
      "Loss after mini-batch   141: 0.126\n",
      "Loss after mini-batch   151: 0.440\n",
      "Loss after mini-batch   161: 0.310\n",
      "Loss after mini-batch   171: 0.208\n",
      "Loss after mini-batch   181: 7.003\n",
      "Loss after mini-batch   191: 0.200\n",
      "Loss after mini-batch   201: 0.228\n",
      "Loss after mini-batch   211: 0.068\n",
      "Loss after mini-batch   221: 0.770\n",
      "Loss after mini-batch   231: 0.059\n",
      "Loss after mini-batch   241: 0.330\n",
      "Loss after mini-batch   251: 0.074\n",
      "Loss after mini-batch   261: 0.304\n",
      "Loss after mini-batch   271: 2.713\n",
      "Loss after mini-batch   281: 0.378\n",
      "Loss after mini-batch   291: 0.038\n",
      "Loss after mini-batch   301: 1.282\n",
      "Loss after mini-batch   311: 0.045\n",
      "Loss after mini-batch   321: 1.051\n",
      "Loss after mini-batch   331: 0.024\n",
      "Loss after mini-batch   341: 0.401\n",
      "Loss after mini-batch   351: 14.686\n",
      "Loss after mini-batch   361: 0.832\n",
      "Loss after mini-batch   371: 2.175\n",
      "Training Loss: 1.940 \t\t Validation Loss:1.946\n",
      "Starting epoch 284\n",
      "Loss after mini-batch     1: 0.336\n",
      "Loss after mini-batch    11: 0.266\n",
      "Loss after mini-batch    21: 6.830\n",
      "Loss after mini-batch    31: 1.892\n",
      "Loss after mini-batch    41: 4.514\n",
      "Loss after mini-batch    51: 2.531\n",
      "Loss after mini-batch    61: 0.500\n",
      "Loss after mini-batch    71: 1.374\n",
      "Loss after mini-batch    81: 0.212\n",
      "Loss after mini-batch    91: 13.292\n",
      "Loss after mini-batch   101: 4.094\n",
      "Loss after mini-batch   111: 0.352\n",
      "Loss after mini-batch   121: 0.056\n",
      "Loss after mini-batch   131: 1.293\n",
      "Loss after mini-batch   141: 0.630\n",
      "Loss after mini-batch   151: 0.103\n",
      "Loss after mini-batch   161: 0.919\n",
      "Loss after mini-batch   171: 0.117\n",
      "Loss after mini-batch   181: 0.350\n",
      "Loss after mini-batch   191: 0.242\n",
      "Loss after mini-batch   201: 1.985\n",
      "Loss after mini-batch   211: 2.784\n",
      "Loss after mini-batch   221: 5.481\n",
      "Loss after mini-batch   231: 0.121\n",
      "Loss after mini-batch   241: 0.083\n",
      "Loss after mini-batch   251: 0.087\n",
      "Loss after mini-batch   261: 1.579\n",
      "Loss after mini-batch   271: 0.907\n",
      "Loss after mini-batch   281: 0.102\n",
      "Loss after mini-batch   291: 3.592\n",
      "Loss after mini-batch   301: 0.192\n",
      "Loss after mini-batch   311: 0.052\n",
      "Loss after mini-batch   321: 0.029\n",
      "Loss after mini-batch   331: 0.014\n",
      "Loss after mini-batch   341: 0.062\n",
      "Loss after mini-batch   351: 0.188\n",
      "Loss after mini-batch   361: 0.192\n",
      "Loss after mini-batch   371: 1.140\n",
      "Training Loss: 0.059 \t\t Validation Loss:1.915\n",
      "Starting epoch 285\n",
      "Loss after mini-batch     1: 6.815\n",
      "Loss after mini-batch    11: 7.430\n",
      "Loss after mini-batch    21: 0.343\n",
      "Loss after mini-batch    31: 0.526\n",
      "Loss after mini-batch    41: 1.472\n",
      "Loss after mini-batch    51: 2.660\n",
      "Loss after mini-batch    61: 0.132\n",
      "Loss after mini-batch    71: 0.254\n",
      "Loss after mini-batch    81: 1.563\n",
      "Loss after mini-batch    91: 0.297\n",
      "Loss after mini-batch   101: 0.304\n",
      "Loss after mini-batch   111: 0.724\n",
      "Loss after mini-batch   121: 2.845\n",
      "Loss after mini-batch   131: 0.293\n",
      "Loss after mini-batch   141: 0.458\n",
      "Loss after mini-batch   151: 0.181\n",
      "Loss after mini-batch   161: 0.133\n",
      "Loss after mini-batch   171: 2.097\n",
      "Loss after mini-batch   181: 1.014\n",
      "Loss after mini-batch   191: 0.353\n",
      "Loss after mini-batch   201: 0.126\n",
      "Loss after mini-batch   211: 0.207\n",
      "Loss after mini-batch   221: 0.115\n",
      "Loss after mini-batch   231: 0.136\n",
      "Loss after mini-batch   241: 1.408\n",
      "Loss after mini-batch   251: 3.482\n",
      "Loss after mini-batch   261: 0.148\n",
      "Loss after mini-batch   271: 4.339\n",
      "Loss after mini-batch   281: 2.080\n",
      "Loss after mini-batch   291: 0.752\n",
      "Loss after mini-batch   301: 23.430\n",
      "Loss after mini-batch   311: 1.155\n",
      "Loss after mini-batch   321: 0.205\n",
      "Loss after mini-batch   331: 0.840\n",
      "Loss after mini-batch   341: 0.317\n",
      "Loss after mini-batch   351: 0.064\n",
      "Loss after mini-batch   361: 0.878\n",
      "Loss after mini-batch   371: 0.825\n",
      "Training Loss: 1.486 \t\t Validation Loss:3.066\n",
      "Starting epoch 286\n",
      "Loss after mini-batch     1: 0.353\n",
      "Loss after mini-batch    11: 0.230\n",
      "Loss after mini-batch    21: 1.310\n",
      "Loss after mini-batch    31: 0.034\n",
      "Loss after mini-batch    41: 2.081\n",
      "Loss after mini-batch    51: 0.411\n",
      "Loss after mini-batch    61: 5.352\n",
      "Loss after mini-batch    71: 2.398\n",
      "Loss after mini-batch    81: 1.104\n",
      "Loss after mini-batch    91: 0.712\n",
      "Loss after mini-batch   101: 0.084\n",
      "Loss after mini-batch   111: 0.199\n",
      "Loss after mini-batch   121: 0.147\n",
      "Loss after mini-batch   131: 0.452\n",
      "Loss after mini-batch   141: 1.700\n",
      "Loss after mini-batch   151: 1.206\n",
      "Loss after mini-batch   161: 0.067\n",
      "Loss after mini-batch   171: 0.490\n",
      "Loss after mini-batch   181: 0.098\n",
      "Loss after mini-batch   191: 0.048\n",
      "Loss after mini-batch   201: 0.974\n",
      "Loss after mini-batch   211: 0.331\n",
      "Loss after mini-batch   221: 0.360\n",
      "Loss after mini-batch   231: 1.382\n",
      "Loss after mini-batch   241: 0.343\n",
      "Loss after mini-batch   251: 0.056\n",
      "Loss after mini-batch   261: 0.110\n",
      "Loss after mini-batch   271: 0.425\n",
      "Loss after mini-batch   281: 0.031\n",
      "Loss after mini-batch   291: 0.452\n",
      "Loss after mini-batch   301: 1.566\n",
      "Loss after mini-batch   311: 0.239\n",
      "Loss after mini-batch   321: 0.415\n",
      "Loss after mini-batch   331: 0.275\n",
      "Loss after mini-batch   341: 0.070\n",
      "Loss after mini-batch   351: 5.450\n",
      "Loss after mini-batch   361: 1.166\n",
      "Loss after mini-batch   371: 0.142\n",
      "Training Loss: 0.147 \t\t Validation Loss:0.855\n",
      "Starting epoch 287\n",
      "Loss after mini-batch     1: 0.092\n",
      "Loss after mini-batch    11: 0.827\n",
      "Loss after mini-batch    21: 8.884\n",
      "Loss after mini-batch    31: 0.357\n",
      "Loss after mini-batch    41: 8.133\n",
      "Loss after mini-batch    51: 1.903\n",
      "Loss after mini-batch    61: 3.091\n",
      "Loss after mini-batch    71: 2.821\n",
      "Loss after mini-batch    81: 0.054\n",
      "Loss after mini-batch    91: 1.974\n",
      "Loss after mini-batch   101: 0.842\n",
      "Loss after mini-batch   111: 1.311\n",
      "Loss after mini-batch   121: 0.334\n",
      "Loss after mini-batch   131: 0.084\n",
      "Loss after mini-batch   141: 0.436\n",
      "Loss after mini-batch   151: 0.269\n",
      "Loss after mini-batch   161: 0.151\n",
      "Loss after mini-batch   171: 6.426\n",
      "Loss after mini-batch   181: 0.739\n",
      "Loss after mini-batch   191: 9.426\n",
      "Loss after mini-batch   201: 0.322\n",
      "Loss after mini-batch   211: 0.217\n",
      "Loss after mini-batch   221: 0.059\n",
      "Loss after mini-batch   231: 0.984\n",
      "Loss after mini-batch   241: 0.982\n",
      "Loss after mini-batch   251: 1.273\n",
      "Loss after mini-batch   261: 0.512\n",
      "Loss after mini-batch   271: 3.483\n",
      "Loss after mini-batch   281: 0.374\n",
      "Loss after mini-batch   291: 0.106\n",
      "Loss after mini-batch   301: 2.691\n",
      "Loss after mini-batch   311: 0.657\n",
      "Loss after mini-batch   321: 3.178\n",
      "Loss after mini-batch   331: 0.604\n",
      "Loss after mini-batch   341: 23.358\n",
      "Loss after mini-batch   351: 2.627\n",
      "Loss after mini-batch   361: 0.411\n",
      "Loss after mini-batch   371: 0.056\n",
      "Training Loss: 7.096 \t\t Validation Loss:7.355\n",
      "Starting epoch 288\n",
      "Loss after mini-batch     1: 0.363\n",
      "Loss after mini-batch    11: 0.658\n",
      "Loss after mini-batch    21: 0.232\n",
      "Loss after mini-batch    31: 0.306\n",
      "Loss after mini-batch    41: 1.665\n",
      "Loss after mini-batch    51: 1.638\n",
      "Loss after mini-batch    61: 0.625\n",
      "Loss after mini-batch    71: 0.204\n",
      "Loss after mini-batch    81: 0.222\n",
      "Loss after mini-batch    91: 0.883\n",
      "Loss after mini-batch   101: 0.126\n",
      "Loss after mini-batch   111: 1.747\n",
      "Loss after mini-batch   121: 3.457\n",
      "Loss after mini-batch   131: 0.135\n",
      "Loss after mini-batch   141: 2.618\n",
      "Loss after mini-batch   151: 0.141\n",
      "Loss after mini-batch   161: 0.157\n",
      "Loss after mini-batch   171: 0.215\n",
      "Loss after mini-batch   181: 1.768\n",
      "Loss after mini-batch   191: 0.767\n",
      "Loss after mini-batch   201: 0.115\n",
      "Loss after mini-batch   211: 0.089\n",
      "Loss after mini-batch   221: 0.036\n",
      "Loss after mini-batch   231: 0.020\n",
      "Loss after mini-batch   241: 1.119\n",
      "Loss after mini-batch   251: 0.052\n",
      "Loss after mini-batch   261: 0.125\n",
      "Loss after mini-batch   271: 0.431\n",
      "Loss after mini-batch   281: 0.497\n",
      "Loss after mini-batch   291: 0.791\n",
      "Loss after mini-batch   301: 5.467\n",
      "Loss after mini-batch   311: 1.558\n",
      "Loss after mini-batch   321: 5.883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   331: 2.941\n",
      "Loss after mini-batch   341: 2.638\n",
      "Loss after mini-batch   351: 1.153\n",
      "Loss after mini-batch   361: 2.592\n",
      "Loss after mini-batch   371: 1.091\n",
      "Training Loss: 4.861 \t\t Validation Loss:6.593\n",
      "Starting epoch 289\n",
      "Loss after mini-batch     1: 0.708\n",
      "Loss after mini-batch    11: 0.059\n",
      "Loss after mini-batch    21: 0.135\n",
      "Loss after mini-batch    31: 1.148\n",
      "Loss after mini-batch    41: 0.208\n",
      "Loss after mini-batch    51: 0.126\n",
      "Loss after mini-batch    61: 0.791\n",
      "Loss after mini-batch    71: 0.134\n",
      "Loss after mini-batch    81: 6.012\n",
      "Loss after mini-batch    91: 0.623\n",
      "Loss after mini-batch   101: 0.226\n",
      "Loss after mini-batch   111: 0.210\n",
      "Loss after mini-batch   121: 0.249\n",
      "Loss after mini-batch   131: 1.242\n",
      "Loss after mini-batch   141: 0.245\n",
      "Loss after mini-batch   151: 1.340\n",
      "Loss after mini-batch   161: 9.732\n",
      "Loss after mini-batch   171: 0.210\n",
      "Loss after mini-batch   181: 0.738\n",
      "Loss after mini-batch   191: 0.612\n",
      "Loss after mini-batch   201: 23.378\n",
      "Loss after mini-batch   211: 0.341\n",
      "Loss after mini-batch   221: 0.260\n",
      "Loss after mini-batch   231: 0.079\n",
      "Loss after mini-batch   241: 0.411\n",
      "Loss after mini-batch   251: 0.380\n",
      "Loss after mini-batch   261: 0.142\n",
      "Loss after mini-batch   271: 0.090\n",
      "Loss after mini-batch   281: 0.234\n",
      "Loss after mini-batch   291: 8.022\n",
      "Loss after mini-batch   301: 1.745\n",
      "Loss after mini-batch   311: 0.163\n",
      "Loss after mini-batch   321: 0.034\n",
      "Loss after mini-batch   331: 0.133\n",
      "Loss after mini-batch   341: 6.798\n",
      "Loss after mini-batch   351: 0.394\n",
      "Loss after mini-batch   361: 0.349\n",
      "Loss after mini-batch   371: 0.124\n",
      "Training Loss: 1.761 \t\t Validation Loss:2.080\n",
      "Starting epoch 290\n",
      "Loss after mini-batch     1: 0.143\n",
      "Loss after mini-batch    11: 0.514\n",
      "Loss after mini-batch    21: 2.868\n",
      "Loss after mini-batch    31: 7.991\n",
      "Loss after mini-batch    41: 3.186\n",
      "Loss after mini-batch    51: 0.176\n",
      "Loss after mini-batch    61: 3.765\n",
      "Loss after mini-batch    71: 0.299\n",
      "Loss after mini-batch    81: 0.127\n",
      "Loss after mini-batch    91: 1.203\n",
      "Loss after mini-batch   101: 0.256\n",
      "Loss after mini-batch   111: 0.091\n",
      "Loss after mini-batch   121: 0.139\n",
      "Loss after mini-batch   131: 1.796\n",
      "Loss after mini-batch   141: 0.083\n",
      "Loss after mini-batch   151: 0.086\n",
      "Loss after mini-batch   161: 0.206\n",
      "Loss after mini-batch   171: 0.901\n",
      "Loss after mini-batch   181: 2.061\n",
      "Loss after mini-batch   191: 0.109\n",
      "Loss after mini-batch   201: 0.353\n",
      "Loss after mini-batch   211: 0.952\n",
      "Loss after mini-batch   221: 0.095\n",
      "Loss after mini-batch   231: 1.495\n",
      "Loss after mini-batch   241: 5.130\n",
      "Loss after mini-batch   251: 0.256\n",
      "Loss after mini-batch   261: 0.231\n",
      "Loss after mini-batch   271: 0.278\n",
      "Loss after mini-batch   281: 0.086\n",
      "Loss after mini-batch   291: 0.070\n",
      "Loss after mini-batch   301: 1.143\n",
      "Loss after mini-batch   311: 1.274\n",
      "Loss after mini-batch   321: 0.516\n",
      "Loss after mini-batch   331: 0.413\n",
      "Loss after mini-batch   341: 0.368\n",
      "Loss after mini-batch   351: 0.977\n",
      "Loss after mini-batch   361: 2.427\n",
      "Loss after mini-batch   371: 1.993\n",
      "Training Loss: 0.111 \t\t Validation Loss:1.924\n",
      "Starting epoch 291\n",
      "Loss after mini-batch     1: 1.407\n",
      "Loss after mini-batch    11: 6.297\n",
      "Loss after mini-batch    21: 0.485\n",
      "Loss after mini-batch    31: 0.067\n",
      "Loss after mini-batch    41: 2.082\n",
      "Loss after mini-batch    51: 3.473\n",
      "Loss after mini-batch    61: 5.604\n",
      "Loss after mini-batch    71: 1.495\n",
      "Loss after mini-batch    81: 0.963\n",
      "Loss after mini-batch    91: 0.102\n",
      "Loss after mini-batch   101: 0.423\n",
      "Loss after mini-batch   111: 1.262\n",
      "Loss after mini-batch   121: 0.230\n",
      "Loss after mini-batch   131: 0.565\n",
      "Loss after mini-batch   141: 0.190\n",
      "Loss after mini-batch   151: 2.029\n",
      "Loss after mini-batch   161: 2.837\n",
      "Loss after mini-batch   171: 0.088\n",
      "Loss after mini-batch   181: 0.019\n",
      "Loss after mini-batch   191: 4.565\n",
      "Loss after mini-batch   201: 0.089\n",
      "Loss after mini-batch   211: 4.089\n",
      "Loss after mini-batch   221: 0.642\n",
      "Loss after mini-batch   231: 0.352\n",
      "Loss after mini-batch   241: 0.169\n",
      "Loss after mini-batch   251: 0.593\n",
      "Loss after mini-batch   261: 8.124\n",
      "Loss after mini-batch   271: 0.459\n",
      "Loss after mini-batch   281: 0.435\n",
      "Loss after mini-batch   291: 0.686\n",
      "Loss after mini-batch   301: 7.006\n",
      "Loss after mini-batch   311: 0.051\n",
      "Loss after mini-batch   321: 1.160\n",
      "Loss after mini-batch   331: 0.275\n",
      "Loss after mini-batch   341: 0.562\n",
      "Loss after mini-batch   351: 5.879\n",
      "Loss after mini-batch   361: 0.040\n",
      "Loss after mini-batch   371: 0.095\n",
      "Training Loss: 0.385 \t\t Validation Loss:0.698\n",
      "Starting epoch 292\n",
      "Loss after mini-batch     1: 3.126\n",
      "Loss after mini-batch    11: 0.496\n",
      "Loss after mini-batch    21: 0.493\n",
      "Loss after mini-batch    31: 0.059\n",
      "Loss after mini-batch    41: 0.202\n",
      "Loss after mini-batch    51: 7.667\n",
      "Loss after mini-batch    61: 0.369\n",
      "Loss after mini-batch    71: 0.832\n",
      "Loss after mini-batch    81: 0.063\n",
      "Loss after mini-batch    91: 1.134\n",
      "Loss after mini-batch   101: 0.182\n",
      "Loss after mini-batch   111: 0.443\n",
      "Loss after mini-batch   121: 3.709\n",
      "Loss after mini-batch   131: 0.106\n",
      "Loss after mini-batch   141: 0.114\n",
      "Loss after mini-batch   151: 0.086\n",
      "Loss after mini-batch   161: 0.203\n",
      "Loss after mini-batch   171: 0.262\n",
      "Loss after mini-batch   181: 0.226\n",
      "Loss after mini-batch   191: 0.146\n",
      "Loss after mini-batch   201: 0.109\n",
      "Loss after mini-batch   211: 0.052\n",
      "Loss after mini-batch   221: 7.585\n",
      "Loss after mini-batch   231: 0.091\n",
      "Loss after mini-batch   241: 0.097\n",
      "Loss after mini-batch   251: 1.256\n",
      "Loss after mini-batch   261: 0.122\n",
      "Loss after mini-batch   271: 3.901\n",
      "Loss after mini-batch   281: 0.089\n",
      "Loss after mini-batch   291: 1.068\n",
      "Loss after mini-batch   301: 0.101\n",
      "Loss after mini-batch   311: 0.207\n",
      "Loss after mini-batch   321: 0.243\n",
      "Loss after mini-batch   331: 2.367\n",
      "Loss after mini-batch   341: 0.881\n",
      "Loss after mini-batch   351: 0.699\n",
      "Loss after mini-batch   361: 0.031\n",
      "Loss after mini-batch   371: 0.226\n",
      "Training Loss: 1.164 \t\t Validation Loss:1.995\n",
      "Starting epoch 293\n",
      "Loss after mini-batch     1: 11.088\n",
      "Loss after mini-batch    11: 1.287\n",
      "Loss after mini-batch    21: 0.105\n",
      "Loss after mini-batch    31: 0.126\n",
      "Loss after mini-batch    41: 0.755\n",
      "Loss after mini-batch    51: 1.700\n",
      "Loss after mini-batch    61: 0.406\n",
      "Loss after mini-batch    71: 0.042\n",
      "Loss after mini-batch    81: 0.562\n",
      "Loss after mini-batch    91: 0.701\n",
      "Loss after mini-batch   101: 1.250\n",
      "Loss after mini-batch   111: 0.159\n",
      "Loss after mini-batch   121: 0.655\n",
      "Loss after mini-batch   131: 0.069\n",
      "Loss after mini-batch   141: 0.458\n",
      "Loss after mini-batch   151: 8.023\n",
      "Loss after mini-batch   161: 7.786\n",
      "Loss after mini-batch   171: 0.083\n",
      "Loss after mini-batch   181: 8.074\n",
      "Loss after mini-batch   191: 3.635\n",
      "Loss after mini-batch   201: 6.683\n",
      "Loss after mini-batch   211: 2.282\n",
      "Loss after mini-batch   221: 4.975\n",
      "Loss after mini-batch   231: 0.059\n",
      "Loss after mini-batch   241: 0.295\n",
      "Loss after mini-batch   251: 6.110\n",
      "Loss after mini-batch   261: 0.407\n",
      "Loss after mini-batch   271: 1.177\n",
      "Loss after mini-batch   281: 0.215\n",
      "Loss after mini-batch   291: 1.934\n",
      "Loss after mini-batch   301: 0.163\n",
      "Loss after mini-batch   311: 0.720\n",
      "Loss after mini-batch   321: 0.112\n",
      "Loss after mini-batch   331: 1.232\n",
      "Loss after mini-batch   341: 0.218\n",
      "Loss after mini-batch   351: 0.134\n",
      "Loss after mini-batch   361: 0.022\n",
      "Loss after mini-batch   371: 1.209\n",
      "Training Loss: 0.340 \t\t Validation Loss:0.413\n",
      "Starting epoch 294\n",
      "Loss after mini-batch     1: 0.373\n",
      "Loss after mini-batch    11: 0.217\n",
      "Loss after mini-batch    21: 3.850\n",
      "Loss after mini-batch    31: 0.116\n",
      "Loss after mini-batch    41: 0.319\n",
      "Loss after mini-batch    51: 0.295\n",
      "Loss after mini-batch    61: 0.466\n",
      "Loss after mini-batch    71: 0.186\n",
      "Loss after mini-batch    81: 0.808\n",
      "Loss after mini-batch    91: 0.133\n",
      "Loss after mini-batch   101: 0.648\n",
      "Loss after mini-batch   111: 0.522\n",
      "Loss after mini-batch   121: 0.688\n",
      "Loss after mini-batch   131: 0.506\n",
      "Loss after mini-batch   141: 2.604\n",
      "Loss after mini-batch   151: 0.059\n",
      "Loss after mini-batch   161: 0.484\n",
      "Loss after mini-batch   171: 0.322\n",
      "Loss after mini-batch   181: 0.376\n",
      "Loss after mini-batch   191: 0.360\n",
      "Loss after mini-batch   201: 22.904\n",
      "Loss after mini-batch   211: 3.014\n",
      "Loss after mini-batch   221: 0.136\n",
      "Loss after mini-batch   231: 0.500\n",
      "Loss after mini-batch   241: 1.152\n",
      "Loss after mini-batch   251: 1.858\n",
      "Loss after mini-batch   261: 1.089\n",
      "Loss after mini-batch   271: 0.178\n",
      "Loss after mini-batch   281: 3.894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   291: 2.184\n",
      "Loss after mini-batch   301: 0.957\n",
      "Loss after mini-batch   311: 0.206\n",
      "Loss after mini-batch   321: 0.926\n",
      "Loss after mini-batch   331: 0.082\n",
      "Loss after mini-batch   341: 0.101\n",
      "Loss after mini-batch   351: 0.038\n",
      "Loss after mini-batch   361: 2.615\n",
      "Loss after mini-batch   371: 0.262\n",
      "Training Loss: 0.162 \t\t Validation Loss:1.824\n",
      "Starting epoch 295\n",
      "Loss after mini-batch     1: 1.367\n",
      "Loss after mini-batch    11: 0.112\n",
      "Loss after mini-batch    21: 0.098\n",
      "Loss after mini-batch    31: 1.951\n",
      "Loss after mini-batch    41: 0.926\n",
      "Loss after mini-batch    51: 0.052\n",
      "Loss after mini-batch    61: 0.385\n",
      "Loss after mini-batch    71: 5.942\n",
      "Loss after mini-batch    81: 4.738\n",
      "Loss after mini-batch    91: 0.039\n",
      "Loss after mini-batch   101: 0.837\n",
      "Loss after mini-batch   111: 0.321\n",
      "Loss after mini-batch   121: 0.401\n",
      "Loss after mini-batch   131: 0.692\n",
      "Loss after mini-batch   141: 1.345\n",
      "Loss after mini-batch   151: 2.221\n",
      "Loss after mini-batch   161: 0.083\n",
      "Loss after mini-batch   171: 0.542\n",
      "Loss after mini-batch   181: 0.545\n",
      "Loss after mini-batch   191: 0.869\n",
      "Loss after mini-batch   201: 1.522\n",
      "Loss after mini-batch   211: 0.102\n",
      "Loss after mini-batch   221: 0.078\n",
      "Loss after mini-batch   231: 0.242\n",
      "Loss after mini-batch   241: 0.187\n",
      "Loss after mini-batch   251: 0.223\n",
      "Loss after mini-batch   261: 4.228\n",
      "Loss after mini-batch   271: 2.467\n",
      "Loss after mini-batch   281: 6.876\n",
      "Loss after mini-batch   291: 3.535\n",
      "Loss after mini-batch   301: 0.069\n",
      "Loss after mini-batch   311: 0.155\n",
      "Loss after mini-batch   321: 23.479\n",
      "Loss after mini-batch   331: 1.877\n",
      "Loss after mini-batch   341: 0.166\n",
      "Loss after mini-batch   351: 0.014\n",
      "Loss after mini-batch   361: 5.373\n",
      "Loss after mini-batch   371: 0.200\n",
      "Training Loss: 2.278 \t\t Validation Loss:3.008\n",
      "Starting epoch 296\n",
      "Loss after mini-batch     1: 1.614\n",
      "Loss after mini-batch    11: 0.470\n",
      "Loss after mini-batch    21: 0.461\n",
      "Loss after mini-batch    31: 0.095\n",
      "Loss after mini-batch    41: 0.692\n",
      "Loss after mini-batch    51: 0.303\n",
      "Loss after mini-batch    61: 7.707\n",
      "Loss after mini-batch    71: 1.095\n",
      "Loss after mini-batch    81: 0.060\n",
      "Loss after mini-batch    91: 0.362\n",
      "Loss after mini-batch   101: 0.024\n",
      "Loss after mini-batch   111: 2.326\n",
      "Loss after mini-batch   121: 0.411\n",
      "Loss after mini-batch   131: 2.105\n",
      "Loss after mini-batch   141: 0.190\n",
      "Loss after mini-batch   151: 0.086\n",
      "Loss after mini-batch   161: 0.525\n",
      "Loss after mini-batch   171: 0.519\n",
      "Loss after mini-batch   181: 0.415\n",
      "Loss after mini-batch   191: 1.223\n",
      "Loss after mini-batch   201: 1.601\n",
      "Loss after mini-batch   211: 0.791\n",
      "Loss after mini-batch   221: 0.484\n",
      "Loss after mini-batch   231: 1.248\n",
      "Loss after mini-batch   241: 2.018\n",
      "Loss after mini-batch   251: 0.130\n",
      "Loss after mini-batch   261: 1.208\n",
      "Loss after mini-batch   271: 0.284\n",
      "Loss after mini-batch   281: 0.109\n",
      "Loss after mini-batch   291: 0.083\n",
      "Loss after mini-batch   301: 3.776\n",
      "Loss after mini-batch   311: 0.264\n",
      "Loss after mini-batch   321: 2.289\n",
      "Loss after mini-batch   331: 0.529\n",
      "Loss after mini-batch   341: 10.356\n",
      "Loss after mini-batch   351: 0.963\n",
      "Loss after mini-batch   361: 4.734\n",
      "Loss after mini-batch   371: 1.037\n",
      "Training Loss: 7.289 \t\t Validation Loss:11.347\n",
      "Starting epoch 297\n",
      "Loss after mini-batch     1: 0.254\n",
      "Loss after mini-batch    11: 0.088\n",
      "Loss after mini-batch    21: 0.518\n",
      "Loss after mini-batch    31: 0.492\n",
      "Loss after mini-batch    41: 0.553\n",
      "Loss after mini-batch    51: 0.223\n",
      "Loss after mini-batch    61: 0.341\n",
      "Loss after mini-batch    71: 1.493\n",
      "Loss after mini-batch    81: 1.678\n",
      "Loss after mini-batch    91: 7.037\n",
      "Loss after mini-batch   101: 0.121\n",
      "Loss after mini-batch   111: 1.319\n",
      "Loss after mini-batch   121: 1.896\n",
      "Loss after mini-batch   131: 0.183\n",
      "Loss after mini-batch   141: 8.546\n",
      "Loss after mini-batch   151: 0.226\n",
      "Loss after mini-batch   161: 2.359\n",
      "Loss after mini-batch   171: 1.956\n",
      "Loss after mini-batch   181: 0.065\n",
      "Loss after mini-batch   191: 2.725\n",
      "Loss after mini-batch   201: 5.103\n",
      "Loss after mini-batch   211: 0.528\n",
      "Loss after mini-batch   221: 0.209\n",
      "Loss after mini-batch   231: 0.880\n",
      "Loss after mini-batch   241: 1.412\n",
      "Loss after mini-batch   251: 3.978\n",
      "Loss after mini-batch   261: 0.767\n",
      "Loss after mini-batch   271: 5.878\n",
      "Loss after mini-batch   281: 0.180\n",
      "Loss after mini-batch   291: 1.292\n",
      "Loss after mini-batch   301: 1.219\n",
      "Loss after mini-batch   311: 0.995\n",
      "Loss after mini-batch   321: 0.049\n",
      "Loss after mini-batch   331: 0.093\n",
      "Loss after mini-batch   341: 1.155\n",
      "Loss after mini-batch   351: 2.547\n",
      "Loss after mini-batch   361: 0.352\n",
      "Loss after mini-batch   371: 0.262\n",
      "Training Loss: 0.066 \t\t Validation Loss:16.010\n",
      "Starting epoch 298\n",
      "Loss after mini-batch     1: 0.284\n",
      "Loss after mini-batch    11: 1.066\n",
      "Loss after mini-batch    21: 1.724\n",
      "Loss after mini-batch    31: 0.405\n",
      "Loss after mini-batch    41: 3.439\n",
      "Loss after mini-batch    51: 0.395\n",
      "Loss after mini-batch    61: 0.074\n",
      "Loss after mini-batch    71: 0.195\n",
      "Loss after mini-batch    81: 0.026\n",
      "Loss after mini-batch    91: 0.183\n",
      "Loss after mini-batch   101: 0.651\n",
      "Loss after mini-batch   111: 0.247\n",
      "Loss after mini-batch   121: 0.073\n",
      "Loss after mini-batch   131: 0.215\n",
      "Loss after mini-batch   141: 1.496\n",
      "Loss after mini-batch   151: 1.901\n",
      "Loss after mini-batch   161: 2.132\n",
      "Loss after mini-batch   171: 0.861\n",
      "Loss after mini-batch   181: 0.352\n",
      "Loss after mini-batch   191: 0.428\n",
      "Loss after mini-batch   201: 0.387\n",
      "Loss after mini-batch   211: 0.129\n",
      "Loss after mini-batch   221: 0.249\n",
      "Loss after mini-batch   231: 2.240\n",
      "Loss after mini-batch   241: 0.550\n",
      "Loss after mini-batch   251: 0.183\n",
      "Loss after mini-batch   261: 0.411\n",
      "Loss after mini-batch   271: 6.473\n",
      "Loss after mini-batch   281: 11.186\n",
      "Loss after mini-batch   291: 0.253\n",
      "Loss after mini-batch   301: 0.740\n",
      "Loss after mini-batch   311: 1.324\n",
      "Loss after mini-batch   321: 5.203\n",
      "Loss after mini-batch   331: 0.079\n",
      "Loss after mini-batch   341: 0.409\n",
      "Loss after mini-batch   351: 0.388\n",
      "Loss after mini-batch   361: 0.068\n",
      "Loss after mini-batch   371: 0.930\n",
      "Training Loss: 2.289 \t\t Validation Loss:2.354\n",
      "Starting epoch 299\n",
      "Loss after mini-batch     1: 0.398\n",
      "Loss after mini-batch    11: 5.860\n",
      "Loss after mini-batch    21: 0.832\n",
      "Loss after mini-batch    31: 0.605\n",
      "Loss after mini-batch    41: 0.644\n",
      "Loss after mini-batch    51: 0.054\n",
      "Loss after mini-batch    61: 0.075\n",
      "Loss after mini-batch    71: 0.167\n",
      "Loss after mini-batch    81: 0.103\n",
      "Loss after mini-batch    91: 0.080\n",
      "Loss after mini-batch   101: 4.049\n",
      "Loss after mini-batch   111: 0.089\n",
      "Loss after mini-batch   121: 1.035\n",
      "Loss after mini-batch   131: 2.423\n",
      "Loss after mini-batch   141: 0.265\n",
      "Loss after mini-batch   151: 0.068\n",
      "Loss after mini-batch   161: 1.259\n",
      "Loss after mini-batch   171: 0.106\n",
      "Loss after mini-batch   181: 1.440\n",
      "Loss after mini-batch   191: 2.592\n",
      "Loss after mini-batch   201: 1.796\n",
      "Loss after mini-batch   211: 0.093\n",
      "Loss after mini-batch   221: 1.191\n",
      "Loss after mini-batch   231: 0.347\n",
      "Loss after mini-batch   241: 0.241\n",
      "Loss after mini-batch   251: 2.842\n",
      "Loss after mini-batch   261: 0.160\n",
      "Loss after mini-batch   271: 0.192\n",
      "Loss after mini-batch   281: 2.110\n",
      "Loss after mini-batch   291: 1.370\n",
      "Loss after mini-batch   301: 1.845\n",
      "Loss after mini-batch   311: 0.112\n",
      "Loss after mini-batch   321: 2.237\n",
      "Loss after mini-batch   331: 0.246\n",
      "Loss after mini-batch   341: 6.899\n",
      "Loss after mini-batch   351: 0.050\n",
      "Loss after mini-batch   361: 1.608\n",
      "Loss after mini-batch   371: 5.612\n",
      "Training Loss: 0.018 \t\t Validation Loss:3.175\n",
      "Starting epoch 300\n",
      "Loss after mini-batch     1: 0.111\n",
      "Loss after mini-batch    11: 2.902\n",
      "Loss after mini-batch    21: 0.983\n",
      "Loss after mini-batch    31: 0.319\n",
      "Loss after mini-batch    41: 0.272\n",
      "Loss after mini-batch    51: 0.189\n",
      "Loss after mini-batch    61: 0.331\n",
      "Loss after mini-batch    71: 1.053\n",
      "Loss after mini-batch    81: 0.069\n",
      "Loss after mini-batch    91: 0.453\n",
      "Loss after mini-batch   101: 0.784\n",
      "Loss after mini-batch   111: 0.104\n",
      "Loss after mini-batch   121: 0.562\n",
      "Loss after mini-batch   131: 4.904\n",
      "Loss after mini-batch   141: 2.725\n",
      "Loss after mini-batch   151: 0.077\n",
      "Loss after mini-batch   161: 1.796\n",
      "Loss after mini-batch   171: 0.405\n",
      "Loss after mini-batch   181: 9.829\n",
      "Loss after mini-batch   191: 0.105\n",
      "Loss after mini-batch   201: 0.513\n",
      "Loss after mini-batch   211: 2.177\n",
      "Loss after mini-batch   221: 0.382\n",
      "Loss after mini-batch   231: 0.532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after mini-batch   241: 1.584\n",
      "Loss after mini-batch   251: 2.625\n",
      "Loss after mini-batch   261: 0.257\n",
      "Loss after mini-batch   271: 0.187\n",
      "Loss after mini-batch   281: 0.852\n",
      "Loss after mini-batch   291: 0.529\n",
      "Loss after mini-batch   301: 3.885\n",
      "Loss after mini-batch   311: 2.600\n",
      "Loss after mini-batch   321: 1.627\n",
      "Loss after mini-batch   331: 0.306\n",
      "Loss after mini-batch   341: 0.119\n",
      "Loss after mini-batch   351: 0.196\n",
      "Loss after mini-batch   361: 3.025\n",
      "Loss after mini-batch   371: 6.943\n",
      "Training Loss: 1.708 \t\t Validation Loss:1.844\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "# Run the training loop\n",
    "history_train = np.empty((1,))\n",
    "history_val = np.empty((1,))\n",
    "for epoch in range(0, 300): # 5 epochs at maximum  \n",
    "    # Print epoch\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    # Set current loss value\n",
    "    current_loss = 0.0\n",
    "\n",
    "    # Iterate over the DataLoader for training data\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "          # Get and prepare inputs\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = mlp(inputs)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_function(outputs, targets)\n",
    "        # Perform backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Perform optimization\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        current_loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            print('Loss after mini-batch %5d: %.3f' %\n",
    "#                 (i + 1, current_loss / 500))\n",
    "                  (i + 1, loss.item()))\n",
    "            current_loss = 0.0\n",
    "    history_train = np.append(history_train, current_loss)\n",
    "\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    mlp.eval()     # Optional when not using Model Specific layer\n",
    "    for i, data in enumerate(validloader, 0):\n",
    "        # Get and prepare inputs\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "        \n",
    "        output_val = mlp(inputs)\n",
    "        valid_loss = loss_function(output_val, targets)\n",
    "    \n",
    "        valid_loss += loss.item()\n",
    "    history_val = np.append(history_val, valid_loss.item())\n",
    "    print('Training Loss: {:.3f} \\t\\t Validation Loss:'\\\n",
    "         '{:.3f}'.format(loss.item(), valid_loss.item()))\n",
    "#     print('Training Loss: {:.3f} \\t\\t Validation Loss:'\\\n",
    "#           '{:.3f}'.format(current_loss / len(trainloader), valid_loss / len(validloader)))\n",
    "#     if min_valid_loss > valid_loss:\n",
    "#         print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "#         min_valid_loss = valid_loss\n",
    "#         # Saving State Dict\n",
    "#         torch.save(model.state_dict(), 'saved_model.pth')\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7b9d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = np.random.randn(13)\n",
    "# torch usa tensores de torch y no numpy.darrays\n",
    "dtype = torch.float\n",
    "test = torch.randn((1, 3), device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3332d5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.forward(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62c6a43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.988006591796875"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27fc4848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0, 0], X_test[0]\n",
    "# xtest = [x[0] for x in X_test]\n",
    "ypred = [y[0].item() for y in y_pred]\n",
    "ytest = [y[0].item() for y in y_test]\n",
    "diff=np.array(ytest)-np.array(ypred)\n",
    "len(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b7e8ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 4.5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(diff,bins=100)\n",
    "plt.xscale('log')\n",
    "plt.ylim(0,4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f558b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff34b91b820>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ep = np.arange(0, 300+1)\n",
    "plt.plot(ep, history_train, label='train', color='green')\n",
    "plt.plot(ep, history_val, label='val', color='orange')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1355f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71.71311] [58.101044]\n",
      "[7.261673] [7.264923]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sns.displot(y_test)\n",
    "plt.plot(np.sort(y_test.detach().numpy()), color='blue', label='true likelihood')\n",
    "plt.plot(np.sort(y_pred.detach().numpy()), color='red', label='neural likelihood')\n",
    "plt.ylabel('loglikelihood')\n",
    "plt.legend()\n",
    "print(max(y_test.detach().numpy()), max(y_pred.detach().numpy()))\n",
    "print(min(y_test.detach().numpy()), min(y_pred.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47ff911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 1]), torch.Size([100, 1]), (100, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_pred), np.shape(y_test), np.shape(y_pred.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58b48c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((301,), (301,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(history_train), np.shape(history_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4744941b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 60.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ytest, bins=len(ytest), color='red')\n",
    "# plt.hist(ypred, bins=len(ypred), color='green')\n",
    "plt.ylim(0,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a45db1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ypred)==len(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a07e1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f802e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
